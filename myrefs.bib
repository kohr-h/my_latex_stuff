
@article{kunis_nonequispaced_2012,
	title = {The nonequispaced {FFT} on graphics processing units},
	volume = {12},
	issn = {1617-7061},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/pamm.201210003/abstract},
	doi = {10.1002/pamm.201210003},
	abstract = {Without doubt, the fast Fourier transform (FFT) belongs to the algorithms with large impact on science and engineering. By appropriate approximations, this scheme has been generalized for arbitrary spatial sampling points. This so called nonequispaced FFT is the core of the sequential NFFT3 library and we discuss its computational costs in detail. On the other hand, programmable graphics processing units have evolved into highly parallel, multithreaded, manycore processors with enormous computational capacity and very high memory bandwidth. By means of the so called Compute Unified Device Architecture (CUDA), we parallelized the nonequispaced FFT using the CUDA FFT library and a dedicated parallelization of the approximation scheme. ({\textcopyright} 2012 Wiley-VCH Verlag GmbH \& Co. KGaA, Weinheim)},
	language = {en},
	number = {1},
	urldate = {2016-10-31},
	journal = {PAMM},
	author = {Kunis, Susanne and Kunis, Stefan},
	month = dec,
	year = {2012},
	pages = {7--10},
}

@article{jia_bayesian_2016,
	title = {Bayesian approach to inverse problems for functions with a variable-index {Besov} prior},
	volume = {32},
	issn = {0266-5611, 1361-6420},
	url = {http://stacks.iop.org/0266-5611/32/i=8/a=085006?key=crossref.dcafc8c6c1e3ea1bc3abfa141dd0695f},
	doi = {10.1088/0266-5611/32/8/085006},
	number = {8},
	urldate = {2016-09-22},
	journal = {Inverse Problems},
	author = {Jia, Junxiong and Peng, Jigen and Gao, Jinghuai},
	month = aug,
	year = {2016},
	pages = {085006},
}

@book{hormander_analysis_2008,
	address = {Berlin, Heidelberg},
	series = {Classics in {Mathematics}},
	title = {The {Analysis} of {Linear} {Partial} {Differential} {Operators} {II}},
	url = {http://link.springer.com/10.1007/b138375},
	language = {en},
	urldate = {2016-09-12},
	publisher = {Springer Berlin Heidelberg},
	author = {H{\"o}rmander, Lars},
	year = {2008},
}

@article{brandt_multiphase_2001,
	title = {Multiphase method for automatic alignment of transmission electron microscope images using markers},
	volume = {133},
	number = {1},
	journal = {Journal of Structural Biology},
	author = {Brandt, S. and {others}},
	year = {2001},
	pages = {10--22}
}

@article{wu_clinical_2003,
	title = {Clinical implementation of x-ray phase-contrast imaging: {Theoretical} foundations and design considerations},
	volume = {30},
	issn = {0094-2405},
	shorttitle = {Clinical implementation of x-ray phase-contrast imaging},
	url = {http://scitation.aip.org/content/aapm/journal/medphys/30/8/10.1118/1.1593836},
	doi = {10.1118/1.1593836},
	abstract = {Theoretical foundation and design considerations of a clinical feasible x-ray phase contrastimaging technique were presented in this paper. Different from the analysis of imaging phase object with weak absorption in literature, we proposed a new formalism for in-line phase-contrast imaging to analyze the effects of four clinically important factors on the phase contrast. These are the body parts attenuation, the spatial coherence of spherical waves from a finite-size focal spot, and polychromatic x-ray and radiation doses to patients for clinical applications. The theory presented in this paper can be applied widely in diagnostic x-ray imaging procedures. As an example, computer simulations were conducted and optimal design parameters were derived for clinical mammography. The results of phantom experiments were also presented which validated the theoretical analysis and computer simulations.},
	number = {8},
	urldate = {2016-10-31},
	journal = {Medical Physics},
	author = {Wu, Xizeng and Liu, Hong},
	month = aug,
	year = {2003},
	pages = {2169--2179},
}

@incollection{burger_guide_2013,
	series = {Lecture {Notes} in {Mathematics}},
	title = {A {Guide} to the {TV} {Zoo}},
	copyright = {{\textcopyright}2013 Springer International Publishing Switzerland},
	isbn = {978-3-319-01711-2 978-3-319-01712-9},
	url = {http://link.springer.com/chapter/10.1007/978-3-319-01712-9_1},
	abstract = {Total variation methods and similar approaches based on regularizations with l 1-type norms (and seminorms) have become a very popular tool in image processing and inverse problems due to peculiar features that cannot be realized with smooth regularizations. In particular total variation techniques had particular success due to their ability to realize cartoon-type reconstructions with sharp edges. Due to an explosion of new developments in this field within the last decade it is a difficult task to keep an overview of the major results in analysis, the computational schemes, and the application fields. With these lectures we attempt to provide such an overview, of course biased by our major lines of research. We are focusing on the basic analysis of total variation methods and the extension of the original ROF-denoising model due various application fields. Furthermore we provide a brief discussion of state-of-the art computational methods and give an outlook to applications in different disciplines.},
	language = {en},
	number = {2090},
	urldate = {2016-09-09},
	booktitle = {Level {Set} and {PDE} {Based} {Reconstruction} {Methods} in {Imaging}},
	publisher = {Springer International Publishing},
	author = {Burger, Martin and Osher, Stanley},
	year = {2013},
	note = {DOI: 10.1007/978-3-319-01712-9\_1},
	pages = {1--70},
}

@article{alber_connection_2007,
	title = {The connection between the metric and generalized projection operators in {\textbackslash}{uppercaseBanach} spaces},
	volume = {23},
	number = {6},
	journal = {Acta Mathematica Sinica},
	author = {Alber, Y. I. and Li, J. L.},
	year = {2007},
	pages = {1109--1120}
}

@article{erickson_measurement_1971,
	title = {Measurement and compensation of defocusing and aberrations by {\textbackslash}{uppercaseFourier} processing of electron micrographs},
	volume = {261},
	number = {837},
	journal = {Philosophical Transactions of the Royal Society of London. Series B{\textendash}Biological Sciences},
	author = {Erickson, H. P. and Klug, A.},
	year = {1971},
	pages = {105--118}
}

@book{stein_introduction_1971,
	title = {Introduction to {\textbackslash}{uppercaseFourier} analysis on {\textbackslash}{uppercaseEuclidean} spaces},
	publisher = {Princeton University Press},
	author = {Stein, E. M. and Weiss, G. L.},
	year = {1971}
}

@article{unser_new_1987,
	title = {A new resolution criterion based on spectral signal-to-noise ratios},
	volume = {23},
	issn = {0304-3991},
	url = {http://www.sciencedirect.com/science/article/pii/0304399187902257},
	doi = {10.1016/0304-3991(87)90225-7},
	abstract = {A new criterion for the {\textquotedblleft}useful{\textquotedblright} resolution of electron micrographs of macromolecular particles is introduced. This criterion is based on estimation of the spatial frequency limit beyond which the spectral signal-to-noise ratio (SSNR) falls below an acceptable baseline. Applicable to both periodic and aperiodic specimens, this approach is particularly apposite for sets of correlation-averaged images. It represents a straightforward and intuitively appealing generalization of the traditional method of estimating the resolution of crystalline specimens from the spectral ranges of periodic reflections in their diffraction patterns. This method allows one to assess how closely the resolution of an averaged image based on N individual images approaches the ultimate resolution obtainable from an indefinitely large number of statistically equivalent images. Inter-relationships between the SSNR and two other measures of resolution, the differential phase residual and the Fourier ring correlation coefficient, are discussed, and their properties compared.},
	number = {1},
	urldate = {2016-10-24},
	journal = {Ultramicroscopy},
	author = {Unser, Michael and Trus, Benes L. and Steven, Alasdair C.},
	month = jan,
	year = {1987},
	keywords = {resolution, signal-to-noise ratio},
	pages = {39--51},
}

@book{lee_introduction_2012,
	address = {New York, NY},
	series = {Graduate {Texts} in {Mathematics}},
	title = {Introduction to {Smooth} {Manifolds}},
	volume = {218},
	isbn = {978-1-4419-9981-8 978-1-4419-9982-5},
	url = {http://link.springer.com/10.1007/978-1-4419-9982-5},
	urldate = {2016-09-20},
	publisher = {Springer New York},
	author = {Lee, John M.},
	year = {2012},
}

@article{lindenstrauss_complemented_1971,
	title = {On the complemented subspaces problem},
	volume = {9},
	number = {2},
	journal = {Israel Journal of Mathematics},
	author = {Lindenstrauss, J. and Tzafriri, L.},
	year = {1971},
	pages = {263--269}
}

@article{skoglund_maximum-entropy_1996,
	title = {Maximum-entropy three-dimensional reconstruction with deconvolution of the contrast transfer function: a test application with adenovirus},
	volume = {117},
	number = {3},
	journal = {Journal of Structural Biology},
	author = {Skoglund, U. and {others}},
	year = {1996},
	pages = {173--188}
}

@incollection{karlovich_pseudodifferential_2013,
	series = {Operator {Theory}: {Advances} and {Applications}},
	title = {Pseudodifferential {Operators} on {Variable} {Lebesgue} {Spaces}},
	copyright = {{\textcopyright}2013 Springer Basel},
	isbn = {978-3-0348-0536-0 978-3-0348-0537-7},
	url = {http://link.springer.com/chapter/10.1007/978-3-0348-0537-7_9},
	abstract = {Let M(Rn)M(Rn) {\textbackslash}mathcal\{M\}({\textbackslash}mathbb\{R\}{\textasciicircum}n) be the class of bounded away from one and infinity functions p:Rn{\textrightarrow}[1,$\infty$]p:Rn{\textrightarrow}[1,$\infty$] p : {\textbackslash}mathbb\{R\}{\textasciicircum}n {\textbackslash}rightarrow [1,{\textbackslash}infty] such that the Hardy-Littlewood maximal operator is bounded on the variable Lebesgue space Lp(.)(R(n)Lp(.)(R(n) L{\textasciicircum}\{p(.)\}({\textbackslash}mathbb\{R\}{\textasciicircum}\{(n)\}. We show that if a belongs to the H{\"o}rmander class Sn($\rho$-1)$\rho$$\delta$S$\rho$$\delta$n($\rho$-1) S {\textasciicircum}\{n({\textbackslash}rho-1)\}\_\{{\textbackslash}rho{\textbackslash}delta\} with 0{\textless}$\rho$<=1,0<=$\delta${\textless}10{\textless}$\rho$<=1,0<=$\delta${\textless}1 0 {\textless} {\textbackslash}rho {\textbackslash}leq 1, 0 {\textbackslash}leq {\textbackslash}delta {\textless} 1 1, then the pseudodifferential operator Opa is bounded on Lp(.)(Rn)Lp(.)(Rn) L{\textasciicircum}\{p(.)\}\{({\textbackslash}mathbb\{R\}{\textasciicircum}n)\} provided that p?M(Rn)p?M(Rn) p{\textbackslash}in {\textbackslash}mathcal\{M\}\{({\textbackslash}mathbb\{R\}{\textasciicircum}n)\}. Let M*(Rn)M*(Rn) {\textbackslash}mathcal\{M\}*\{({\textbackslash}mathbb\{R\}{\textasciicircum}n)\} be the class of variable exponents p?M(Rn)p?M(Rn) p{\textbackslash}in {\textbackslash}mathcal\{M\}\{({\textbackslash}mathbb\{R\}{\textasciicircum}n)\} represented as 1/1p(x)p(x)1/1p(x)p(x) \{{\textbackslash}raise0.7ex{\textbackslash}hbox\{\$1\$\} {\textbackslash}!{\textbackslash}mathord\{{\textbackslash}left/\{{\textbackslash}vphantom \{1 \{p(x)\}\}\}{\textbackslash}right.{\textbackslash}kern-{\textbackslash}nulldelimiterspace\} {\textbackslash}!{\textbackslash}lower0.7ex{\textbackslash}hbox\{\$\{p(x)\}\$\}\} $\theta$/$\theta$popo+(1-0)/(1-0)p1p1(x)wherepo?(1,$\infty$),($\theta$)?(0,1)andp?M(Rn).Weprovethatifa?s01,0$\theta$/$\theta$popo+(1-0)/(1-0)p1p1(x)wherepo?(1,$\infty$),($\theta$)?(0,1)andp?M(Rn).Weprovethatifa?s1,00 \{{\textbackslash}raise0.7ex{\textbackslash}hbox\{\${\textbackslash}theta \$\} {\textbackslash}!{\textbackslash}mathord\{{\textbackslash}left/\{{\textbackslash}vphantom \{{\textbackslash}theta \{po\}\}\}{\textbackslash}right.{\textbackslash}kern-{\textbackslash}nulldelimiterspace\} {\textbackslash}!{\textbackslash}lower0.7ex{\textbackslash}hbox\{\$\{po\}\$\}\} + \{{\textbackslash}raise0.7ex{\textbackslash}hbox\{\$\{(1 - 0)\}\$\} {\textbackslash}!{\textbackslash}mathord\{{\textbackslash}left/\{{\textbackslash}vphantom \{\{(1 -0)\}\{p1\}\}\}{\textbackslash}right.{\textbackslash}kern-{\textbackslash}nulldelimiterspace\}{\textbackslash}!{\textbackslash}lower0.7ex{\textbackslash}hbox\{\$\{p1\}\$\}\}(x) \{{\textbackslash}rm where {\textbackslash}, po\} {\textbackslash}in (1,{\textbackslash}infty),({\textbackslash}theta){\textbackslash}in (0,1) {\textbackslash}rm \{and\}p{\textbackslash}in {\textbackslash}mathcal\{M\}\{({\textbackslash}mathbb\{R\}{\textasciicircum}n)\}.{\textbackslash}rm \{We prove that if\} a {\textbackslash}in s{\textasciicircum}\{0\}\_\{1,0\} limpo+(1-0)/(1-0)p1p1(x)wherepo?(1,$\infty$),($\theta$)?(0,1)andp?M(Rn).Weprovethatifa?s01,0limpo+(1-0)/(1-0)p1p1(x)wherepo?(1,$\infty$),($\theta$)?(0,1)andp?M(Rn).Weprovethatifa?s1,00 \{{\textbackslash}lim\}{\textbackslash}kern-{\textbackslash}nulldelimiterspace{\textbackslash}!{\textbackslash}lower0.7ex{\textbackslash}hbox\{\$\{po\}\$\} + \{{\textbackslash}raise0.7ex{\textbackslash}hbox\{\$\{(1 - 0)\}\$\} {\textbackslash}!{\textbackslash}mathord\{{\textbackslash}left/\{{\textbackslash}vphantom \{\{(1 - 0)\} \{p1\}\}\}{\textbackslash}right.{\textbackslash}kern-{\textbackslash}nulldelimiterspace\}{\textbackslash}!{\textbackslash}lower0.7ex{\textbackslash}hbox\{\$\{p1\}\$\}\}(x) \{{\textbackslash}rm where {\textbackslash}, po\} {\textbackslash}in (1,{\textbackslash}infty),({\textbackslash}theta){\textbackslash}in (0,1) {\textbackslash}rm \{and\} p{\textbackslash}in {\textbackslash}mathcal\{M\}\{({\textbackslash}mathbb\{R\}{\textasciicircum}n)\}.{\textbackslash}rm \{We prove that if\} a {\textbackslash}in s{\textasciicircum}\{0\}\_\{1,0\} slowly oscillates at infinity in the first variable, then the condition limR{\textrightarrow}$\infty$inf{\textbar}x{\textbar}+{\textbar}$\xi${\textbar}>={\textbar}Ra(x,$\xi${\textbar}){\textgreater}0limR{\textrightarrow}$\infty$inf{\textbar}x{\textbar}+{\textbar}$\xi${\textbar}>={\textbar}Ra(x,$\xi${\textbar}){\textgreater}0{\textbackslash}lim\_\{R\} {\textbackslash}rightarrow {\textbackslash}infty {\textbackslash}rm\{inf\}\_\{{\textbar}x{\textbar}+{\textbar}{\textbackslash}xi{\textbar}{\textbackslash}geq{\textbar}R\}\{a(x,{\textbackslash}xi{\textbar})\}{\textgreater}0 is sufficient for the Fredholmness of Op(A) on p?M(Rn)p?M(Rn) p{\textbackslash}in {\textbackslash}mathcal\{M\}\{({\textbackslash}mathbb\{R\}{\textasciicircum}n)\} Lp(.)(Rn)Lp(.)(Rn) L{\textasciicircum}\{p(.)\}\{({\textbackslash}mathbb\{R\}{\textasciicircum}n)\} whenever Opa Lp(.)(Rn)Lp(.)(Rn) L{\textasciicircum}\{p(.)\}\{({\textbackslash}mathbb\{R\}{\textasciicircum}n)\} Both theorems generalize pioneering results by Rabinovich and Samko [24] obtained for globally log-H{\"o}lder continuous exponents p constituting a proper subset of p?M(Rn)p?M(Rn) p{\textbackslash}in {\textbackslash}mathcal\{M\}\{({\textbackslash}mathbb\{R\}{\textasciicircum}n)\}},
	language = {en},
	number = {228},
	urldate = {2016-09-10},
	booktitle = {Operator {Theory}, {Pseudo}-{Differential} {Equations}, and {Mathematical} {Physics}},
	publisher = {Springer Basel},
	author = {Karlovich, Alexei Yu and Spitkovsky, Ilya M.},
	editor = {Karlovich, Yuri I. and Rodino, Luigi and Silbermann, Bernd and Spitkovsky, Ilya M.},
	year = {2013},
	note = {DOI: 10.1007/978-3-0348-0537-7\_9},
	pages = {173--183},
}

@article{raydan_barzilai_1997,
	title = {The {Barzilai} and {Borwein} {Gradient} {Method} for the {Large} {Scale} {Unconstrained} {Minimization} {Problem}},
	volume = {7},
	issn = {1052-6234, 1095-7189},
	url = {http://epubs.siam.org/doi/abs/10.1137/S1052623494266365},
	doi = {10.1137/S1052623494266365},
	language = {en},
	number = {1},
	urldate = {2016-09-23},
	journal = {SIAM Journal on Optimization},
	author = {Raydan, Marcos},
	month = feb,
	year = {1997},
	pages = {26--33},
}

@article{schuster_regularization_2005,
	title = {On a regularization scheme for linear operators in distribution spaces with an application to the spherical {\textbackslash}{uppercaseRadon} transform},
	volume = {65},
	number = {4},
	journal = {SIAM Journal on Applied Mathematics},
	author = {Schuster, T. and Quinto, E. T.},
	year = {2005},
	pages = {1369--1387}
}

@article{fernandez_ctf_2006,
	title = {{CTF} determination and correction in electron cryotomography},
	volume = {106},
	issn = {0304-3991},
	url = {http://www.sciencedirect.com/science/article/pii/S0304399106000222},
	doi = {10.1016/j.ultramic.2006.02.004},
	abstract = {Electron cryotomography (cryoET) has the potential to elucidate the structure of complex biological specimens at molecular resolution but technical and computational improvements are still needed. This work addresses the determination and correction of the contrast transfer function (CTF) of the electron microscope in cryoET. Our approach to CTF detection and defocus determination depends on strip-based periodogram averaging, extended throughout the tilt series to overcome the low contrast conditions found in cryoET. A method for CTF correction that deals with the defocus gradient in images of tilted specimens is also proposed. These approaches to CTF determination and correction have been applied here to several examples of cryoET of pleomorphic specimens and of single particles. CTF correction is essential for improving the resolution, particularly in those studies that combine cryoET with single particle averaging techniques.},
	number = {7},
	urldate = {2016-09-24},
	journal = {Ultramicroscopy},
	author = {Fern{\'a}ndez, J. J. and Li, S. and Crowther, R. A.},
	month = may,
	year = {2006},
	pages = {587--596},
}

@article{sorzano_normalizing_2004,
	title = {Normalizing projection images: a study of image normalizing procedures for single particle three-dimensional electron microscopy},
	volume = {101},
	issn = {0304-3991},
	number = {2-4},
	journal = {Ultramicroscopy},
	author = {Sorzano, C. O. S. and de la Fraga, L. G. and Clackdoyle, R. and Carazo, J. M.},
	year = {2004},
	pages = {129--138}
}

@article{fanelli_electron_2008,
	title = {Electron tomography: a short overview with an emphasis on the absorption potential model for the forward problem},
	volume = {24},
	issn = {0266-5611},
	shorttitle = {Electron tomography},
	url = {http://stacks.iop.org/0266-5611/24/i=1/a=013001},
	doi = {10.1088/0266-5611/24/1/013001},
	abstract = {This review of the development and current status of electron tomography deals mainly with the mathematical and algorithmic aspects. After a very brief description of the role of electron tomography in structural biology, we turn our attention to the derivation of the forward operator. Starting from the Schr{\"o}dinger equation, the electron{\textendash}specimen interaction is modelled as a diffraction tomography problem and the picture is completed by adding a description of the optical system of the transmission electron microscope. The first-order Born approximation enables one to explicitly express the intensity for any finite wavenumber in terms of the propagation operator acting on the specimen convolved with a point spread function, derived from the optics in the transmission electron microscope. Next, we focus on the difficulties that cause the reconstruction problem to be quite challenging. Special emphasis is put on explaining the extremely low signal-to-noise ratio in the data combined with the incomplete data problems, which lead to severe ill-posedness. The next step is to derive the standard phase contrast model used in the electron tomography community. The above-mentioned expression for the intensity generalizes the standard phase contrast model which can be obtained by replacing the propagation operator by its high-energy limit, the x-ray transform, as the wavenumber tends to infinity. The importance of more carefully including the wave nature of the electron{\textendash}specimen interaction is supported by performing an asymptotic analysis of the intensity as the wavenumber tends to infinity. Next we provide an overview of the various reconstruction methods that have been employed in electron tomography and we conclude by mentioning a number of open problems. Besides providing an introduction to electron tomography written in the 'language of inverse problems', the authors hope to raise interest among experts in integral geometry and regularization theory for the mathematical and algorithmic difficulties that are encountered in electron tomography.},
	language = {en},
	number = {1},
	urldate = {2016-09-24},
	journal = {Inverse Problems},
	author = {Fanelli, Duccio and {\"O}ktem, Ozan},
	year = {2008},
	keywords = {electron microscopy, tomography, topical review},
	pages = {013001},
}

@article{zang_interpolation_2008,
	title = {Interpolation inequalities for derivatives in variable exponent {Lebesgue}{\textendash}{Sobolev} spaces},
	volume = {69},
	issn = {0362546X},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0362546X0700675X},
	doi = {10.1016/j.na.2007.10.001},
	language = {en},
	number = {10},
	urldate = {2016-09-10},
	journal = {Nonlinear Analysis: Theory, Methods \& Applications},
	author = {Zang, Aibin and Fu, Yong},
	month = nov,
	year = {2008},
	pages = {3629--3636},
}

@inproceedings{kohr_novel_2010,
	title = {A novel method for fast and high-quality reconstructions in {Electron} {Tomo}},
	volume = {7},
	booktitle = {Oberwolfach {Reports} 2010},
	publisher = {EMS},
	author = {{Kohr}},
	year = {2010},
	pages = {1017--1099}
}

@article{agmon_spectral_1975,
	title = {Spectral properties of {\textbackslash}{uppercaseSchr{\"o}dinger} operators and scattering theroy},
	volume = {4},
	journal = {Ann. Scoula. Norm. Sup. Pisa Ser.},
	author = {Agmon, S.},
	year = {1975},
	pages = {151--218}
}

@article{quinto_local_2008,
	title = {Local tomography in electron microscopy},
	volume = {68},
	issn = {0036-1399},
	number = {5},
	journal = {SIAM J. Appl. Math.},
	author = {Quinto, E. T. and {\"O}ktem, O.},
	year = {2008},
	pages = {1282--1303}
}

@book{sneddon_fourier_1951,
	title = {Fourier transforms},
	publisher = {McGraw-Hill},
	author = {Sneddon, I. N.},
	year = {1951}
}

@article{acar_analysis_1994,
	title = {Analysis of bounded variation penalty methods for ill-posed problems},
	volume = {10},
	issn = {0266-5611},
	url = {http://stacks.iop.org/0266-5611/10/i=6/a=003},
	doi = {10.1088/0266-5611/10/6/003},
	abstract = {This paper presents an abstract analysis of bounded variation (BV) methods for ill-posed operator equations Au=z. Let T(u) def =//Au-z// 2 + alpha J(u) where the penalty, or 'regularization parameter alpha {\textgreater}0 and the functional J(u) is the BV norm or semi-norm of u, also known as the total variation of u. Under mild restrictions on the operator A and the functional J(u), it is shown that the functional T(u) has a unique minimizer which is stable with respect to certain perturbations in the data z, the operator A, the parameter alpha , and the functional J(u). In addition, convergence results are obtained which apply when these perturbations vanish and the regularization parameter is chosen appropriately.},
	language = {en},
	number = {6},
	urldate = {2016-09-25},
	journal = {Inverse Problems},
	author = {Acar, R. and Vogel, C. R.},
	year = {1994},
	pages = {1217},
}

@book{rockafellar_variational_1998,
	address = {Berlin, Heidelberg},
	series = {Grundlehren der mathematischen {Wissenschaften}},
	title = {Variational {Analysis}},
	volume = {317},
	isbn = {978-3-540-62772-2 978-3-642-02431-3},
	url = {http://link.springer.com/10.1007/978-3-642-02431-3},
	urldate = {2016-09-12},
	publisher = {Springer Berlin Heidelberg},
	author = {Rockafellar, R. Tyrrell and Wets, Roger J. B.},
	editor = {Berger, M. and de la Harpe, P. and Hirzebruch, F. and Hitchin, N. J. and H{\"o}rmander, L. and Kupiainen, A. and Lebeau, G. and Ratner, M. and Serre, D. and Sinai, Y. G. and Sloane, N. J. A. and Vershik, A. M. and Waldschmidt, M.},
	year = {1998},
}

@incollection{combettes_proximal_2011,
	series = {Springer {Optimization} and {Its} {Applications}},
	title = {Proximal {Splitting} {Methods} in {Signal} {Processing}},
	copyright = {{\textcopyright}2011 Springer Science+Business Media, LLC},
	isbn = {978-1-4419-9568-1 978-1-4419-9569-8},
	url = {http://link.springer.com/chapter/10.1007/978-1-4419-9569-8_10},
	abstract = {The proximity operator of a convex function is a natural extension of the notion of a projection operator onto a convex set. This tool, which plays a central role in the analysis and the numerical solution of convex optimization problems, has recently been introduced in the arena of inverse problems and, especially, in signal processing, where it has become increasingly important. In this paper, we review the basic properties of proximity operators which are relevant to signal processing and present optimization methods based on these operators. These proximal splitting methods are shown to capture and extend several well-known algorithms in a unifying framework. Applications of proximal methods in signal recovery and synthesis are discussed.},
	language = {en},
	number = {49},
	urldate = {2016-09-12},
	booktitle = {Fixed-{Point} {Algorithms} for {Inverse} {Problems} in {Science} and {Engineering}},
	publisher = {Springer New York},
	author = {Combettes, Patrick L. and Pesquet, Jean-Christophe},
	editor = {Bauschke, Heinz H. and Burachik, Regina S. and Combettes, Patrick L. and Elser, Veit and Luke, D. Russell and Wolkowicz, Henry},
	year = {2011},
	note = {DOI: 10.1007/978-1-4419-9569-8\_10},
	keywords = {convex, optimization, proximal, splitting},
	pages = {185--212},
}

@article{handa_gvnn:_2016,
	title = {gvnn: {Neural} {Network} {Library} for {Geometric} {Computer} {Vision}},
	shorttitle = {gvnn},
	url = {http://arxiv.org/abs/1607.07405},
	abstract = {We introduce gvnn, a neural network library in Torch aimed towards bridging the gap between classic geometric computer vision and deep learning. Inspired by the recent success of Spatial Transformer Networks, we propose several new layers which are often used as parametric transformations on the data in geometric computer vision. These layers can be inserted within a neural network much in the spirit of the original spatial transformers and allow backpropagation to enable end-to-end learning of a network involving any domain knowledge in geometric computer vision. This opens up applications in learning invariance to 3D geometric transformation for place recognition, end-to-end visual odometry, depth estimation and unsupervised learning through warping with a parametric transformation for image reconstruction error.},
	urldate = {2016-10-03},
	journal = {arXiv:1607.07405 [cs]},
	author = {Handa, Ankur and Bloesch, Michael and Patraucean, Viorica and Stent, Simon and McCormac, John and Davison, Andrew},
	month = jul,
	year = {2016},
	note = {arXiv: 1607.07405},
	keywords = {computer vision, machine learning, neural networks, unsupervised learning},
}

@article{dahmen_combined_2014,
	title = {Combined {Scanning} {Transmission} {Electron} {Microscopy} {Tilt}- and {Focal} {Series}},
	volume = {20},
	issn = {1435-8115},
	url = {http://journals.cambridge.org/article_S1431927614000075},
	doi = {10.1017/S1431927614000075},
	number = {02},
	journal = {Microscopy and Microanalysis},
	author = {Dahmen, Tim and Baudoin, Jean-Pierre and Lupini, Andrew R. and K{\"u}bel, Christian and Slusallek, Philipp and de Jonge, Niels},
	year = {2014},
	keywords = {electron microscopy, stem imaging, tomography},
	pages = {548--560}
}

@book{werner_funktionalanalysis_2005,
	title = {Funktionalanalysis},
	publisher = {Springer},
	author = {Werner, D.},
	year = {2005}
}

@book{engl_regularization_1996,
	title = {Regularization of inverse problems},
	publisher = {Springer},
	author = {Engl, H. W. and Hanke, M. and Neubauer, A.},
	year = {1996}
}

@article{grimm_electron_1998,
	title = {Electron {Tomography} of {Ice}-{Embedded} {Prokaryotic} {Cells}},
	volume = {74},
	issn = {0006-3495},
	url = {http://www.sciencedirect.com/science/article/pii/S0006349598740287},
	doi = {10.1016/S0006-3495(98)74028-7},
	abstract = {Whole cells of archaea were embedded in vitreous ice by plunge freezing and investigated by automated energy-filtered electron tomography at 120 kV. The embedded cells were between 300 and 750 nm thick, and their structures were reconstructed to a resolution of 20{\textendash}40 nm from tilt series comprising 50{\textendash}140 images. The dose was kept within tolerable limits. A resolution of 20 nm allowed visualization of the individual stalks of the S-layer of Pyrobaculum aerophilum cells, which had undergone partial lysis, in three dimensions. The attainable resolution for low-dose electron tomography under different experimental conditions was theoretically investigated in terms of the specimen thickness. To obtain 2-nm resolution at 120 kV (300 kV), the specimen must not be thicker than 100 nm (150 nm). For a resolution of 10 nm, the maximum thickness is 450 nm (700 nm). An accelerating voltage of 300 kV is advantageous, mainly for specimens thicker than 100 nm. Experimental investigations so far have resulted in a resolution that is worse by a factor of 2{\textendash}5 as compared to theory.},
	number = {2},
	urldate = {2016-10-24},
	journal = {Biophysical Journal},
	author = {Grimm, Rudo and Singh, Hapreet and Rachel, Reinhard and Typke, Dieter and Zillig, Wolfram and Baumeister, Wolfgang},
	month = feb,
	year = {1998},
	keywords = {electron microscopy, tem imaging, tomography},
	pages = {1031--1042},
}

@article{heidari_mezerji_practical_2011,
	title = {A practical method to determine the effective resolution in incoherent experimental electron tomography},
	volume = {111},
	issn = {0304-3991},
	url = {http://www.sciencedirect.com/science/article/pii/S0304399111000362},
	doi = {10.1016/j.ultramic.2011.01.021},
	abstract = {It is not straightforward to determine resolution for a 3D reconstruction when performing an electron tomography experiment. Different contributions such as missing wedge and misalignment add up and often influence the final resolution in an anisotropic manner. The conventional resolution measures can not be used for all of the reconstruction techniques, especially for iterative techniques which are more commonly used for electron tomography in materials science. Here we define a quantitative resolution measure that determines the resolution in three orthogonal directions of the reconstruction. As an application we use this measure to determine the optimum number of simultaneous iterative reconstruction technique (SIRT) iterations to reconstruct the gold nanoparticles, based on a high angle annular dark field STEM (HAADF-STEM) tilt series.},
	number = {5},
	urldate = {2016-10-31},
	journal = {Ultramicroscopy},
	author = {Heidari Mezerji, Hamed and Van den Broek, Wouter and Bals, Sara},
	month = apr,
	year = {2011},
	keywords = {electron microscopy, resolution, tomography},
	pages = {330--336},
}

@article{beckner_inequalities_1975,
	title = {Inequalities in {\textbackslash}{uppercaseFourier} analysis},
	volume = {102},
	journal = {Annals of Mathematics},
	author = {Beckner, W.},
	year = {1975},
	pages = {159--182}
}

@article{zhu_efficient_2008,
	title = {An efficient primal-dual hybrid gradient algorithm for total variation image restoration},
	journal = {UCLA CAM Report},
	author = {Zhu, Mingqiang, Zhu and Chan, Tony},
	year = {2008},
	pages = {08--34},
}

@book{burger_level_2013,
	address = {Cham},
	series = {Lecture {Notes} in {Mathematics}},
	title = {Level {Set} and {PDE} {Based} {Reconstruction} {Methods} in {Imaging}},
	volume = {2090},
	isbn = {978-3-319-01711-2 978-3-319-01712-9},
	url = {http://link.springer.com/10.1007/978-3-319-01712-9},
	urldate = {2016-09-12},
	publisher = {Springer International Publishing},
	author = {Burger, Martin and Mennucci, Andrea C.G. and Osher, Stanley and Rumpf, Martin},
	year = {2013},
}

@incollection{penczek_resolution_2007,
	title = {Resolution in {Electron} {Tomography}},
	copyright = {{\textcopyright}2006 Springer Science+Business Media, LLC},
	isbn = {978-0-387-31234-7 978-0-387-69008-7},
	url = {http://link.springer.com/chapter/10.1007/978-0-387-69008-7_11},
	abstract = {Traditionally, in computed tomography practiced in radiology, the resolution of the reconstruction is expressed in terms of the number of evenly spaced projections required for the faithful reconstruction of an object that has a given diameter (see equation (10) below).The tacit assumption is that projection data have a sufficient spectral signal-to-noise ratio (SSNR) in the whole frequency range in order to reproduce the object faithfully. In electron microscopy, the situation is dramatically different, as the electron dose limitations result in very low SSNR in the individual projections. The suppression of signal is particularly severe in high spatial frequencies, where the signal is affected by the envelope function of the microscope and the high amount of ambient noise, as well as in some low spatial frequency regions (due to the influence of the contrast transfer function (CTF) of the electron microscope). In single-particle reconstruction, a satisfactory level of the SSNR in the 3D reconstruction is achieved by including a large number of 2D projections (tens to hundreds of thousands) that are averaged during the reconstruction process. Except for rare cases (Boisset et al., 1998), the angular distribution of projections is not an issue, as the large number of molecules and the randomness of their orientations on the support grid all but guarantee uniform coverage of angular space. The concern is whether the number of projections per angular direction is sufficient to yield the desired SSNR or whether the angular distribution of projections is such that the oversampling of the 3D Fourier space achieved during the reconstruction process will yield the desired SSNR.},
	language = {en},
	urldate = {2016-10-31},
	booktitle = {Electron {Tomography}},
	publisher = {Springer New York},
	author = {Penczek, Pawel A. and Frank, Joachim},
	editor = {Frank, Joachim},
	year = {2007},
	note = {DOI: 10.1007/978-0-387-69008-7\_11},
	keywords = {electron microscopy, resolution, tomography},
	pages = {307--330},
}

@book{yosida_functional_1995,
	edition = {Reprint of the sixth (1980)},
	series = {Classics in {Mathematics}},
	title = {Functional analysis},
	publisher = {Springer},
	author = {Yosida, K.},
	year = {1995}
}

@article{louis_unified_1999,
	title = {A {Unified} {Approach} to {Regularization} {Methods} for {Linear} {Ill}-{Posed} {Problems}},
	volume = {15},
	number = {2},
	journal = {Inverse Problems},
	author = {Louis, A. K.},
	year = {1999},
	pages = {489--498}
}

@article{bauer_diffeomorphic_2015,
	title = {Diffeomorphic {Density} {Matching} by {Optimal} {Information} {Transport}},
	volume = {8},
	url = {http://epubs.siam.org/doi/abs/10.1137/151006238},
	doi = {10.1137/151006238},
	abstract = {We address the following problem: given two smooth densities on a manifold, find an optimal diffeomorphism that transforms one density into the other. Our framework builds on connections between the Fisher--Rao information metric on the space of probability densities and right-invariant metrics on the infinite-dimensional manifold of diffeomorphisms.	This optimal information transport, and modifications thereof, allow us to construct numerical algorithms for density matching. The algorithms are inherently more efficient than those based on optimal mass transport or diffeomorphic registration.	Our methods have applications in medical image registration, texture mapping, image morphing, nonuniform random sampling, and mesh adaptivity. Some of these applications are illustrated in examples.},
	number = {3},
	urldate = {2016-09-12},
	journal = {SIAM Journal on Imaging Sciences},
	author = {Bauer, M. and Joshi, S. and Modin, K.},
	month = jan,
	year = {2015},
	pages = {1718--1751},
}

@article{de_jonge_three-dimensional_2010,
	title = {Three-{Dimensional} {Scanning} {Transmission} {Electron} {Microscopy} of {Biological} {Specimens}},
	volume = {16},
	issn = {1435-8115, 1431-9276},
	url = {https://www.cambridge.org/core/journals/microscopy-and-microanalysis/article/three-dimensional-scanning-transmission-electron-microscopy-of-biological-specimens/B5C3DB36CACA196241313DEB9C1F75CD},
	doi = {10.1017/S1431927609991280},
	abstract = {AbstractA three-dimensional (3D) reconstruction of the cytoskeleton and a clathrin-coated pit in mammalian cells has been achieved from a focal-series of images recorded in an aberration-corrected scanning transmission electron microscope (STEM). The specimen was a metallic replica of the biological structure comprising Pt nanoparticles 2{\textendash}3 nm in diameter, with a high stability under electron beam radiation. The 3D dataset was processed by an automated deconvolution procedure. The lateral resolution was 1.1 nm, set by pixel size. Particles differing by only 10 nm in vertical position were identified as separate objects with greater than 20\% dip in contrast between them. We refer to this value as the axial resolution of the deconvolution or reconstruction, the ability to recognize two objects, which were unresolved in the original dataset. The resolution of the reconstruction is comparable to that achieved by tilt-series transmission electron microscopy. However, the focal-series method does not require mechanical tilting and is therefore much faster. 3D STEM images were also recorded of the Golgi ribbon in conventional thin sections containing 3T3 cells with a comparable axial resolution in the deconvolved dataset.},
	number = {1},
	urldate = {2016-10-24},
	journal = {Microscopy and Microanalysis},
	author = {de Jonge, Niels and Sougrat, Rachid and Northan, Brian M. and Pennycook, Stephen J.},
	month = feb,
	year = {2010},
	keywords = {electron microscopy, stem imaging, tomography},
	pages = {54--63},
}

@book{diening_lebesgue_2011,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Mathematics}},
	title = {Lebesgue and {Sobolev} {Spaces} with {Variable} {Exponents}},
	volume = {2017},
	isbn = {978-3-642-18362-1 978-3-642-18363-8},
	url = {http://link.springer.com/10.1007/978-3-642-18363-8},
	urldate = {2016-09-12},
	publisher = {Springer Berlin Heidelberg},
	author = {Diening, Lars and Harjulehto, Petteri and H{\"a}st{\"o}, Peter and Ruzicka, Michael},
	year = {2011},
}

@book{schuster_method_2007,
	address = {Berlin},
	series = {Lecture {Notes} in {Mathematics}},
	title = {The method of approximate inverse: theory and applications},
	volume = {1906},
	isbn = {978-3-540-71226-8 3-540-71226-7},
	url = {http://dx.doi.org/10.1007/978-3-540-71227-5},
	publisher = {Springer},
	author = {Schuster, T.},
	year = {2007},
	mrnumber = {2317109 (2009c:65369)}
}

@article{lewis_medical_2004,
	title = {Medical phase contrast x-ray imaging: current status and future prospects},
	volume = {49},
	issn = {0031-9155},
	shorttitle = {Medical phase contrast x-ray imaging},
	url = {http://stacks.iop.org/0031-9155/49/i=16/a=005},
	doi = {10.1088/0031-9155/49/16/005},
	abstract = {The exploitation of phase contrast appears to offer the tantalising possibility of creating the biggest change in medical x-ray imaging since the invention of computed tomography. A considerable number of experiments performed by researchers across four continents have produced some extraordinary images. These images have demonstrated greatly enhanced contrast over conventional methods revealing soft tissue discrimination at micron scale resolutions. Contrast improvements can be achieved at doses rather less than those required by conventional x-ray imaging. The use of synchrotrons has revealed the possibilities offered by these techniques but unfortunately the application of these ideas in a clinical context requires that technology be pushed to its limits in a number of areas including x-ray sources, optics and detectors. The current state of the art is reviewed.},
	language = {en},
	number = {16},
	urldate = {2016-10-31},
	journal = {Physics in Medicine and Biology},
	author = {Lewis, R. A.},
	year = {2004},
	pages = {3573},
}

@article{rieder_approximate_2003,
	title = {The approximate inverse in action {II}: convergence and stability},
	volume = {72},
	number = {243},
	journal = {Mathematics of computation},
	author = {Rieder, A and Schuster, T},
	year = {2003},
	pages = {1399--1415}
}

@book{scherzer_handbook_2015,
	address = {New York, NY},
	title = {Handbook of {Mathematical} {Methods} in {Imaging}},
	isbn = {978-1-4939-0789-2 978-1-4939-0790-8},
	url = {http://link.springer.com/10.1007/978-1-4939-0790-8},
	language = {en},
	urldate = {2016-09-12},
	publisher = {Springer New York},
	editor = {Scherzer, Otmar},
	year = {2015},
}

@article{midgley_electron_2009,
	title = {Electron tomography and holography in materials science},
	volume = {8},
	number = {4},
	journal = {Nature Materials},
	author = {Midgley, P. A. and Dunin-Borkowski, R. E.},
	year = {2009},
	pages = {271--280}
}

@article{marone_regridding_2012,
	title = {Regridding reconstruction algorithm for real-time tomographic imaging},
	volume = {19},
	issn = {0909-0495},
	url = {http://europepmc.org/articles/PMC3480277},
	doi = {10.1107/s0909049512032864},
	number = {Pt 6},
	journal = {Journal of synchrotron radiation},
	author = {Marone, F and Stampanoni, M},
	month = nov,
	year = {2012},
	pages = {1029--1037}
}

@article{leonov_computation_1977,
	title = {On the computation of the values of unbounded operators by the averaging method},
	volume = {18},
	number = {4},
	journal = {Soviet Math. Dokl.},
	author = {Leonov, A. S.},
	year = {1977},
	pages = {882--886}
}

@inproceedings{louis_application_1997,
	title = {Application of the approximate inverse to 3{\textbackslash}{uppercaseD} {\textbackslash}{uppercaseX}-ray {\textbackslash}{uppercaseCT} and ultrasound tomography},
	booktitle = {Inverse problems in medical imaging and nondestructive testing},
	publisher = {Springer},
	author = {Louis, A. K.},
	year = {1997}
}

@article{cheng_mrc2014:_2015,
	series = {Recent {Advances} in {Detector} {Technologies} and {Applications} for {Molecular} {TEM}},
	title = {{MRC}2014: {Extensions} to the {MRC} format header for electron cryo-microscopy and tomography},
	volume = {192},
	issn = {1047-8477},
	shorttitle = {{MRC}2014},
	url = {http://www.sciencedirect.com/science/article/pii/S104784771500074X},
	doi = {10.1016/j.jsb.2015.04.002},
	abstract = {The MRC binary file format is widely used in the three-dimensional electron microscopy field for storing image and volume data. Files contain a header which describes the kind of data held, together with other important metadata. In response to advances in electron microscopy techniques, a number of variants to the file format have emerged which contain useful additional data, but which limit interoperability between different software packages. Following extensive discussions, the authors, who represent leading software packages in the field, propose a set of extensions to the MRC format standard designed to accommodate these variants, while restoring interoperability. The MRC format is equivalent to the map format used in the CCP4 suite for macromolecular crystallography, and the proposal also maintains interoperability with crystallography software. This Technical Note describes the proposed extensions, and serves as a reference for the standard.},
	number = {2},
	urldate = {2016-10-31},
	journal = {Journal of Structural Biology},
	author = {Cheng, Anchi and Henderson, Richard and Mastronarde, David and Ludtke, Steven J. and Schoenmakers, Remco H. M. and Short, Judith and Marabini, Roberto and Dallakyan, Sargis and Agard, David and Winn, Martyn},
	month = nov,
	year = {2015},
	keywords = {data exchange, electron microscopy},
	pages = {146--150},
}

@article{beylkin_fast_1995,
	title = {On the fast {\textbackslash}{uppercaseFourier} transform of functions with singularities},
	volume = {2},
	number = {4},
	journal = {Applied and Computational Harmonic Analysis},
	author = {Beylkin, G.},
	year = {1995},
	pages = {363--381}
}

@article{zhu_three-dimensional_1997,
	title = {Three-dimensional reconstruction with contrast transfer function correction from energy-filtered cryoelectron micrographs: procedure and application to the 70S {Escherichia} coli ribosome},
	volume = {118},
	issn = {1047-8477},
	number = {3},
	journal = {Journal of Structural Biology},
	author = {Zhu, J. and Penczek, P. and Schroder, R. and Frank, J.},
	year = {1997},
	pages = {197--219}
}

@article{chambolle_image_1997,
	title = {Image recovery via total variation minimization and related problems},
	volume = {76},
	number = {2},
	journal = {Numerische Mathematik},
	author = {Chambolle, A. and Lions, P.-L.},
	year = {1997},
	pages = {167--188}
}

@article{crowther_reconstruction_1970,
	title = {The {Reconstruction} of a {Three}-{Dimensional} {Structure} from {Projections} and its {Application} to {Electron} {Microscopy}},
	volume = {317},
	issn = {1364-5021, 1471-2946},
	url = {http://rspa.royalsocietypublishing.org/content/317/1530/319},
	doi = {10.1098/rspa.1970.0119},
	abstract = {A transmission electron micrograph is essentially a projection of the specimen in the direction of view. In order to reconstruct a three-dimensional image of the specimen, it is necessary to be able to combine data from a number of different views. A formal solution of this problem is given in terms of Fourier transforms. Its realization requires data reduction and interpolation. The final solution is given by a least squares approach, which also indicates how many views must be included to give a valid reconstruction of a given particle to a given degree of resolution. Interpolation procedures of varying power are given, to be employed according to the economy with which the available data must be used. An alternative procedure is described for direct reconstruction without the use of Fourier transforms, but it is shown to be in general less practicable than the Fourier approach.},
	language = {en},
	number = {1530},
	urldate = {2016-10-24},
	journal = {Proceedings of the Royal Society of London A: Mathematical, Physical and Engineering Sciences},
	author = {Crowther, R. A. and DeRosier, D. J. and Klug, A.},
	month = jun,
	year = {1970},
	keywords = {crowther criterion, electron microscopy, resolution},
	pages = {319--340},
}

@book{gibson_optical_2016,
	address = {Cham},
	series = {{SpringerBriefs} in {Computer} {Science}},
	title = {Optical {Flow} and {Trajectory} {Estimation} {Methods}},
	isbn = {978-3-319-44940-1 978-3-319-44941-8},
	url = {http://link.springer.com/10.1007/978-3-319-44941-8},
	urldate = {2016-09-19},
	publisher = {Springer International Publishing},
	author = {Gibson, Joel and Marques, Oge},
	year = {2016},
}

@book{byrne_iterative_2014,
	series = {Monographs and {Research} {Notes} in {Mathematics}},
	title = {Iterative {Optimization} in {Inverse} {Problems}},
	isbn = {978-1-4822-2233-3},
	url = {https://www.crcpress.com/Iterative-Optimization-in-Inverse-Problems/Byrne/p/book/9781482222333},
	abstract = {Iterative Optimization in Inverse Problems brings together a number of important iterative algorithms for medical imaging, optimization, and statistical estimation. It incorporates recent work that has not appeared in other books and draws on the author{\textquoteright}s considerable research in the field, includ},
	urldate = {2016-09-12},
	publisher = {Chapman and Hall/CRC},
	author = {Byrne, Charles L.},
	year = {2014},
}

@article{lakhal_locating_2008,
	title = {Locating radiating sources for {\textbackslash}{uppercaseMaxwell}'s equations using the approximate inverse},
	volume = {24},
	journal = {Inverse Problems},
	author = {Lakhal, A. and Louis, A. K.},
	year = {2008},
	pages = {045020}
}

@book{press_numerical_1992,
	edition = {2nd},
	title = {Numerical {Recipes} in {\textbackslash}{uppercaseC} - {The} {Art} of {Scientific} {Computing}},
	publisher = {Cambridge University Press},
	author = {Press, W. H. and {others}},
	year = {1992}
}

@article{koster_perspectives_1997,
	title = {Perspectives of molecular and cellular electron tomography.},
	volume = {120},
	number = {3},
	journal = {Journal of structural biology},
	author = {Koster, A. J. and Grimm, R. and Typke, D. and Hegerl, R. and Stoschek, A. and Walz, J. and Baumeister, W.},
	year = {1997},
	pages = {276--308}
}

@article{winkler_focus_2003,
	title = {Focus gradient correction applied to tilt series image data used in electron tomography},
	volume = {143},
	number = {1},
	journal = {Journal of Structural Biology},
	author = {Winkler, H. and Taylor, K. A.},
	year = {2003},
	pages = {24--32}
}

@article{hofmann_regularization_2009,
	title = {Regularization in {\textbackslash}{uppercaseHilbert} space under unbounded operators and general source conditions},
	volume = {25},
	journal = {Inverse Problems},
	author = {Hofmann, B. and Math{\'e}, P. and von Weizs{\"a}cker, H.},
	year = {2009},
	pages = {115013}
}

@book{rieder_keine_2003,
	title = {Keine {Probleme} mit {Inversen} {Problemen}},
	publisher = {Vieweg},
	author = {Rieder, A.},
	year = {2003}
}

@article{cardone_resolution_2005,
	title = {A resolution criterion for electron tomography based on cross-validation},
	volume = {151},
	issn = {1047-8477},
	url = {http://www.sciencedirect.com/science/article/pii/S1047847705001085},
	doi = {10.1016/j.jsb.2005.04.006},
	abstract = {Despite much progress in electron tomography, quantitative assessment of resolution has remained a problematic issue. The criteria that are used in single particle analysis, based on gauging the consistency between density maps calculated from half data sets, are not directly applicable because of the uniqueness of a tomographic volume. Here, we propose two criteria based on a cross-validation approach. One, called FSCe/o, is based on a Fourier shell correlation comparison between tomograms calculated from the even and odd members of a tilt series. The other, called noise-compensated leave-one-out (NLOO), is based on Fourier ring correlation comparisons between an original projection and the corresponding reprojection of the tomogram calculated from all the other projections, taking into account the differing noise statistics. Plotted as a function of tilt angle, they allow assessment of the angular dependence of resolution and quality control over the series of projections. Integrated over all projections, the results give a global figure for resolution. Tests on simulated tomograms established consistency between these criteria and the FSCref, a correlation coefficient calculated between a known reference structure and the corresponding portion of a tomogram containing that structure. The two criteria{\textemdash}FSCe/o and NLOO{\textemdash}are mutually consistent when residual noise is the major resolution-limiting factor. When the size of the tilt increment becomes a significant factor, NLOO provides a more reliable criterion, as expected, although it is computationally intensive. Applicable to entire tomograms or selected structures, NLOO has also been tested on experimental tomographic data.},
	number = {2},
	urldate = {2016-10-31},
	journal = {Journal of Structural Biology},
	author = {Cardone, Giovanni and Gr{\"u}newald, Kay and Steven, Alasdair C.},
	month = aug,
	year = {2005},
	keywords = {electron microscopy, fourier shell correlation, resolution, tomography},
	pages = {117--129},
}

@article{sidky_convex_2012,
	title = {Convex optimization problem prototyping for image reconstruction in computed tomography with the {Chambolle}{\textendash}{Pock} algorithm},
	volume = {57},
	issn = {0031-9155},
	url = {http://stacks.iop.org/0031-9155/57/i=10/a=3065},
	doi = {10.1088/0031-9155/57/10/3065},
	abstract = {The primal{\textendash}dual optimization algorithm developed in Chambolle and Pock (CP) (2011 J. Math. Imag. Vis. 40 1{\textendash}26) is applied to various convex optimization problems of interest in computed tomography (CT) image reconstruction. This algorithm allows for rapid prototyping of optimization problems for the purpose of designing iterative image reconstruction algorithms for CT. The primal{\textendash}dual algorithm is briefly summarized in this paper, and its potential for prototyping is demonstrated by explicitly deriving CP algorithm instances for many optimization problems relevant to CT. An example application modeling breast CT with low-intensity x-ray illumination is presented.},
	language = {en},
	number = {10},
	urldate = {2016-10-31},
	journal = {Physics in Medicine and Biology},
	author = {Sidky, Emil Y. and J{\o}rgensen, Jakob H. and Pan, Xiaochuan},
	year = {2012},
	pages = {3065},
}

@article{xu_dual-axis_2007,
	title = {Dual-axis electron tomography: a new approach for investigating the spatial organization of wood cellulose microfibrils},
	volume = {41},
	number = {2},
	journal = {Wood Science and Technology},
	author = {Xu, P. and Donaldson, L. A. and Gergely, Z. R. and Staehelin, L. A.},
	year = {2007},
	pages = {101--116}
}

@phdthesis{padula_software_2005,
	type = {Thesis},
	title = {Software design for simulation driven optimization},
	url = {https://scholarship.rice.edu/handle/1911/18795},
	abstract = {This thesis describes a flexible framework for abstract numerical algorithms which treats algorithms as objects and makes them reusable, composable, and modifiable. These algorithm objects are implemented using the Rice Vector Library (RVL) interface, decoupling the algorithmic code from the details of linear algebra and calculus in Hilbert Space. I made many improvements to the RVL design, including abstract return types for reductions. These improvements allowed me to demonstrate the breadth of this design by incorporating semantically similar objects from other packages which had significant syntatic differences to the RVL objects. By adapting other libraries, I gain access to a variety of tools, including parallel linear algebra implementations. The benefits of the algorithm framework can be seen when abstract numerical algorithms are coupled with parallel simulators without needing to modify either the algorithm or the simulator.},
	language = {eng},
	urldate = {2016-10-31},
	school = {Rice University},
	author = {Padula, Anthony D.},
	year = {2005},
}

@article{danev_volta_2014,
	title = {Volta potential phase plate for in-focus phase contrast transmission electron microscopy},
	volume = {111},
	issn = {0027-8424, 1091-6490},
	url = {http://www.pnas.org/content/111/44/15635},
	doi = {10.1073/pnas.1418377111},
	abstract = {We describe a phase plate for transmission electron microscopy taking advantage of a hitherto-unknown phenomenon, namely a beam-induced Volta potential on the surface of a continuous thin film. The Volta potential is negative, indicating that it is not caused by beam-induced electrostatic charging. The film must be heated to \~{}200 {\textdegree}C to prevent contamination and enable the Volta potential effect. The phase shift is created {\textquotedblleft}on the fly{\textquotedblright} by the central diffraction beam eliminating the need for precise phase plate alignment. Images acquired with the Volta phase plate (VPP) show higher contrast and unlike Zernike phase plate images no fringing artifacts. Following installation into the microscope, the VPP has an initial settling time of about a week after which the phase shift behavior becomes stable. The VPP has a long service life and has been used for more than 6 mo without noticeable degradation in performance. The mechanism underlying the VPP is the same as the one responsible for the degradation over time of the performance of thin-film Zernike phase plates, but in the VPP it is used in a constructive way. The exact physics and/or chemistry behind the process causing the Volta potential are not fully understood, but experimental evidence suggests that radiation-induced surface modification combined with a chemical equilibrium between the surface and residual gases in the vacuum play an important role.},
	language = {en},
	number = {44},
	urldate = {2016-10-31},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Danev, Radostin and Buijsse, Bart and Khoshouei, Maryam and Plitzko, J{\"u}rgen M. and Baumeister, Wolfgang},
	month = nov,
	year = {2014},
	pmid = {25331897},
	keywords = {electron microscopy, phase plate, tomography},
	pages = {15635--15640},
}

@book{hormander_analysis_2007,
	address = {Berlin, Heidelberg},
	series = {Classics in {Mathematics}},
	title = {The {Analysis} of {Linear} {Partial} {Differential} {Operators} {III}},
	isbn = {978-3-540-49937-4},
	url = {http://link.springer.com/10.1007/978-3-540-49938-1},
	language = {en},
	urldate = {2016-09-12},
	publisher = {Springer Berlin Heidelberg},
	author = {H{\"o}rmander, Lars},
	year = {2007},
}

@article{alber_numerical_1984,
	title = {Numerical computation of waves at high frequencies by an iterated {\textbackslash}{uppercaseWKB}-method},
	volume = {6},
	number = {4},
	journal = {Mathematical Methods in the Applied Sciences},
	author = {Alber, H. D.},
	year = {1984},
	pages = {520--526}
}

@article{nashed_inner_1987,
	title = {Inner, outer, and generalized inverses in {\textbackslash}{uppercaseBanach} and {\textbackslash}{uppercaseHilbert} spaces},
	volume = {9},
	number = {3-4},
	journal = {Numerical Functional Analysis and Optimization},
	author = {Nashed, M. Z.},
	year = {1987},
	pages = {261--325}
}

@book{zeidler_nonlinear_1985,
	address = {New York, NY},
	title = {Nonlinear {Functional} {Analysis} and its {Applications}},
	isbn = {978-1-4612-9529-7 978-1-4612-5020-3},
	url = {http://link.springer.com/10.1007/978-1-4612-5020-3},
	language = {en},
	urldate = {2016-09-12},
	publisher = {Springer New York},
	author = {Zeidler, Eberhard},
	year = {1985},
}

@article{colton_recent_2000,
	title = {Recent developments in inverse acoustic scattering theory},
	volume = {42},
	number = {3},
	journal = {Siam Review},
	author = {Colton, D. and Coyle, J. and Monk, P.},
	year = {2000},
	pages = {369--414}
}

@article{sommer_sparse_2013,
	title = {Sparse {Multi}-{Scale} {Diffeomorphic} {Registration}: {The} {Kernel} {Bundle} {Framework}},
	volume = {46},
	issn = {0924-9907, 1573-7683},
	shorttitle = {Sparse {Multi}-{Scale} {Diffeomorphic} {Registration}},
	url = {http://link.springer.com/10.1007/s10851-012-0409-0},
	doi = {10.1007/s10851-012-0409-0},
	language = {en},
	number = {3},
	urldate = {2016-09-23},
	journal = {Journal of Mathematical Imaging and Vision},
	author = {Sommer, Stefan and Lauze, Fran{\c c}ois and Nielsen, Mads and Pennec, Xavier},
	month = jul,
	year = {2013},
	pages = {292--308},
}

@article{kremer_computer_1996,
	title = {Computer visualization of three-dimensional image data using {\textbackslash}{uppercaseIMOD}},
	volume = {116},
	number = {1},
	journal = {Journal of Structural Biology},
	author = {Kremer, J. R. and Mastronarde, D. N. and McIntosh, J. R.},
	year = {1996},
	pages = {71--76}
}

@book{goodman_introduction_1996,
	edition = {2nd},
	title = {Introduction to {Fourier} optics},
	publisher = {McGraw-Hill},
	author = {Goodman, J. W.},
	year = {1996}
}

@article{xiong_ctf_2009,
	title = {\{{CTF}\} determination and correction for low dose tomographic tilt series},
	volume = {168},
	issn = {1047-8477},
	url = {http://www.sciencedirect.com/science/article/pii/S1047847709002433},
	doi = {10.1016/j.jsb.2009.08.016},
	abstract = {The resolution of cryo-electron tomography can be limited by the first zero of the microscope's contrast transfer function (CTF). To achieve higher resolution, it is critical to determine the \{CTF\} and correct its phase inversions. However, the extremely low signal-to-noise ratio (SNR) and the defocus gradient in the projections of tilted specimens make this process challenging. Two programs, \{CTFPLOTTER\} and CTFPHASEFLIP, have been developed to address these issues. \{CTFPLOTTER\} obtains a 1D power spectrum by periodogram averaging and rotational averaging and it estimates the noise background with a novel approach, which uses images taken with no specimen. The background-subtracted 1D power spectra from image regions at different defocus values are then shifted to align their first zeros and averaged together. This averaging improves the \{SNR\} sufficiently that it becomes possible to determine the defocus for subsets of the tilt series rather than just the entire series. \{CTFPHASEFLIP\} corrects images line-by-line by inverting phases appropriately in thin strips of the image at nearly constant defocus. \{CTF\} correction by these methods is shown to improve the resolution of aligned, averaged particles extracted from tomograms. However, some restoration of Fourier amplitudes at high frequencies is important for seeing the benefits from \{CTF\} correction.},
	number = {3},
	journal = {Journal of Structural Biology},
	author = {Xiong, Quanren and Morphew, Mary K. and Schwartz, Cindi L. and Hoenger, Andreas H. and Mastronarde, David N.},
	year = {2009},
	pages = {378--387}
}

@phdthesis{schuster_schnelle_1999,
	title = {Schnelle {Rekonstruktion} von {Geschwindigkeitsfeldern} und {Theorie} der {Approximativen} {Inversen}},
	school = {Universit{\"a}t des Saarlandes},
	author = {Schuster, T.},
	year = {1999}
}

@article{louis_diffusion_2010,
	title = {Diffusion reconstruction from very noisy tomographic data},
	volume = {4},
	journal = {Inverse Problems and Imaging},
	author = {Louis, A. K.},
	year = {2010},
	pages = {675--683}
}

@article{fenander_modal_1996,
	title = {Modal synthesis when modeling damping by use of fractional derivatives},
	volume = {34},
	number = {5},
	journal = {AIAA Journal},
	author = {Fenander, A.},
	year = {1996},
	pages = {1051--1058}
}

@phdthesis{dietz_approximative_1999,
	title = {Die {Approximative} {Inverse} als {Rekonstruktionsmethode} in der {\textbackslash}{uppercaseR{\"o}ntgen}-{Computertomographie}},
	school = {Universit{\"a}t des Saarlandes},
	author = {Dietz, R.},
	year = {1999}
}

@article{vulovic_image_2013,
	title = {Image formation modeling in cryo-electron microscopy},
	volume = {183},
	issn = {1047-8477},
	url = {http://www.sciencedirect.com/science/article/pii/S1047847713001226},
	doi = {10.1016/j.jsb.2013.05.008},
	abstract = {Accurate modeling of image formation in cryo-electron microscopy is an important requirement for quantitative image interpretation and optimization of the data acquisition strategy. Here we present a forward model that accounts for the specimen{\textquoteright}s scattering properties, microscope optics, and detector response. The specimen interaction potential is calculated with the isolated atom superposition approximation (IASA) and extended with the influences of solvent{\textquoteright}s dielectric and ionic properties as well as the molecular electrostatic distribution. We account for an effective charge redistribution via the Poisson{\textendash}Boltzmann approach and find that the IASA-based potential forms the dominant part of the interaction potential, as the contribution of the redistribution is less than 10\%. The electron wave is propagated through the specimen by a multislice approach and the influence of the optics is included via the contrast transfer function. We incorporate the detective quantum efficiency of the camera due to the difference between signal and noise transfer characteristics, instead of using only the modulation transfer function. The full model was validated against experimental images of 20S proteasome, hemoglobin, and GroEL. The simulations adequately predict the effects of phase contrast, changes due to the integrated electron flux, thickness, inelastic scattering, detective quantum efficiency and acceleration voltage. We suggest that beam-induced specimen movements are relevant in the experiments whereas the influence of the solvent amorphousness can be neglected. All simulation parameters are based on physical principles and, when necessary, experimentally determined.},
	number = {1},
	urldate = {2016-10-31},
	journal = {Journal of Structural Biology},
	author = {Vulovi{\'c}, Milo{\v s} and Ravelli, Raimond B. G. and van Vliet, Lucas J. and Koster, Abraham J. and Lazi{\'c}, Ivan and L{\"u}cken, Uwe and Rullg{\r a}rd, Hans and {\"O}ktem, Ozan and Rieger, Bernd},
	month = jul,
	year = {2013},
	keywords = {electron microscopy, modeling},
	pages = {19--32},
}

@article{penczek_double-tilt_1995,
	title = {Double-tilt electron tomography},
	volume = {60},
	number = {3},
	journal = {Ultramicroscopy},
	author = {Penczek, P. and {others}},
	year = {1995},
	pages = {393}
}

@book{hawkes_principles_1994,
	title = {Principles of electron optics. {Volume} 3: {Wave} {Optics}},
	publisher = {Academic Press},
	author = {Hawkes, P. W. and Kasper, E.},
	year = {1994}
}

@book{kaballo_grundkurs_2011,
	title = {Grundkurs {Funktionalanalysis}},
	publisher = {Springer, Berlin},
	author = {Kaballo, W.},
	year = {2011}
}

@article{jonas_phase_2004,
	title = {Phase contrast tomography using holographic measurements},
	volume = {20},
	issn = {0266-5611},
	url = {http://stacks.iop.org/0266-5611/20/i=1/a=005},
	doi = {10.1088/0266-5611/20/1/005},
	abstract = {Phase contrast tomography is a developing area in imaging. It is an extension of conventional tomography additionally employing phase information. However, a strong coherence condition is needed for the measurement set-up. Applications at synchrotron devices have been performed since 1998 with convincing success. Devices for small laboratories are about to be implemented in the near future. In this paper several models for phase contrast tomography are derived from the wave equation. Error estimates show the area of validity of these models. Using results from tomography, such as approximate inverse and fast backprojection, efficient reconstruction algorithms are worked out. Numerical tests with synthetic and real data are included.},
	language = {en},
	number = {1},
	urldate = {2016-10-31},
	journal = {Inverse Problems},
	author = {Jonas, Peter and Louis, Alfred K.},
	year = {2004},
	pages = {75},
}

@book{kutyniok_shearlets_2012,
	address = {Boston},
	title = {Shearlets},
	isbn = {978-0-8176-8315-3 978-0-8176-8316-0},
	url = {http://link.springer.com/10.1007/978-0-8176-8316-0},
	language = {en},
	urldate = {2016-09-12},
	publisher = {Birkh{\"a}user Boston},
	editor = {Kutyniok, Gitta and Labate, Demetrio},
	year = {2012},
}

@book{hofmann_mathematik_1999,
	title = {Mathematik inverser {Probleme}},
	publisher = {BG Teubner},
	author = {Hofmann, B.},
	year = {1999}
}

@article{natterer_error_2004,
	title = {An error bound for the {\textbackslash}{uppercaseBorn} approximation},
	volume = {20},
	journal = {Inverse Problems},
	author = {Natterer, F.},
	year = {2004},
	pages = {447--452}
}

@article{de_hoop_local_2012,
	title = {Local analysis of inverse problems: {\textbackslash}{uppercaseH{\"o}lder} stability and iterative reconstruction},
	volume = {28},
	number = {4},
	journal = {Inverse Problems},
	author = {de Hoop, M. V. and Qiu, L. and Scherzer, O.},
	year = {2012},
	pages = {045001}
}

@book{cruz-uribe_variable_2013,
	title = {Variable {Lebesgue} {Spaces}: {Foundations} and {Harmonic} {Analysis}},
	publisher = {Springer Science \& Business Media},
	author = {Cruz-Uribe, David and Fiorenza, Alberto},
	year = {2013},
}

@article{chambolle_algorithm_2004,
	title = {An {Algorithm} for {Total} {Variation} {Minimization} and {Applications}},
	volume = {20},
	issn = {0924-9907, 1573-7683},
	url = {http://link.springer.com/article/10.1023/B%3AJMIV.0000011325.36760.1e},
	doi = {10.1023/B:JMIV.0000011325.36760.1e},
	abstract = {We propose an algorithm for minimizing the total variation of an image, and provide a proof of convergence. We show applications to image denoising, zooming, and the computation of the mean curvature motion of interfaces.},
	language = {en},
	number = {1-2},
	urldate = {2016-09-24},
	journal = {Journal of Mathematical Imaging and Vision},
	author = {Chambolle, Antonin},
	month = jan,
	year = {2004},
	keywords = {optimization, primal-dual, total variation},
	pages = {89--97},
}

@article{reginska_conditional_2009,
	title = {Conditional stability estimates and regularization with applications to {\textbackslash}{uppercaseCauchy} problems for the {\textbackslash}{uppercaseHelmholtz} equation},
	volume = {30},
	number = {9-10},
	journal = {Numerical Functional Analysis and Optimization},
	author = {Regi{\'n}ska, T. and Tautenhahn, U.},
	year = {2009},
	pages = {1065--1097}
}

@article{mariani_simulation_2011,
	title = {Simulation and correction of electron images of tilted planar weak-phase samples},
	volume = {174},
	number = {2},
	journal = {Journal of Structural Biology},
	author = {Mariani, V. and Schenk, A. D. and Philippsen, A. and Engel, A.},
	year = {2011},
	pages = {259--268}
}

@book{aubin_applied_2000,
	title = {Applied functional analysis},
	volume = {47},
	publisher = {Wiley-Interscience},
	author = {Aubin, J. P.},
	year = {2000}
}

@article{dahmen_matched_2015,
	title = {Matched {Backprojection} {Operator} for {Combined} {Scanning} {Transmission} {Electron} {Microscopy} {Tilt}- and {Focal} {Series}},
	volume = {21},
	issn = {1431-9276, 1435-8115},
	url = {https://www.cambridge.org/core/journals/microscopy-and-microanalysis/article/matched-backprojection-operator-for-combined-scanning-transmission-electron-microscopy-tilt-and-focal-series/228B21C092E99E2F4C510C30F843C1CC},
	doi = {10.1017/S1431927615000525},
	abstract = {AbstractCombined tilt- and focal series scanning transmission electron microscopy is a recently developed method to obtain nanoscale three-dimensional (3D) information of thin specimens. In this study, we formulate the forward projection in this acquisition scheme as a linear operator and prove that it is a generalization of the Ray transform for parallel illumination. We analytically derive the corresponding backprojection operator as the adjoint of the forward projection. We further demonstrate that the matched backprojection operator drastically improves the convergence rate of iterative 3D reconstruction compared to the case where a backprojection based on heuristic weighting is used. In addition, we show that the 3D reconstruction is of better quality.},
	number = {3},
	urldate = {2016-10-11},
	journal = {Microscopy and Microanalysis},
	author = {Dahmen, Tim and Kohr, Holger and Jonge, Niels de and Slusallek, Philipp},
	month = jun,
	year = {2015},
	keywords = {electron microscopy, iterative reconstruction, stem imaging, tomography},
	pages = {725--738},
}

@article{knopp_note_2007,
	title = {A {Note} on the {Iterative} {\textbackslash}{uppercaseMRI} {Reconstruction} from {Nonuniform} k-{Space} {Data}},
	volume = {2007},
	journal = {International Journal of Biomedical Imaging},
	author = {Knopp, T and Kunis, S and Potts, D.},
	year = {2007}
}

@article{lucic_structural_2005,
	title = {Structural studies by electron tomography: from cells to molecules},
	volume = {74},
	journal = {Annu. Rev. Biochem.},
	author = {Lu{\v c}i{\v c}, V. and F{\"o}rster, F. and Baumeister, W.},
	year = {2005},
	pages = {833--865}
}

@article{li_swimming_2016,
	title = {Swimming {Microrobot} {Optical} {Nanoscopy}},
	issn = {1530-6984, 1530-6992},
	url = {http://pubs.acs.org/doi/abs/10.1021/acs.nanolett.6b03303},
	doi = {10.1021/acs.nanolett.6b03303},
	language = {en},
	urldate = {2016-09-20},
	journal = {Nano Letters},
	author = {Li, Jinxing and Liu, Wenjuan and Li, Tianlong and Rozen, Isaac and Zhao, Jason and Bahari, Babak and Kante, Boubacar and Wang, Joseph},
	month = sep,
	year = {2016},
}

@phdthesis{jonas_rekonstruktion_2003,
	title = {Rekonstruktion von {Phasenobjekten} mit {Hilfe} holographischer {R{\"o}ntgentomographie}},
	school = {Universit{\"a}t des Saarlandes},
	author = {Jonas, Peter},
	year = {2003},
}

@article{lewitt_multidimensional_1990,
	title = {Multidimensional digital image representation using generalized {\textbackslash}{uppercaseKaiser}-{\textbackslash}{uppercaseBessel} window functions},
	volume = {7},
	number = {10},
	journal = {Journal of the Optical Society of America A-Optics Image Science and Vision},
	author = {Lewitt, R. M.},
	year = {1990},
	pages = {1834--1846}
}

@article{cunningham_signal_1992,
	title = {Signal and noise in modulation transfer function determinations using the slit, wire, and edge techniques},
	volume = {19},
	number = {4},
	journal = {Medical Physics},
	author = {Cunningham, I. A. and Reid, B. K.},
	year = {1992},
	pages = {1037--1044}
}

@article{chan_nonlinear_1999,
	title = {A nonlinear primal-dual method for total variation-based image restoration},
	volume = {20},
	number = {6},
	journal = {SIAM journal on scientific computing},
	author = {Chan, T. F. and Golub, G. H. and Mulet, P.},
	year = {1999},
	pages = {1964--1977}
}

@book{hardy_inequalities_1952,
	title = {Inequalities},
	publisher = {Cambridge University Press},
	author = {Hardy, G. H. and Littlewood, J. E. and P{\'o}lya, G.},
	year = {1952}
}

@article{kohr_linear_2013,
	title = {A linear regularization scheme for inverse problems with unbounded linear operators on {Banach} spaces},
	volume = {29},
	url = {http://stacks.iop.org/0266-5611/29/i=6/a=065015},
	abstract = {This paper extends the linear regularization scheme known as the approximate inverse to unbounded linear operators on Banach spaces. The principle of feature reconstruction is adapted from bounded operators to the unbounded scenario and, in addition, a new situation is examined where the data need to be pre-processed to fit into the mathematical model. In all these cases, invariance and regularization properties are surveyed and established for the example of fractional differentiation. Numerical results confirm the derived characteristics of the presented methods.},
	number = {6},
	journal = {Inverse Problems},
	author = {Kohr, H.},
	year = {2013},
	pages = {065015}
}

@book{hormander_analysis_2009,
	address = {Berlin, Heidelberg},
	series = {Classics in {Mathematics}},
	title = {The {Analysis} of {Linear} {Partial} {Differential} {Operators} {IV}},
	isbn = {978-3-642-00117-8 978-3-642-00136-9},
	url = {http://link.springer.com/10.1007/978-3-642-00136-9},
	urldate = {2016-09-12},
	publisher = {Springer Berlin Heidelberg},
	author = {H{\"o}rmander, Lars},
	year = {2009},
}

@article{werner_beugungsprobleme_1963,
	title = {Beugungsprobleme der mathematischen {Akustik}},
	volume = {12},
	journal = {Archive for Rational Mechanics and Analysis},
	author = {Werner, P.},
	year = {1963},
	pages = {155--184}
}

@article{louis_combining_2008,
	title = {Combining {Image} {Reconstruction} and {Image} {Analysis} with an {Application} to {Two}-{Dimensional} {Tomography}},
	volume = {1},
	journal = {SIAM Journal on Imaging Sciences},
	author = {Louis, A. K.},
	year = {2008},
	pages = {188}
}

@article{bertero_image_2009,
	title = {Image deblurring with {\textbackslash}{uppercasePoisson} data: from cells to galaxies},
	volume = {25},
	number = {12},
	journal = {Inverse Problems},
	author = {Bertero, M. and Boccacci, P. and Desidera, G. and Vicidomini, G.},
	year = {2009},
	pages = {123006}
}

@article{lupini_three-dimensional_2011,
	title = {The {Three}-{Dimensional} {Point} {Spread} {Function} of {Aberration}-{Corrected} {Scanning} {Transmission} {Electron} {Microscopy}},
	volume = {17},
	issn = {1435-8115, 1431-9276},
	url = {https://www.cambridge.org/core/journals/microscopy-and-microanalysis/article/the-three-dimensional-point-spread-function-of-aberration-corrected-scanning-transmission-electron-microscopy/B8B447B758044C05DAD074CEF088E641},
	doi = {10.1017/S1431927611011913},
	abstract = {AbstractAberration correction reduces the depth of field in scanning transmission electron microscopy (STEM) and thus allows three-dimensional (3D) imaging by depth sectioning. This imaging mode offers the potential for sub-{\r A}ngstrom lateral resolution and nanometer-scale depth sensitivity. For biological samples, which may be many microns across and where high lateral resolution may not always be needed, optimizing the depth resolution even at the expense of lateral resolution may be desired, aiming to image through thick specimens. Although there has been extensive work examining and optimizing the probe formation in two dimensions, there is less known about the probe shape along the optical axis. Here the probe shape is examined in three dimensions in an attempt to better understand the depth resolution in this mode. Examples are presented of how aberrations change the probe shape in three dimensions, and it is found that off-axial aberrations may need to be considered for focal series of large areas. It is shown that oversized or annular apertures theoretically improve the vertical resolution for 3D imaging of nanoparticles. When imaging nanoparticles of several nanometer size, regular STEM can thereby be optimized such that the vertical full-width at half-maximum approaches that of the aberration-corrected STEM with a standard aperture.},
	number = {5},
	urldate = {2016-10-24},
	journal = {Microscopy and Microanalysis},
	author = {Lupini, Andrew R. and de Jonge, Niels},
	month = oct,
	year = {2011},
	keywords = {electron microscopy, stem imaging, tomography},
	pages = {817--826},
}

@article{meyer_characterisation_2000,
	title = {Characterisation of the {Signal} and {Noise} {Transfer} of {\textbackslash}{uppercaseCCD} {Cameras} for {Electron} {Detection}},
	volume = {49},
	journal = {Microscopy Research and Technique},
	author = {Meyer, R. R. and Kirkland, A. I.},
	year = {2000},
	pages = {269--280}
}

@article{hoppe_endlichkeitspostulat_1969,
	title = {Das {Endlichkeitspostulat} und das {Interpolationstheorem} der dreidimensionalen elektronenmikroskopischen {Analyse} aperiodischer {Strukturen}},
	volume = {29},
	journal = {Optik},
	author = {Hoppe, W},
	year = {1969},
	keywords = {resolution},
	pages = {617--621}
}

@article{frigo_design_2005,
	title = {The {Design} and {Implementation} of {FFTW}3},
	volume = {93},
	number = {2},
	journal = {Proceedings of the IEEE},
	author = {Frigo, Matteo and Johnson, Steven G.},
	year = {2005},
	note = {Special issue on {\textquotedblleft}Program Generation, Optimization, and Platform Adaptation{\textquotedblright}},
	pages = {216--231}
}

@article{groh_improved_2012,
	title = {Improved solution methods for an inverse problem related to a population balance model in chemical engineering},
	volume = {28},
	journal = {Inverse Problems},
	author = {Groh, A. and Krebs, J.},
	year = {2012},
	pages = {085006}
}

@article{garduno_optimization_2004,
	title = {Optimization of basis functions for both reconstruction and visualization},
	volume = {139},
	number = {1-3},
	journal = {Discrete Applied Mathematics},
	author = {Gardu{\~n}o, E. and Herman, G. T.},
	year = {2004},
	pages = {95--111}
}

@article{boothroyd_why_1998,
	title = {Why don't high-resolution simulations and images match?},
	volume = {190},
	journal = {Journal of Microscopy},
	author = {Boothroyd, C. B.},
	year = {1998},
	pages = {99--108}
}

@book{bauschke_fixed-point_2011,
	address = {New York, NY},
	series = {Springer {Optimization} and {Its} {Applications}},
	title = {Fixed-{Point} {Algorithms} for {Inverse} {Problems} in {Science} and {Engineering}},
	volume = {49},
	isbn = {978-1-4419-9568-1 978-1-4419-9569-8},
	url = {http://link.springer.com/10.1007/978-1-4419-9569-8},
	urldate = {2016-09-12},
	publisher = {Springer New York},
	editor = {Bauschke, Heinz H. and Burachik, Regina S. and Combettes, Patrick L. and Elser, Veit and Luke, D. Russell and Wolkowicz, Henry},
	year = {2011},
}

@article{van_zwet_measurement_1996,
	title = {Measurement of the modulation transfer function of a slow-scan {\textbackslash}{uppercaseCCD} camera on a {\textbackslash}{uppercaseTEM} using a thin amorphous film as test signal},
	volume = {64},
	number = {1-4},
	journal = {Ultramicroscopy},
	author = {van Zwet, E. J. and Zandbergen, H. W.},
	year = {1996},
	pages = {49--55}
}

@article{smith_practical_1977,
	title = {Practical and mathematical aspects of the problem of reconstructing objects from radiographs},
	volume = {83},
	number = {6},
	journal = {Bulletin of the American Mathematical Society},
	author = {Smith, K. T. and Solmon, D. C. and Wagner, S. L.},
	year = {1977},
	pages = {1227--1270}
}

@book{scherzer_variational_2009,
	address = {New York, NY},
	series = {Applied {Mathematical} {Sciences}},
	title = {Variational {Methods} in {Imaging}},
	volume = {167},
	isbn = {978-0-387-30931-6 978-0-387-69277-7},
	url = {http://link.springer.com/10.1007/978-0-387-69277-7},
	language = {en},
	urldate = {2016-09-12},
	publisher = {Springer New York},
	author = {Scherzer, Otmar and Grasmair, Markus and Grossauer, Harald and Haltmeier, Markus and Lenzen, Frank},
	year = {2009},
}

@article{hegerl_uppercaseem_1996,
	title = {The {\textbackslash}{uppercaseEM} program package: a platform for image processing in biological electron microscopy},
	volume = {116},
	issn = {1047-8477},
	number = {1},
	journal = {Journal of Structural Biology},
	author = {Hegerl, R.},
	year = {1996},
	pages = {30--34}
}

@article{penczek_double-tilt_1995-1,
	title = {Double-tilt electron tomography},
	volume = {60},
	number = {3},
	journal = {Ultramicroscopy},
	author = {Penczek, P. and Marko, M. and Buttle, K. and Frank, J.},
	year = {1995},
	pages = {393}
}

@article{quinto_local_2008-1,
	title = {A local algorithm for {Slant} {Hole} {\textbackslash}{uppercaseSPECT}},
	journal = {Mathematical Methods in Biomedical Imaging and Intensity-Modulated Radiation Therapy (IMRT)},
	author = {Quinto, E. T. and Bakhos, T. and Chung, S.},
	year = {2008},
	pages = {321--348}
}

@book{samko_fractional_1993,
	title = {Fractional {Integrals} and {Derivatives}: {Theory} and {Applications}},
	publisher = {CRC},
	author = {Samko, S. G. and Kilbas, A. A. and Marichev, O. I.},
	year = {1993}
}

@article{kimmel_regularized_2003,
	title = {Regularized {\textbackslash}{uppercaseLaplacian} zero crossings as optimal edge integrators},
	volume = {53},
	number = {3},
	journal = {International Journal of Computer Vision},
	author = {Kimmel, R. and Bruckstein, A. M.},
	year = {2003},
	pages = {225--243}
}

@inproceedings{kohr_mathematics_2014,
	title = {Mathematics of {\textbackslash}{uppercaseSTEM} tomography},
	volume = {11},
	booktitle = {Oberwolfach {Reports} 2014},
	publisher = {EMS},
	author = {Kohr, H},
	year = {2014},
	pages = {2080--82}
}

@article{solmon_uppercasex-ray_1976,
	title = {The {\textbackslash}{uppercaseX}-ray transform},
	volume = {56},
	journal = {Journal of Mathematical Analysis and Applications},
	author = {Solmon, D. C.},
	year = {1976},
	pages = {61--83}
}

@article{grohs_anisotropic_2015,
	title = {Anisotropic {Multiscale} {Systems} on {Bounded} {Domains}},
	url = {http://arxiv.org/abs/1510.04538},
	abstract = {In this paper we provide a construction of multiscale systems on a bounded domain \${\textbackslash}Omega {\textbackslash}subset {\textbackslash}mathbb\{R\}{\textasciicircum}2\$ coined boundary shearlet systems, which satisfy several properties advantageous for applications to imaging science and numerical analysis of partial differential equations. More precisely, we construct boundary shearlet systems that form frames for \$L{\textasciicircum}2({\textbackslash}Omega)\$ with controllable frame bounds and admit optimally sparse approximations for functions, which are smooth apart from a curve-like discontinuity. We show that the constructed systems allow for boundary conditions. Furthermore, for \$s {\textbackslash}geq 0\$ and \$f{\textbackslash}in H{\textasciicircum}s({\textbackslash}Omega)\$ we prove that weighted \${\textbackslash}ell{\textasciicircum}2\$ norms of the analysis coefficients of \$f\$ are equivalent to its \$H{\textasciicircum}s({\textbackslash}Omega)\$ norm. This yields in particular, that the reweighted systems are frames for \$H{\textasciicircum}\{-s\}({\textbackslash}Omega)\$. Moreover, we demonstrate numerically, that the associated synthesis operator is also stable as a map to \$H{\textasciicircum}s({\textbackslash}Omega)\$ which, in combination with the previous result, strongly indicates that these systems even constitute so-called Gelfand frames for \$(H{\textasciicircum}s({\textbackslash}Omega), L{\textasciicircum}2({\textbackslash}Omega), H{\textasciicircum}\{-s\}({\textbackslash}Omega))\$.},
	urldate = {2016-10-11},
	journal = {arXiv:1510.04538 [math]},
	author = {Grohs, Philipp and Kutyniok, Gitta and Ma, Jackie and Petersen, Philipp},
	month = oct,
	year = {2015},
	note = {arXiv: 1510.04538},
}

@article{hamaker_angles_1978,
	title = {The angles between the null spaces of {\textbackslash}{uppercaseX} rays},
	volume = {62},
	number = {1},
	journal = {Journal of Mathematical Analysis and Applications},
	author = {Hamaker, C. and Solmon, D. C.},
	year = {1978},
	pages = {1--23}
}

@article{pelt_method_nodate,
	title = {A method for locally approximating regularized iterative tomographic reconstruction methods},
	abstract = {In many applications of tomography, the acquired projections are either limited in number or contain a significant amount of noise. In these cases, standard reconstruction methods tend to produce artifacts that can make further analysis difficult. Advanced regularized iterative methods, such as total variation minimization, are often able to achieve a higher reconstruction quality by exploiting prior knowledge about the scanned object. In practice, however, these methods often have prohibitively long computation times or large memory requirements. Furthermore, since they are based on minimizing a global objective function, regularized iterative methods need to reconstruct the entire scanned object, even when one is only interested in a (small) region of the reconstructed image. In this paper, we present a method to approximate regularized iterative reconstruction methods inside a (small) region of the scanned object. The method only performs computations inside the region of interest, ensuring low computational requirements. Reconstruction results for different phantom images and types of regularization are given, showing that reconstructions of the proposed local method are almost identical to those of the global regularized iterative methods that are approximated, even for relatively small regions of interest. Furthermore, we show that larger regions can be reconstructed efficiently by reconstructing several small regions in parallel and combining them into a single reconstruction afterwards.},
	author = {Pelt, Dani{\"e}l M. and Batenburg, K. Joost},
}

@article{tanaka_quantitative_1983,
	title = {Quantitative image reconstruction with weighted backprojection for single photon emission computed tomography},
	volume = {7},
	number = {4},
	journal = {Journal of Computer Assisted Tomography},
	author = {Tanaka, E.},
	year = {1983},
	pages = {692--700}
}

@book{reimer_transmission_1997,
	edition = {4th ed.},
	title = {Transmission electron microscopy : {Physics} of image formation and microanalysis},
	publisher = {Springer},
	author = {Reimer, L.},
	year = {1997}
}

@article{medalia_organization_2007,
	title = {Organization of actin networks in intact filopodia},
	volume = {17},
	number = {1},
	journal = {Current Biology},
	author = {Medalia, O. and {others}},
	year = {2007},
	pages = {79--84}
}

@article{owen_alignment_1996,
	title = {Alignment of electron tomographic series by correlation without the use of gold particles},
	volume = {63},
	number = {1},
	journal = {Ultramicroscopy},
	author = {Owen, C. H. and Landis, W. J.},
	year = {1996},
	pages = {27--38}
}

@book{newton_quantum_2002,
	series = {Graduate {Texts} in {Contemporary} {Physics}},
	title = {Quantum {Physics}: {A} {Text} for {Graduate} {Students}},
	publisher = {Springer},
	author = {Newton, R. G.},
	year = {2002}
}

@article{kremer_computer_1996-1,
	title = {Computer visualization of three-dimensional image data using {\textbackslash}{uppercaseIMOD}},
	volume = {116},
	number = {1},
	journal = {Journal of Structural Biology},
	author = {Kremer, J. R. and {others}},
	year = {1996},
	pages = {71--76}
}

@incollection{sorzano_interchanging_2014,
	series = {Applied and {Numerical} {Harmonic} {Analysis}},
	title = {Interchanging {Geometry} {Conventions} in 3DEM: {Mathematical} {Context} for the {Development} of {Standards}},
	copyright = {{\textcopyright}2014 Springer Science+Business Media New York},
	isbn = {978-1-4614-9520-8 978-1-4614-9521-5},
	shorttitle = {Interchanging {Geometry} {Conventions} in 3DEM},
	url = {http://link.springer.com/chapter/10.1007/978-1-4614-9521-5_2},
	abstract = {The specification of the information on the three-dimensional orientation of an image with respect to a given coordinate system is at the heart of our ability to reconstruct a three-dimensional object from sets of its two-dimensional projection images. Transferring this information from one package to another is important to structural biologists wanting to get the best from each software suite. In this chapter, we review in depth the main considerations and implications associated with the unambiguous specification of geometrical specifications, in this way paving the way to the future specifications of standards in the field of three-dimensional electron microscopy. This is the case of EMX in which affine transformations have been adopted as the means to communicate geometrical information.},
	language = {en},
	urldate = {2016-10-24},
	booktitle = {Computational {Methods} for {Three}-{Dimensional} {Microscopy} {Reconstruction}},
	publisher = {Springer New York},
	author = {Sorzano, C. O. S. and Marabini, R. and Vargas, J. and Ot{\'o}n, J. and Cuenca-Alba, J. and Quintana, A. and Rosa-Trev{\'i}n, J. M. de la and Carazo, J. M.},
	editor = {Herman, Gabor T. and Frank, Joachim},
	year = {2014},
	note = {DOI: 10.1007/978-1-4614-9521-5\_2},
	pages = {7--42},
}

@article{pan_unified_2004,
	title = {A unified analysis of {FBP}-based algorithms in helical cone-beam and circular cone- and fan-beam scans},
	volume = {49},
	issn = {0031-9155},
	url = {http://stacks.iop.org/0031-9155/49/i=18/a=011},
	doi = {10.1088/0031-9155/49/18/011},
	abstract = {A circular scanning trajectory is and will likely remain a popular choice of trajectory in computed tomography (CT) imaging because it is easy to implement and control. Filtered-backprojection (FBP)-based algorithms have been developed previously for approximate and exact reconstruction of the entire image or a region of interest within the image in circular cone-beam and fan-beam cases. Recently, we have developed a 3D FBP-based algorithm for image reconstruction on PI-line segments in a helical cone-beam scan. In this work, we demonstrated that the 3D FBP-based algorithm indeed provided a rather general formulation for image reconstruction from divergent projections (such as cone-beam and fan-beam projections). On the basis of this formulation we derived new approximate or exact algorithms for image reconstruction in circular cone-beam or fan-beam scans, which can be interpreted as special cases of the helical scan. Existing algorithms corresponding to the derived algorithms were identified. We also performed a preliminary numerical study to verify our theoretical results in each of the cases. The results in the work can readily be generalized to other non-circular trajectories.},
	language = {en},
	number = {18},
	urldate = {2016-10-31},
	journal = {Physics in Medicine and Biology},
	author = {Pan, Xiaochuan and Xia, Dan and Zou, Yu and Yu, Lifeng},
	year = {2004},
	keywords = {cone beam geometry, fan beam geometry, tomography},
	pages = {4349},
}

@article{grigorieff_three-dimensional_1998,
	title = {Three-dimensional structure of bovine {NADH}:ubiquinone oxidoreductase (complex {I}) at 22 {\r A} in ice},
	volume = {277},
	issn = {0022-2836},
	url = {http://www.sciencedirect.com/science/article/pii/S0022283698916680},
	doi = {10.1006/jmbi.1998.1668},
	abstract = {NADH:ubiquinone oxidoreductase (complex I) is the first and largest complex in the electron transport chain of mitochondria. The bovine complex purified from cardiac muscle consists of at least 42 different subunits with a combined molecular mass of about 890 kDa. The three-dimensional structure of the complex was determined at 22 {\r A} from single particles embedded in vitrified ice using electron cryo-microscopy. The structure was calculated using a new program to align particles, to correct for the contrast transfer function of the microscope, and to carry out the three-dimensional reconstruction of the complex. The bovine complex has the overall L-shaped appearance found in earlier studies of the closely related complex I from Neurospora crassa, but it differs by having a thin stalk region linking the membrane-bound globular arm with the intrinsic membrane domain. Thus, the stalk which measures about 30 {\r A} in diameter is likely to contain part of the electron transfer pathway linking the \{NADH\} binding site in the globular arm with the ubiquinone binding site in the membrane domain. The globular domain of bovine complex I is significantly bigger than that of the N. crassa enzyme, suggesting that the apparent additional subunit complexity of the bovine enzyme is associated with the globular part.},
	number = {5},
	journal = {Journal of Molecular Biology},
	author = {Grigorieff, N.},
	year = {1998},
	pages = {1033--1046}
}

@incollection{rottman_mobile_2015,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Mobile {C}-arm 3D {Reconstruction} in the {Presence} of {Uncertain} {Geometry}},
	copyright = {{\textcopyright}2015 Springer International Publishing Switzerland},
	isbn = {978-3-319-24570-6 978-3-319-24571-3},
	url = {http://link.springer.com/chapter/10.1007/978-3-319-24571-3_83},
	abstract = {Computed tomography (CT) is a widely used medical technology. Adding 3D imaging to a mobile fluoroscopic C-arm reduces the cost of CT, as a mobile C-arm is much less expensive than a dedicated CT scanner. In this paper we explore the technical challenges to implementing 3D reconstruction on these devices. One of the biggest challenges is the problem of uncertain geometry; mobile C-arms do not have the same geometric consistency that exists in larger dedicated CT scanners. The geometric parameters of an acquisition scan are therefore uncertain, and a na{\"i}ve reconstruction with these incorrect parameters leads to poor image quality. Our proposed method reconstructs the 3D image using the expectation maximization (EM) framework while jointly estimating the true geometry, thereby improving the feasibility of 3D imaging on mobile C-arms.},
	language = {en},
	number = {9350},
	urldate = {2016-10-21},
	booktitle = {Medical {Image} {Computing} and {Computer}-{Assisted} {Intervention} -- {MICCAI} 2015},
	publisher = {Springer International Publishing},
	author = {Rottman, Caleb and McBride, Lance and Cheryauka, Arvidas and Whitaker, Ross and Joshi, Sarang},
	editor = {Navab, Nassir and Hornegger, Joachim and Wells, William M. and Frangi, Alejandro F.},
	month = oct,
	year = {2015},
	note = {DOI: 10.1007/978-3-319-24571-3\_83},
	pages = {692--699},
}

@incollection{luther_sample_2006,
	title = {Sample {Shrinkage} and {Radiation} {Damage} of {Plastic} {Sections}},
	booktitle = {Electron tomography : methods for three-dimensional visualization of structures in the cell},
	publisher = {Springer},
	author = {Luther, P. K.},
	editor = {Frank, J.},
	year = {2006},
	pages = {39--60}
}

@article{louis_inversion_2011,
	title = {Inversion algorithms for the spherical {\textbackslash}{uppercaseRadon} and cosine transform},
	volume = {27},
	journal = {Inverse Problems},
	author = {Louis, A. K. and Riplinger, M. and Spiess, M. and Spodarev, E.},
	year = {2011},
	pages = {035015}
}

@article{parikh_proximal_2014,
	title = {Proximal {Algorithms}},
	volume = {1},
	issn = {2167-3888},
	url = {https://dl.acm.org/citation.cfm?id=2693613},
	doi = {10.1561/2400000003},
	abstract = {This monograph is about a class of optimization algorithms called proximal algorithms. Much like Newton's method is a standard tool for solving unconstrained smooth optimization problems of modest size, proximal algorithms can be viewed as an analogous tool for nonsmooth, constrained, large-scale, or distributed versions of these problems. They are very generally applicable, but are especially well-suited to problems of substantial recent interest involving large or high-dimensional datasets. Proximal methods sit at a higher level of abstraction than classical algorithms like Newton's method: the base operation is evaluating the proximal operator of a function, which itself involves solving a small convex optimization problem. These subproblems, which generalize the problem of projecting a point onto a convex set, often admit closed-form solutions or can be solved very quickly with standard or simple specialized methods. Here, we discuss the many different interpretations of proximal operators and algorithms, describe their connections to many other topics in optimization and applied mathematics, survey some popular algorithms, and provide a large number of examples of proximal operators that commonly arise in practice.},
	number = {3},
	journal = {Foundations and Trends in Optimization},
	author = {Parikh, Neil and Boyd, Stephen},
	month = jan,
	year = {2014},
	pages = {127--239},
}

@phdthesis{mathews_four-dimensional_2014,
	address = {St. Louis},
	title = {A {Four}-{Dimensional} {Image} {Reconstruction} {Framework} for {PET} under {Arbitrary} {Geometries}},
	abstract = {Positron Emission Tomography (PET) is a functional imaging modality with applications
ranging from the treatment of cancer, studying neurological diseases and disease models.
Virtual-Pinhole PET technology improves the image quality in terms of resolution and contrast recovery. The technology calls for having a detector with smaller crystals placed near a
region of interest in a conventional whole-body PET scanner. The improvement is from the higher spatial sampling of the imaging area near the detector. A prototype half-ring PET insert built to study head-and-neck cancer imaging was extended to breast cancer imaging. We have built a prototype half-ring PET insert for head-and-neck cancer imaging applications. In the first half of this work, we extend the use of the insert to breast imaging and show that such a system provides high resolution images of breast and axillary lymph nodes while maintaining the full imaging field of view capability of a clinical PET scanner.
We are focused on designing unconventional PET geometries for specific applications. A
general purpose 4D PET reconstruction framework was created to estimate the radionuclide uptake in the subject. Quantitative estimation in PET requires precise modeling of PET physics. Data acquired in a PET scanner is well modeled as a Poisson counting process. Reconstruction given the forward model is implemented using MAP-OSEM. The framework is capable of reconstructing PET data under arbitrary position of the detector elements and
different crystal sizes. A novel symmetry finding algorithm is created to reduce the system
matrix size, without loss of resolution. The framework motivates investigation into different PET system geometries for different applications, as well as optimizing the design of PET systems. A generalized normalization procedure was developed to model unknown components. The programs are parallelized using OpenMP and MPI to run on small workstations as well as supercomputing clusters. The performance of our reconstruction framework is
presented through four novel and unconventional PET systems, each designed specifically for a different geometry. The Virtual-Pinhole half-ring system is a half-ring insert integrated into a Siemens Biograph-40, for head and neck imaging. The Flat-panel system is a modular insert system integrated into the Biograph-40, designed for breast cancer imaging. The MicroInsert II is the second generation full ring insert device, integrated into the MicroPET scanner to improve the resolution and contrast recovery of the MicroPET scanner. The Plant PET system is a PET system designed to image plants vertically, and integrated into a plant growth chamber. The improvement in speed/memory from symmetry finding is as high as a factor of 50 in some cases. Further improvements to the framework and state of
the field are also discussed.},
	school = {Washington University},
	author = {Mathews, Aswin John},
	year = {2014},
}

@book{kriegl_convenient_1997,
	series = {Mathematical {Surveys} and {Monographs}},
	title = {The {Convenient} {Setting} of {Global} {Analysis}},
	url = {http://bookstore.ams.org/surv-53/},
	abstract = {This book lays the foundations of differential calculus in infinite dimensions and discusses those applications in infinite dimensional differential geometry and global analysis not involving Sobolev completions and fixed point theory. The approach is simple: a mapping is called smooth if it maps smooth curves to smooth curves. Up to Fr{\'e}chet spaces, this notion of smoothness coincides with all known reasonable concepts. In the same spirit, calculus of holomorphic mappings (including Hartogs' theorem and holomorphic uniform boundedness theorems) and calculus of real analytic mappings are developed. Existence of smooth partitions of unity, the foundations of manifold theory in infinite dimensions, the relation between tangent vectors and derivations, and differential forms are discussed thoroughly. Special emphasis is given to the notion of regular infinite dimensional Lie groups. Many applications of this theory are included: manifolds of smooth mappings, groups of diffeomorphisms, geodesics on spaces of Riemannian metrics, direct limit manifolds, perturbation theory of operators, and differentiability questions of infinite dimensional representations.},
	number = {53},
	urldate = {2016-09-12},
	publisher = {American Mathematical Society},
	author = {Kriegl, Andreas and Michor, Peter W.},
	year = {1997},
}

@inproceedings{bertero_iterative_2008,
	title = {Iterative image reconstruction: a point of view},
	booktitle = {Proceedings of the {Interdisciplinary} {Workshop} on {Mathematical} {Methods} in {Biomedical} {Imaging} and {Intensity}-{Modulated} {Radiation} ({IMRT}), {Pisa}, {Italy}},
	author = {Bertero, M. and {others}},
	editor = {{Y. Censor} and {M. Jiang} and {A. K. Louis}},
	year = {2008},
	pages = {37--63}
}

@incollection{sawatzky_em-tv_2013,
	series = {Lecture {Notes} in {Mathematics}},
	title = {{EM}-{TV} {Methods} for {Inverse} {Problems} with {Poisson} {Noise}},
	copyright = {{\textcopyright}2013 Springer International Publishing Switzerland},
	isbn = {978-3-319-01711-2 978-3-319-01712-9},
	url = {http://link.springer.com/chapter/10.1007/978-3-319-01712-9_2},
	abstract = {We address the task of reconstructing images corrupted by Poisson noise, which is important in various applications such as fluorescence microscopy (Dey et al., 3D microscopy deconvolution using Richardson-Lucy algorithm with total variation regularization, 2004), positron emission tomography (PET; Vardi et al., J Am Stat Assoc 80:8{\textendash}20, 1985), or astronomical imaging (Lant{\'e}ri and Theys, EURASIP J Appl Signal Processing 15:2500{\textendash}2513, 2005). Here we focus on reconstruction strategies combining the expectation-maximization (EM) algorithm and total variation (TV) based regularization, and present a detailed analysis as well as numerical results. Recently extensions of the well known EM/Richardson-Lucy algorithm received increasing attention for inverse problems with Poisson data (Dey et al., 3D microscopy deconvolution using Richardson-Lucy algorithm with total variation regularization, 2004; Jonsson et al., Total variation regularization in positron emission tomography, 1998; Panin et al., IEEE Trans Nucl Sci 46(6):2202{\textendash}2210, 1999). However, most of these algorithms for regularizations like TV lead to convergence problems for large regularization parameters, cannot guarantee positivity, and rely on additional approximations (like smoothed TV). The goal of this lecture is to provide accurate, robust and fast EM-TV based methods for computing cartoon reconstructions facilitating post-segmentation and providing a basis for quantification techniques. We illustrate also the performance of the proposed algorithms and confirm the analytical concepts by 2D and 3D synthetic and real-world results in optical nanoscopy and PET.},
	language = {en},
	number = {2090},
	urldate = {2016-10-05},
	booktitle = {Level {Set} and {PDE} {Based} {Reconstruction} {Methods} in {Imaging}},
	publisher = {Springer International Publishing},
	author = {Sawatzky, Alex and Brune, Christoph and K{\"o}sters, Thomas and W{\"u}bbeling, Frank and Burger, Martin},
	year = {2013},
	note = {DOI: 10.1007/978-3-319-01712-9\_2},
	pages = {71--142},
}

@book{natterer_mathematics_2001,
	series = {Classics in {Applied} {Mathematics}},
	title = {The {Mathematics} of {Computerized} {Tomography}},
	isbn = {978-0-89871-493-7},
	url = {http://epubs.siam.org/doi/book/10.1137/1.9780898719284},
	abstract = {By computerized tomography (CT) we mean the reconstruction of a function from its line or plane integrals, irrespective of the field where this technique is applied. In the early 1970s CT was introduced in diagnostic radiology and since then, many other applications of CT have become known, some of them preceding the application in radiology by many years. In this book I have made an attempt to collect some mathematics which is of possible interest both to the research mathematician who wants to understand the theory and algorithms of CT and to the practitioner who wants to apply CT in his special field of interest. I also want to present the state of the art of the mathematical theory of CT as it has developed from 1970 on. It seems that essential parts of the theory are now well understood. In the selection of the material I restricted myself{\textemdash}with very few exceptions{\textemdash}to the original problem of CT, even though extensions to other problems of integral geometry, such as reconstruction from integrals over arbitrary manifolds are possible in some cases. This is because the field is presently developing rapidly and its final shape is not yet visible. Another glaring omission is the statistical side of CT which is very important in practice and which we touch on only occasionally. The book is intended to be self-contained and the necessary mathematical background is briefly reviewed in an appendix (Chapter VII). A familiarity with the material of that chapter is required throughout the book. In the main text I have tried to be mathematically rigorous in the statement and proof of the theorems, but I do not hesitate in giving a loose interpretation of mathematical facts when this helps to understand its practical relevance. The book arose from courses on the mathematics of CT I taught at the Universities of Saarbr{\"u}cken and M{\"u}nster. I owe much to the enthusiasm and diligence of my students, many of whom did their diploma thesis with me. Thanks are due to D. C. Solmon and E. T. Quinto, who, during their stay in M{\"u}nster which has been made possible by the Humboldt{\textendash}Stiftung, not only read critically parts of the manuscript and suggested major improvements but also gave their advice in the preparation of the book. I gratefully acknowledge the help of A. Faridani, U. Heike and H. Kruse without whose support the book would never have been finished. Last but not least I want to thank Mrs I. Berg for her excellent typing. Frank Natterer M{\"u}nster, July 1985},
	urldate = {2016-09-12},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Natterer, Frank},
	month = jan,
	year = {2001},
}

@article{roseman_particle_2003,
	title = {Particle finding in electron micrographs using a fast local correlation algorithm},
	volume = {94},
	number = {3},
	journal = {Ultramicroscopy},
	author = {Roseman, A. M.},
	year = {2003},
	pages = {225--236}
}

@article{burger_convergence_2004,
	title = {Convergence rates of convex variational regularization},
	volume = {20},
	journal = {Inverse Problems},
	author = {Burger, M. and Osher, S.},
	year = {2004},
	pages = {1411--21}
}

@phdthesis{kohr_inverse_2012,
	address = {Postfach 151141, 66041 Saarbr{\"u}cken},
	title = {Inverse {Probleme} mit unbeschr{\"a}nktem {Operator} : {Theorie} und {Anwendung} in der {Elektronen}-{Tomographie}},
	url = {http://scidok.sulb.uni-saarland.de/volltexte/2012/4915},
	language = {ger},
	school = {Saarl{\"a}ndische Universit{\"a}ts- und Landesbibliothek},
	author = {Kohr, H.},
	year = {2012}
}

@book{ambrosio_functions_2000,
	series = {Oxford {Mathematical} {Monographs}},
	title = {Functions of {Bounded} {Variation} and {Free} {Discontinuity} {Problems}},
	isbn = {978-0-19-850245-6},
	abstract = {This book deals with a class of mathematical problems which involve the minimization of the sum of a volume and a surface energy and have lately been referred to as 'free discontinuity problems'. The aim of this book is twofold: The first three chapters present all the basic prerequisites for the treatment of free discontinuity and other variational problems in a systematic, general, and self-contained way. In the later chapters, the reader is introduced to the theory of free discontinuity problems, to the space of special functions of bounded variation, and is presented with a detailed analysis of the Mumford-Shah image segmentation problem. Existence, regularity and qualitative properties of solutions are explained and a survey is given on the current knowledge of this challenging mathematical problem. The theory embodies classical problems, e.g. related to phase transitions, or fracture and plasticity in continuum mechanics, as well as more recent ones like edge detection in image analysis. This book provides the reader with a solid introduction to the field, written by principle contributors to the theory.},
	publisher = {Oxford University Press},
	author = {Ambrosio, Luigi and Fusco, Nicola and Pallara, Diego},
	year = {2000}
}

@book{abramowitz_handbook_1988,
	title = {Handbook of {Mathematical} {Functions} with {Formulas}, {Graphs}, and {Mathematical} {Tables}},
	volume = {56},
	url = {http://scitation.aip.org/content/aapt/journal/ajp/56/10/10.1119/1.15378},
	urldate = {2016-09-12},
	author = {Abramowitz, Milton and Stegun, Irene A. and Romer, Robert H.},
	month = oct,
	year = {1988},
}

@article{brandt_multiphase_2001-1,
	title = {Multiphase method for automatic alignment of transmission electron microscope images using markers},
	volume = {133},
	number = {1},
	journal = {Journal of Structural Biology},
	author = {Brandt, S. and Heikkonen, J. and Engelhardt, P.},
	year = {2001},
	pages = {10--22}
}

@article{hanke_quasi-uppercasenewton_2000,
	title = {Quasi-{\textbackslash}{uppercaseNewton} {Approach} to {Nonnegative} {Image} {Restorations}},
	volume = {316},
	journal = {Linear Algebra and its Applications},
	author = {Hanke, M. and Nagy, J. G. and Vogel, C.},
	year = {2000},
	pages = {223--236}
}

@article{lindeberg_segmentation_1997,
	title = {Segmentation and {Classification} of {Edges} {Using} {Minimum} {Description} {Length} {Approximation} and {Complementary} {Junction} {Cues}},
	volume = {67},
	issn = {1077-3142},
	url = {http://www.sciencedirect.com/science/article/pii/S107731429690510X},
	doi = {10.1006/cviu.1996.0510},
	number = {1},
	journal = {Computer Vision and Image Understanding},
	author = {Lindeberg, T. and Li, M.-X.},
	year = {1997},
	pages = {88--98}
}

@article{chambolle_first-order_2010,
	title = {A {First}-{Order} {Primal}-{Dual} {Algorithm} for {Convex} {Problems} with {Applications} to {Imaging}},
	volume = {40},
	issn = {0924-9907, 1573-7683},
	url = {http://link.springer.com/article/10.1007/s10851-010-0251-1},
	doi = {10.1007/s10851-010-0251-1},
	abstract = {In this paper we study a first-order primal-dual algorithm for non-smooth convex optimization problems with known saddle-point structure. We prove convergence to a saddle-point with rate O(1/N) in finite dimensions for the complete class of problems. We further show accelerations of the proposed algorithm to yield improved rates on problems with some degree of smoothness. In particular we show that we can achieve O(1/N2) convergence on problems, where the primal or the dual objective is uniformly convex, and we can show linear convergence, i.e. O($\omega$N) for some $\omega$?(0,1), on smooth problems. The wide applicability of the proposed algorithm is demonstrated on several imaging problems such as image denoising, image deconvolution, image inpainting, motion estimation and multi-label image segmentation.},
	language = {en},
	number = {1},
	urldate = {2016-09-24},
	journal = {Journal of Mathematical Imaging and Vision},
	author = {Chambolle, Antonin and Pock, Thomas},
	month = dec,
	year = {2010},
	keywords = {convex, optimization, primal-dual, proximal, splitting},
	pages = {120--145},
}

@article{haltmeier_filtered_2005,
	title = {Filtered backprojection for thermoacoustic computed tomography in spherical geometry},
	volume = {28},
	number = {16},
	journal = {Mathematical Methods in the Applied Sciences},
	author = {Haltmeier, M. and {others}},
	year = {2005},
	pages = {1919--1938}
}

@book{goodman_introduction_2005,
	edition = {3rd},
	title = {Introduction to {Fourier} optics},
	publisher = {Roberts \& Company},
	author = {Goodman, J. W.},
	year = {2005}
}

@article{gordon_algebraic_1970,
	title = {Algebraic {Reconstruction} {Techniques} ({\textbackslash}{uppercaseART}) for three-dimensional electron microscopy and {\textbackslash}{uppercaseX}-ray photography},
	volume = {29},
	number = {3},
	journal = {Journal of Theoretical Biology},
	author = {Gordon, R. and {others}},
	year = {1970},
	pages = {471--481}
}

@article{lucet_what_2010,
	title = {What {Shape} {Is} {Your} {Conjugate}? {A} {Survey} of {Computational} {Convex} {Analysis} and {Its} {Applications}},
	volume = {52},
	issn = {0036-1445},
	shorttitle = {What {Shape} {Is} {Your} {Conjugate}?},
	url = {http://epubs.siam.org/doi/abs/10.1137/100788458},
	doi = {10.1137/100788458},
	abstract = {Computational convex analysis algorithms have been rediscovered several times in the past by researchers from different fields. To further communications between practitioners, we review the field of computational convex analysis, which focuses on the numerical computation of fundamental transforms arising from convex analysis. Current models use symbolic, numeric, and hybrid symbolic-numeric algorithms. Our objective is to disseminate widely the most efficient numerical algorithms useful for applications in image processing (computing the distance transform, the generalized distance transform, and mathematical morphology operators), partial differential equations (solving Hamilton{\textendash}Jacobi equations and using differential equations numerical schemes to compute the convex envelope), max-plus algebra (computing the equivalent of the fast Fourier transform), multifractal analysis, etc. The fields of applications include, among others, computer vision, robot navigation, thermodynamics, electrical networks, medical imaging, and network communication.},
	number = {3},
	urldate = {2016-09-12},
	journal = {SIAM Review},
	author = {Lucet, Y.},
	month = jan,
	year = {2010},
	pages = {505--542},
}

@article{hahn_reconstruction_2012,
	title = {Reconstruction in the three-dimensional parallel scanning geometry with application in synchrotron-based x-ray tomography},
	volume = {28},
	journal = {Inverse Problems},
	author = {Hahn, B. and Louis, A. K.},
	year = {2012},
	pages = {045013}
}

@article{devaney_filtered_1982,
	title = {A filtered backpropagation algorithm for diffraction tomography},
	volume = {4},
	number = {4},
	journal = {Ultrasonic Imaging},
	author = {Devaney, A. J.},
	year = {1982},
	pages = {336--350}
}

@book{hormander_analysis_1990,
	address = {Berlin, Heidelberg},
	series = {Classics in {Mathematics}},
	title = {The {Analysis} of {Linear} {Partial} {Differential} {Operators} {I}},
	isbn = {978-3-540-00662-6 978-3-642-61497-2},
	url = {http://link.springer.com/10.1007/978-3-642-61497-2},
	urldate = {2016-09-12},
	publisher = {Springer Berlin Heidelberg},
	author = {H{\"o}rmander, Lars},
	year = {1990},
}

@article{abubakar_diagonalized_2005,
	title = {The diagonalized contrast source approach: an inversion method beyond the {Born} approximation},
	volume = {21},
	issn = {0266-5611},
	shorttitle = {The diagonalized contrast source approach},
	url = {http://stacks.iop.org/0266-5611/21/i=2/a=015},
	doi = {10.1088/0266-5611/21/2/015},
	abstract = {This paper deals with the imaging and inversion of the constitutive material properties of bounded objects embedded in a known background medium. The inversion utilizes measurements of the scattered field due to the illumination of the objects by a set of known single-frequency wave fields. We present two inverse scattering methods that approximately recast the full nonlinear inversion into a number of linear inversion steps. The two methods are as computationally efficient as the constrained Born inversion but provide reconstruction results that are far superior and are almost comparable in quality to the ones obtained using a full nonlinear iterative inversion. The linear inversion steps follow what is referred to as the source-type integral equation approach in which the contrast sources are inverted for in the first step from the linear data equation. In this step, we employ a local (diagonal) approximation of the operator that relates the contrast sources to the incident field. Once the contrast sources have been determined, the total internal wave fields follow from a direct application of the object equation. In the third and final step, the contrast function is estimated from either the constitutive relation (first method) or from solving the data equation again, this time in terms of the contrast profile (second method). The computational cost required by the first method is comparable to that of a constrained Born inversion. With only twice the computational cost, the second method invariably gives an almost perfect image. We will demonstrate the two methods for a number of representative synthetic examples, both in two and three dimensions.},
	language = {en},
	number = {2},
	urldate = {2016-09-25},
	journal = {Inverse Problems},
	author = {Abubakar, Aria and Habashy, Tarek M. and van den Berg, Peter M. and Gisolf, Dries},
	year = {2005},
	pages = {685},
}

@book{kak_principles_2001,
	title = {Principles of computerized tomographic imaging},
	publisher = {SIAM},
	author = {Kak, A. and Slaney, M.},
	year = {2001}
}

@article{symes_modelling_2011,
	title = {From modelling to inversion: designing a well-adapted simulator},
	volume = {59},
	issn = {1365-2478},
	shorttitle = {From modelling to inversion},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1365-2478.2011.00977.x/abstract},
	doi = {10.1111/j.1365-2478.2011.00977.x},
	abstract = {This paper describes a few mild design constraints that permit rapid adaptation of the modelling code for linear wave propagation to imaging/inversion or design optimization applications, retaining parallelism and other performance enhancements of the underlying simulator. It also describes an abstract software framework preserving the modularity of both optimization and modelling software in building inversion applications and illustrates this possibility via an example framework implemented in C++. Wave inverse problems tend to be afflicted by a variety of features, including extreme ill-conditioning and nonlinearity, which degrade the performance of optimization formulations. Extended modelling variants of least-squares inversion, motivated by migration velocity analysis, may relieve some of these difficulties. The framework described also accommodates these extensions to standard inversion.},
	language = {en},
	number = {5},
	urldate = {2016-09-26},
	journal = {Geophysical Prospecting},
	author = {Symes, William W. and Sun, Dong and Enriquez, Marco},
	month = sep,
	year = {2011},
	keywords = {Adjoint, Born modelling, Initialization},
	pages = {814--833},
}

@book{lee_introduction_2011,
	address = {New York, NY},
	series = {Graduate {Texts} in {Mathematics}},
	title = {Introduction to {Topological} {Manifolds}},
	volume = {202},
	isbn = {978-1-4419-7939-1 978-1-4419-7940-7},
	url = {http://link.springer.com/10.1007/978-1-4419-7940-7},
	urldate = {2016-09-21},
	publisher = {Springer New York},
	author = {Lee, John M.},
	year = {2011},
}

@article{aoyama_stem_2008,
	title = {{STEM} tomography for thick biological specimens},
	volume = {109},
	issn = {0304-3991},
	url = {http://www.sciencedirect.com/science/article/pii/S0304399108002234},
	doi = {10.1016/j.ultramic.2008.08.005},
	abstract = {Scanning transmission electron microscopy (STEM) tomography was applied to biological specimens such as yeast cells, HEK293 cells and primary culture neurons. These cells, which were embedded in a resin, were cut into 1-$\mu$m-thick sections. STEM tomography offers several important advantages including: (1) it is effective even for thick specimens, (2) {\textquoteleft}dynamic focusing{\textquoteright}, (3) ease of using an annular dark field (ADF) mode and (4) linear contrasts. It has become evident that STEM tomography offers significant advantages for the observation of thick specimens. By employing STEM tomography, even a 1-$\mu$m-thick specimen (which is difficult to observe by conventional transmission electron microscopy (TEM)) was successfully analyzed in three dimensions. The specimen was tilted up to 73{\textdegree} during data acquisition. At a large tilt angle, the specimen thicknesses increase dramatically. In order to observe such thick specimens, we introduced a special small condenser aperture that reduces the collection angle of the STEM probe. The specimen damage caused by the convergent electron beam was expected to be the most serious problem; however, the damage in STEM was actually smaller than that in TEM. In this study, the irradiation damage caused by TEM- and STEM-tomography in biological specimens was quantitatively compared.},
	number = {1},
	urldate = {2016-10-24},
	journal = {Ultramicroscopy},
	author = {Aoyama, Kazuhiro and Takagi, Tomoko and Hirase, Ai and Miyazawa, Atsuo},
	month = dec,
	year = {2008},
	keywords = {electron microscopy, stem imaging, tomography},
	pages = {70--80},
}

@article{louis_picture_1980,
	title = {Picture reconstruction from projections in restricted range},
	volume = {2},
	number = {2},
	journal = {Mathematical Methods in the Applied Sciences},
	author = {Louis, A. K.},
	year = {1980},
	pages = {209--220}
}

@book{frank_electron_2006,
	address = {New York, NY},
	title = {Electron {Tomography}},
	isbn = {978-0-387-31234-7 978-0-387-69008-7},
	url = {http://link.springer.com/10.1007/978-0-387-69008-7},
	language = {en},
	urldate = {2016-10-31},
	publisher = {Springer New York},
	editor = {Frank, Joachim},
	year = {2006},
}

@book{bauschke_convex_2011,
	address = {New York, NY},
	series = {{CMS} {Books} in {Mathematics}},
	title = {Convex {Analysis} and {Monotone} {Operator} {Theory} in {Hilbert} {Spaces}},
	isbn = {978-1-4419-9466-0 978-1-4419-9467-7},
	url = {http://link.springer.com/10.1007/978-1-4419-9467-7},
	urldate = {2016-09-12},
	publisher = {Springer New York},
	author = {Bauschke, Heinz H. and Combettes, Patrick L.},
	year = {2011},
}

@article{herman_fundamentals_2009,
	title = {Fundamentals of {Computerized} {Tomography}: {Image} {Reconstruction} from {Projections}},
	author = {Herman, G. T.},
	year = {2009}
}

@article{harauz_exact_1986,
	title = {Exact filters for general geometry three dimensional reconstruction},
	volume = {73},
	issn = {0030-4026},
	url = {http://cat.inist.fr/?aModele=afficheN&cpsidt=7856923},
	language = {eng},
	number = {4},
	urldate = {2016-10-24},
	journal = {Optik},
	author = {Harauz, George and van Heel, Marin},
	year = {1986},
	keywords = {fourier shell correlation, resolution},
	pages = {146--156},
}

@article{rieder_approximate_2000,
	title = {The approximate inverse in action with an application to computerized tomography},
	volume = {37},
	number = {6},
	journal = {SIAM journal on numerical analysis},
	author = {Rieder, A and Schuster, T},
	year = {2000},
	pages = {1909--1929}
}

@book{hadamard_lectures_1923,
	title = {Lectures on {\textbackslash}{uppercaseCauchy}'s problem in linear partial differential equations},
	volume = {37},
	publisher = {Yale University Press},
	author = {Hadamard, J.},
	year = {1923}
}

@book{born_principles_1999,
	edition = {7th (expanded)},
	title = {Principles of {Optics}},
	publisher = {Cambridge University Press},
	author = {Born, M. and Wolf, E.},
	year = {1999}
}

@book{natterer_mathematical_2001,
	series = {Mathematical {Modeling} and {Computation}},
	title = {Mathematical {Methods} in {Image} {Reconstruction}},
	isbn = {978-0-89871-622-1},
	url = {http://epubs.siam.org/doi/book/10.1137/1.9780898718324},
	abstract = {Since the advent of computerized tomography in the seventies, many imaging techniques have emerged and have been introduced in radiology, science, and technology. Some of these techniques are now in routine use, most are still under development, and others are the subject of mainly academic research, their future usefulness in debate. This book makes an attempt to describe these techniques in a mathematical language, to provide the adequate mathematical background and the necessary mathematical tools. In particular, it gives a detailed analysis of numerical algorithms for image reconstruction. We concentrate on the developments of the last 10 to 15 years. Previous results are given without proof, except when new proofs are available. It is assumed that, or at least helpful if, the reader is familiar with the tomography literature of the eighties. The backbone of the theory of imaging is still integral geometry. We survey this field as far as is necessary for imaging purposes. Imaging techniques based on or related to integral geometry are briefly described in the section on tomography. In contrast, the section on algorithms is fairly detailed, at least in the two-dimensional (2D) case. In the three-dimensional (3D) case, we derive exact and approximate inversion formulas for specific imaging devices. We describe their algorithmic implementation, which largely parallels the 2D case. The development in the field of algorithms is still quite lively, in particular in the 3D area. While some fundamental principles, such as filtered backprojection, seem to be well established, much of this section may well turn out to be just a snapshot of the present scene. General trends, such as the present revival of Fourier and iterative methods, become visible. In the last part of the book we deal with imaging techniques that are usually referred to as tomography but that are only remotely related to the straight line paradigm of tomography. These can be formulated as bilinear inverse problems of partial differential equations. We give a common framework and describe simple numerical methods based on standard iterative techniques of tomography. The book is aimed at mathematicians, engineers, physicists, and other scientists with the appropriate mathematical skills who want to understand the theoretical foundations of image reconstruction and to solve concrete problems. Often the proofs are sketchy or even missing in cases in which suitable references are easily available. We hope that the readability does not suffer from these omissions, which are necessary to keep this report at a reasonable length.},
	urldate = {2016-09-12},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Natterer, Frank and W{\"u}bbeling, Frank},
	month = jan,
	year = {2001},
}

@article{maretzke_uniqueness_2015,
	title = {A uniqueness result for propagation-based phase contrast imaging from a single measurement},
	volume = {31},
	issn = {0266-5611},
	url = {http://stacks.iop.org/0266-5611/31/i=6/a=065003},
	doi = {10.1088/0266-5611/31/6/065003},
	abstract = {Phase contrast imaging seeks to reconstruct the complex refractive index of an unknown sample from scattering intensities, measured for example under illumination with coherent x-rays. By incorporating refraction, this method yields improved contrast compared to purely absorption-based radiography but involves a phase retrieval problem which, in general, allows for ambiguous reconstructions. In this paper, we show uniqueness of propagation-based phase contrast imaging for compactly supported objects in the near-field regime, based on a description by the projection- and paraxial approximations. In this setting, propagation is governed by the Fresnel propagator and the unscattered part of the illumination function provides a known reference wave at the detector which facilitates phase reconstruction. The uniqueness theorem is derived using the theory of entire functions. Unlike previous results based on exact solution formulae, it is valid for arbitrary complex objects and requires intensity measurements only at a single detector distance and illumination wavelength. We also deduce a uniqueness criterion for phase contrast tomography, which may be applied to resolve the three-dimensional structure of micro- and nano-scale samples. Moreover, our results may have some significance to electronic imaging methods due to the equivalence of paraxial wave propagation and Schr{\"o}dinger{\textquoteright}s equation.},
	language = {en},
	number = {6},
	urldate = {2016-09-29},
	journal = {Inverse Problems},
	author = {Maretzke, Simon},
	year = {2015},
	pages = {065003},
}

@article{haltmeier_filtered_2005-1,
	title = {Filtered backprojection for thermoacoustic computed tomography in spherical geometry},
	volume = {28},
	number = {16},
	journal = {Mathematical Methods in the Applied Sciences},
	author = {Haltmeier, M. and Schuster, T. and Scherzer, O.},
	year = {2005},
	pages = {1919--1938}
}

@phdthesis{hahn_rekonstruktionsverfahren_2013,
	title = {Rekonstruktionsverfahren in der dynamischen {Computertomographie}},
	school = {Universit{\"a}t des Saarlandes},
	author = {Hahn, B.},
	year = {2013}
}

@article{kazantsev_fully_2010,
	title = {Fully three-dimensional defocus-gradient corrected backprojection in cryoelectron microscopy},
	volume = {110},
	issn = {0304-3991},
	url = {http://www.sciencedirect.com/science/article/pii/S0304399110001105},
	doi = {10.1016/j.ultramic.2010.04.002},
	abstract = {Recognizing that the microscope depth of field is a significant resolution-limiting factor in 3D cryoelectron microscopy, Jensen and Kornberg proposed a concept they called defocus-gradient corrected backprojection (DGCBP) and illustrated by computer simulations that DGCBP can effectively eliminate the depth of field limitation. They did not provide a mathematical justification for their concept. Our paper provides this, by showing (in the idealized case of noiseless data being available for all projection directions) that the reconstructions obtained based on DGCBP from data produced with distance-dependent blurring are essentially the same as what is obtained by a classical method of reconstruction of a 3D object from its line integrals. The approach is general enough to be applicable for correcting for any distance-dependent blurring during projection data collection. We present a new implementation of the DGCBP concept, one that closely follows the mathematics of its justifications, and illustrate it using mathematically described phantoms and their reconstructions from finitely many distance-dependently blurred projections.},
	number = {9},
	urldate = {2016-10-31},
	journal = {Ultramicroscopy},
	author = {Kazantsev, Ivan G. and Klukowska, Joanna and Herman, Gabor T. and Cernetic, Laslo},
	month = aug,
	year = {2010},
	keywords = {defocus, electron microscopy, tomography},
	pages = {1128--1142},
}

@article{jin_hanke-raus_2016,
	title = {Hanke-{Raus} heuristic rule for variational regularization in {Banach} spaces},
	volume = {32},
	issn = {0266-5611},
	url = {http://stacks.iop.org/0266-5611/32/i=8/a=085008},
	doi = {10.1088/0266-5611/32/8/085008},
	abstract = {We generalize the heuristic parameter choice rule of Hanke-Raus for quadratic regularization to general variational regularization for solving linear as well as nonlinear ill-posed inverse problems in Banach spaces. Under source conditions formulated as variational inequalities, we obtain a posteriori error estimates in term of the Bregman distance. By imposing certain conditions on the random noise, we establish four convergence results; one relies on the source conditions and the other three do not depend on any source conditions. Numerical results are presented to illustrate the performance.},
	language = {en},
	number = {8},
	urldate = {2016-09-12},
	journal = {Inverse Problems},
	author = {Jin, Qinian},
	year = {2016},
	pages = {085008},
}

@article{louis_ghosts_1981,
	title = {Ghosts in tomography{\textendash}the null space of the {Radon} transform},
	volume = {3},
	number = {1},
	journal = {Mathematical Methods in the Applied Sciences},
	author = {Louis, A. K.},
	year = {1981},
	pages = {1--10}
}

@article{groh_efficient_2011,
	title = {Efficient solution of an inverse problem in cell population dynamics},
	volume = {27},
	journal = {Inverse Problems},
	author = {Groh, A. and Krebs, J. and Wagner, M.},
	year = {2011},
	pages = {065009}
}

@article{alber_james_2005,
	title = {James orthogonality and orthogonal decompositions of {\textbackslash}{uppercaseBanach} spaces},
	volume = {312},
	number = {1},
	journal = {Journal of Mathematical Analysis and Applications},
	author = {Alber, Y. I.},
	year = {2005},
	pages = {330--342}
}

@inproceedings{xu_multi-channel_2014,
	title = {A multi-channel image reconstruction method for grating-based {X}-ray phase-contrast computed tomography},
	volume = {9033},
	url = {http://dx.doi.org/10.1117/12.2043732},
	doi = {10.1117/12.2043732},
	abstract = {In this work, we report on the development of an advanced multi-channel (MC) image reconstruction algorithm for grating-based X-ray phase-contrast computed tomography (GB-XPCT). The MC reconstruction method we have developed operates by concurrently, rather than independently as is done conventionally, reconstructing tomographic images of the three object properties (absorption, small-angle scattering, refractive index). By jointly estimating the object properties by use of an appropriately defined penalized weighted least squares (PWLS) estimator, the 2nd order statistical properties of the object property sinograms, including correlations between them, can be fully exploited to improve the variance vs. resolution tradeoff of the reconstructed images as compared to existing methods. Channel-independent regularization strategies are proposed. To solve the MC reconstruction problem, we developed an advanced algorithm based on the proximal point algorithm and the augmented Lagrangian method. By use of experimental and computer-simulation data, we demonstrate that by exploiting inter-channel noise correlations, the MC reconstruction method can improve image quality in GB-XPCT.},
	urldate = {2016-10-31},
	author = {Xu, Qiaofeng and Sawatzky, Alex and Anastasio, Mark A.},
	year = {2014},
	pages = {90330D--90330D--9},
}

@book{peypouquet_convex_2015,
	address = {Cham},
	series = {{SpringerBriefs} in {Optimization}},
	title = {Convex {Optimization} in {Normed} {Spaces}},
	isbn = {978-3-319-13709-4 978-3-319-13710-0},
	url = {http://link.springer.com/10.1007/978-3-319-13710-0},
	urldate = {2016-09-10},
	publisher = {Springer International Publishing},
	author = {Peypouquet, Juan},
	year = {2015},
}

@article{louis_mollifier_1990,
	title = {A mollifier method for linear operator equations of the first kind},
	volume = {6},
	journal = {Inverse Problems},
	author = {Louis, A. K. and Maass, P.},
	year = {1990},
	pages = {427--440}
}

@article{lorenzi_geodesics_2013,
	title = {Geodesics, {Parallel} {Transport} \& {One}-{Parameter} {Subgroups} for {Diffeomorphic} {Image} {Registration}},
	volume = {105},
	issn = {0920-5691, 1573-1405},
	url = {http://link.springer.com/10.1007/s11263-012-0598-4},
	doi = {10.1007/s11263-012-0598-4},
	language = {en},
	number = {2},
	urldate = {2016-09-24},
	journal = {International Journal of Computer Vision},
	author = {Lorenzi, Marco and Pennec, Xavier},
	month = nov,
	year = {2013},
	keywords = {differential geometry, image registration},
	pages = {111--127},
}

@book{louis_inverse_1989,
	title = {Inverse und schlecht gestellte {Probleme}},
	publisher = {Teubner},
	author = {Louis, A. K.},
	year = {1989}
}

@article{hohage_inverse_2016,
	title = {Inverse problems with {Poisson} data: statistical regularization theory, applications and algorithms},
	volume = {32},
	issn = {0266-5611},
	shorttitle = {Inverse problems with {Poisson} data},
	url = {http://stacks.iop.org/0266-5611/32/i=9/a=093001},
	doi = {10.1088/0266-5611/32/9/093001},
	abstract = {Inverse problems with Poisson data arise in many photonic imaging modalities in medicine, engineering and astronomy. The design of regularization methods and estimators for such problems has been studied intensively over the last two decades. In this review we give an overview of statistical regularization theory for such problems, the most important applications, and the most widely used algorithms. The focus is on variational regularization methods in the form of penalized maximum likelihood estimators, which can be analyzed in a general setup. Complementing a number of recent convergence rate results we will establish consistency results. Moreover, we discuss estimators based on a wavelet-vaguelette decomposition of the (necessarily linear) forward operator. As most prominent applications we briefly introduce Positron emission tomography, inverse problems in fluorescence microscopy, and phase retrieval problems. The computation of a penalized maximum likelihood estimator involves the solution of a (typically convex) minimization problem. We also review several efficient algorithms which have been proposed for such problems over the last five years.},
	language = {en},
	number = {9},
	urldate = {2016-09-12},
	journal = {Inverse Problems},
	author = {Hohage, Thorsten and Werner, Frank},
	year = {2016},
	pages = {093001},
}

@article{canny_computational_1986,
	title = {A computational approach to edge detection},
	volume = {8},
	number = {6},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Canny, J.},
	year = {1986},
	pages = {679--698}
}

@article{grigorieff_resolution_2000,
	title = {Resolution measurement in structures derived from single particles},
	volume = {56},
	issn = {0907-4449},
	url = {http://scripts.iucr.org/cgi-bin/paper?S0907444900009549},
	doi = {10.1107/S0907444900009549},
	number = {10},
	urldate = {2016-10-31},
	journal = {Acta Crystallographica Section D Biological Crystallography},
	author = {Grigorieff, Nikolaus},
	month = oct,
	year = {2000},
	keywords = {electron microscopy, fourier shell correlation, resolution, tomography},
	pages = {1270--1277},
}

@incollection{radermacher_weighted_1992,
	edition = {1st},
	title = {Weighted {Back}-projection {Methods}},
	booktitle = {Electron {Tomography} - {Methods} for {Three}-{Dimensional} {Visualization} of {Structures} in the {Cell}},
	publisher = {Springer},
	author = {Radermacher, M.},
	editor = {Frank, J.},
	year = {1992}
}

@article{strecker_specimen_1993,
	title = {Specimen preparation for transmission electron microscopy({\textbackslash}{uppercaseTEM}){\textendash}reliable method for cross sections and brittle materials},
	volume = {30},
	number = {10},
	journal = {Practical Metallography},
	author = {Strecker, A. and {others}},
	year = {1993},
	pages = {482--495}
}

@article{louis_approximate_1996,
	title = {Approximate inverse for linear and some nonlinear problems},
	volume = {12},
	number = {2},
	journal = {Inverse Problems},
	author = {Louis, A. K.},
	year = {1996},
	pages = {175--190}
}

@article{louis_incomplete_1986,
	title = {Incomplete data problems in {\textbackslash}{uppercaseX}-ray computerized tomography. {\textbackslash}{uppercaseI}. {Singular} value decomposition of the limited angle transform},
	volume = {48},
	number = {3},
	journal = {Numerische Mathematik},
	author = {Louis, A. K.},
	year = {1986},
	pages = {251--262}
}

@article{lanzavecchia_conical_2005,
	title = {Conical tomography of freeze-fracture replicas: a method for the study of integral membrane proteins inserted in phospholipid bilayers},
	volume = {149},
	number = {1},
	journal = {Journal of Structural Biology},
	author = {Lanzavecchia, S. and Cantele, F. and Bellon, P. L. and Zampighi, L. and Kreman, M. and Wright, E. and Zampighi, G. A.},
	year = {2005},
	pages = {87--98}
}

@inproceedings{beucher_use_1979,
	title = {Use of {Watersheds} in {Contour} {Detection}},
	booktitle = {International {Workshop} on {Image} {Processing}: {Real}-time {Edge} and {Motion} {Detection}/{Estimation}, {Rennes}, {France}.},
	author = {Beucher, S. and Lantuejoul, C.},
	month = sep,
	year = {1979}
}

@article{cichocki_low-rank_2016,
	title = {Low-{Rank} {Tensor} {Networks} for {Dimensionality} {Reduction} and {Large}-{Scale} {Optimization} {Problems}: {Perspectives} and {Challenges} {PART} 1},
	shorttitle = {Low-{Rank} {Tensor} {Networks} for {Dimensionality} {Reduction} and {Large}-{Scale} {Optimization} {Problems}},
	url = {http://arxiv.org/abs/1609.00893},
	abstract = {Machine learning and data mining algorithms are becoming increasingly important in analyzing large volume, multi-relational and multi--modal datasets, which are often conveniently represented as multiway arrays or tensors. It is therefore timely and valuable for the multidisciplinary research community to review tensor decompositions and tensor networks as emerging tools for large-scale data analysis and data mining. We provide the mathematical and graphical representations and interpretation of tensor networks, with the main focus on the Tucker and Tensor Train (TT) decompositions and their extensions or generalizations. Keywords: Tensor networks, Function-related tensors, CP decomposition, Tucker models, tensor train (TT) decompositions, matrix product states (MPS), matrix product operators (MPO), basic tensor operations, multiway component analysis, multilinear blind source separation, tensor completion, linear/multilinear dimensionality reduction, large-scale optimization problems, symmetric eigenvalue decomposition (EVD), PCA/SVD, huge systems of linear equations, pseudo-inverse of very large matrices, Lasso and Canonical Correlation Analysis (CCA) (This is Part 1)},
	urldate = {2016-10-03},
	journal = {arXiv:1609.00893 [cs]},
	author = {Cichocki, A. and Lee, N. and Oseledets, I. V. and Phan, A.-H. and Zhao, Q. and Mandic, D.},
	month = sep,
	year = {2016},
	note = {arXiv: 1609.00893},
	keywords = {machine learning, neural networks, tensor},
}

@article{bohm_toward_2000,
	title = {Toward detecting and identifying macromolecules in a cellular context: {Template} matching applied to electron tomograms},
	volume = {97},
	doi = {10.1073/pnas.230282097},
	number = {26},
	journal = {Proceedings of the National Academy of Sciences},
	author = {B{\"o}hm, J. and Frangakis, A. S. and Hegerl, R. and Nickell, S. and Typke, D. and Baumeister, W.},
	year = {2000},
	pages = {14245--14250}
}

@article{vulovic_when_2014,
	title = {When to use the projection assumption and the weak-phase object approximation in phase contrast cryo-{EM}},
	volume = {136},
	issn = {0304-3991},
	url = {http://www.sciencedirect.com/science/article/pii/S0304399113002088},
	doi = {10.1016/j.ultramic.2013.08.002},
	abstract = {The projection assumption (PA) and the weak-phase object approximation (WPOA) are commonly used to model image formation in cryo-electron microscopy. For simulating the next step in resolution improvement we show that it is important to revisit these two approximations as well as their limitations. Here we start off by inspecting both approximations separately to derive their respective conditions of applicability. The thick-phase grating approximation (TPGA) imposes less strict conditions on the interaction potential than PA or WPOA and gives comparable exit waves as a multislice calculation. We suggest the ranges of applicability for four models (PA, PA+WPOA, WPOA, and TPGA) given different interaction potentials using exit wave simulations. The conditions of applicability for the models are based on two measures, a worst-case (safest) and an average criterion. This allows us to present a practical guideline for when to use each image formation model depending on the spatial frequency, thickness and strength of the interaction potential of a macromolecular complex.},
	urldate = {2016-10-31},
	journal = {Ultramicroscopy},
	author = {Vulovi{\'c}, Milo{\v s} and Voortman, Lenard M. and van Vliet, Lucas J. and Rieger, Bernd},
	month = jan,
	year = {2014},
	keywords = {electron microscopy, modeling},
	pages = {61--66},
}

@article{kohr_fast_2011,
	title = {Fast and high-quality reconstruction in electron tomography based on an enhanced linear forward model},
	volume = {27},
	url = {http://stacks.iop.org/0266-5611/27/i=4/a=045008},
	abstract = {We study single-axis electron tomography and present an improved version of the linear forward model given by Fanelli and {\"O}ktem ( 2008 Inverse Problems [/0266-5611/24/1/013001] 24 013001 ) which accounts for inelastic scattering and image distortions caused by imperfect optics. Based on the concept of approximate inverse, we derive an algorithm of filtered backprojection type which is much faster than the frequently used iterative methods. Numerical tests with simulated and measured transmission electron microscope data and comparisons with other FBP-type methods reveal that our algorithm provides reconstructions with high contrast and resolution, while the noise level is significantly reduced.},
	number = {4},
	journal = {Inverse Problems},
	author = {Kohr, H and Louis, A K},
	year = {2011},
	pages = {045008}
}

@inproceedings{welk_variational_2007,
	address = {Girona, Spain},
	title = {Variational {Deconvolution} of {Multi}-channel {Images} with {Inequality} {Constraints}},
	booktitle = {{IbPRIA} '07: {Proceedings} of the 3rd {Iberian} conference on {Pattern} {Recognition} and {Image} {Analysis}, {Part} {I}},
	publisher = {Springer},
	author = {Welk, M. and Nagy, J. G.},
	year = {2007},
	pages = {386--393}
}

@article{herman_image_1980,
	title = {Image reconstruction from projections. {The} fundamentals of computerized tomography},
	author = {Herman, G. T.},
	year = {1980}
}

@article{tautenhahn_optimal_1999,
	title = {On optimal regularization methods for fractional differentiation},
	volume = {18},
	number = {2},
	journal = {Zeitschrift f{\"u}r Analysis und ihre Anwendungen},
	author = {Tautenhahn, U. and Gorenflo, R.},
	year = {1999},
	pages = {449--468}
}

@article{de_ruijter_imaging_1995,
	title = {Imaging properties and applications of slow-scan charge-coupled device cameras suitable for electron microscopy},
	volume = {26},
	number = {3},
	journal = {Micron},
	author = {De Ruijter, W. J.},
	year = {1995},
	pages = {247--275}
}

@article{colton_inverse_2003,
	title = {Inverse {Acoustic} and {Electromagnetic} {Scattering} {Theory}},
	volume = {19},
	number = {47},
	journal = {Inverse Problems},
	author = {Colton, D.},
	year = {2003},
	pages = {67--110}
}

@article{schuster_approximate_2012,
	title = {The approximate inverse in action: {IV}. {Semi}-discrete equations in a {Banach} space setting},
	volume = {28},
	number = {10},
	journal = {Inverse Problems},
	author = {Schuster, T. and Rieder, A. and Sch{\"o}pfer, F.},
	year = {2012},
	pages = {104001}
}

@article{louis_feature_2011,
	title = {Feature reconstruction in inverse problems},
	volume = {27},
	journal = {Inverse Problems},
	author = {Louis, A. K.},
	year = {2011},
	pages = {065010}
}

@inproceedings{kohr_fast_2010,
	title = {Fast and {High}-{Quality} {Reconstructions} in {Electron} {Tomography}},
	volume = {1281},
	url = {http://link.aip.org/link/?APC/1281/1979/1},
	doi = {10.1063/1.3498322},
	booktitle = {{AIP} {Conference} {Proceedings}},
	publisher = {AIP},
	author = {Kohr, H.},
	editor = {Simos, Theodore E. and Psihoyios, George and Tsitouras, Ch.},
	year = {2010},
	pages = {1979--1981}
}

@article{borwein_convex_2000,
	title = {A convex dual approach to the computation of {NMR} complex spectra},
	volume = {51},
	issn = {1432-2994, 1432-5217},
	url = {http://link.springer.com/10.1007/s001860050004},
	doi = {10.1007/s001860050004},
	number = {1},
	urldate = {2016-09-20},
	journal = {Mathematical Methods of Operations Research (ZOR)},
	author = {Borwein, Jonathan M. and Mar{\'e}chal, Pierre and Naugler, David},
	month = feb,
	year = {2000},
	pages = {91--102},
}

@article{wunderli_time_2010,
	title = {On time flows of minimizers of general convex functionals of linear growth with variable exponent in {BV} space and stability of pseudosolutions},
	volume = {364},
	number = {2},
	journal = {Journal of Mathematical Analysis and Applications},
	author = {Wunderli, T.},
	year = {2010},
	pages = {591--598},
}

@article{lanzavecchia_conical_2005-1,
	title = {Conical tomography of freeze-fracture replicas: a method for the study of integral membrane proteins inserted in phospholipid bilayers},
	volume = {149},
	number = {1},
	journal = {Journal of Structural Biology},
	author = {Lanzavecchia, S. and {others}},
	year = {2005},
	pages = {87--98}
}

@article{markham_numerical_2003,
	title = {Numerical evaluation of {\textbackslash}{uppercaseHankel} transforms for oscillating functions.},
	volume = {20},
	number = {4},
	journal = {Journal of the Optical Society of America A-Optics Image Science and Vision},
	author = {Markham, J. and Conchello, J.-A.},
	year = {2003},
	pages = {621--30}
}

@article{lakhal_decoupling-based_2010,
	title = {A decoupling-based imaging method for inverse medium scattering for {\textbackslash}{uppercaseMaxwell}'s equations},
	volume = {26},
	journal = {Inverse Problems},
	author = {Lakhal, A.},
	year = {2010},
	pages = {015007}
}

@book{colton_inverse_1993,
	edition = {Second},
	title = {Inverse {Acoustic} and {Electromagnetic} {Scattering} {Theory}},
	publisher = {Springer},
	author = {Colton, D. and Kress, R.},
	year = {1993}
}

@article{cormack_uppercaseradon_nodate,
	title = {A {\textbackslash}{uppercaseRadon} transform on spheres through the origin in \${R}{\textasciicircum}n\$ and applications to the {\textbackslash}{uppercaseDarboux} equation},
	author = {Cormack, A. M. and Quinto, E. T.}
}

@article{reginska_approximate_2006,
	title = {Approximate solution of a {\textbackslash}{uppercaseCauchy} problem for the {\textbackslash}{uppercaseHelmholtz} equation},
	volume = {22},
	journal = {Inverse Problems},
	author = {Regi{\'n}ska, T. and Regi{\'n}ski, K.},
	year = {2006},
	pages = {975}
}

@article{patterson_high_1976,
	title = {On {High} {Precision} {Methods} for the {Evaluation} of {\textbackslash}{uppercaseFourier} {Integrals} with {Finite} and {Infinite} {Limits}},
	volume = {27},
	number = {1},
	journal = {Numerische Mathematik},
	author = {Patterson, T. N. L.},
	year = {1976},
	pages = {41--52}
}

@article{lawrence_transform-based_2006,
	title = {Transform-based backprojection for volume reconstruction of large format electron microscope tilt series},
	volume = {154},
	number = {2},
	journal = {Journal of Structural Biology},
	author = {Lawrence, A. and {others}},
	year = {2006},
	pages = {144--167}
}

@article{jonas_cone_2013,
	title = {Cone beam geometry for small objects in phase contrast tomography},
	volume = {29},
	issn = {0266-5611},
	url = {http://stacks.iop.org/0266-5611/29/i=9/a=095013},
	doi = {10.1088/0266-5611/29/9/095013},
	abstract = {Phase contrast tomography has developed rapidly within the last ten years. The new method enables the reconstruction of the refraction index in addition to the attenuation coefficient and can therefore be very well applied to samples which are only weakly absorbing. First studies in phase contract tomography were done using synchrotron devices which are modeled by the so-called parallel geometry. Samples studied so far are special foams and fiber materials, see Cloetens et al (1999 App. Phys. Lett. 75 2912{\textendash}4), which give almost no contrast due to absorption but provide excellent images in phase contrast. Recently tubes were successfully applied to a variety of applications. These laboratory devices no longer fulfil the requirement of a parallel geometry but need to be treated as a fan/cone beam geometry. In this paper we derive a mathematical model for cone beam geometry in phase contrast tomography in two and three dimensions for objects small compared to the two distances of object to detector and x-ray source to object. All approximations needed are analyzed and an efficient reconstruction method providing both phase and absorption in a single step is derived, based on the method by Louis and Maa{\ss} (1990 Inverse Problems 6 427{\textendash}39). The reconstruction method is successfully tested using numerical examples with simulated phantom data.},
	language = {en},
	number = {9},
	urldate = {2016-10-31},
	journal = {Inverse Problems},
	author = {Jonas, Peter and Louis, Alfred K.},
	year = {2013},
	pages = {095013},
}

@article{schuster_solving_2010,
	title = {Solving linear operator equations in {\textbackslash}{uppercaseBanach} spaces non-iteratively by the method of approximate inverse},
	volume = {26},
	journal = {Inverse Problems},
	author = {Schuster, T. and Sch{\"o}pfer, F.},
	year = {2010},
	pages = {085006}
}

@article{tuy_reconstruction_1981,
	title = {Reconstruction of a three-dimensional object from a limited range of views},
	volume = {80},
	number = {2},
	journal = {Journal of Mathematical Analysis and Applications},
	author = {Tuy, H.},
	year = {1981},
	pages = {598--616}
}

@article{keiner_using_2009,
	title = {Using {\textbackslash}{uppercaseNFFT} 3 {\textendash} {A} {Software} {Library} for {Various} {Nonequispaced} {Fast} {\textbackslash}{uppercaseFourier} {Transforms}},
	volume = {36},
	number = {4},
	journal = {ACM Transactions on Mathematical Software (TOMS)},
	author = {Keiner, J. and Kunis, S. and Potts, D.},
	year = {2009},
	pages = {19}
}

@article{intaraprasonk_analytic_2008,
	series = {Proceedings of the {Eleventh} {Conference} on {Frontiers} of {Electron} {Microscopy} in {Materials} {Science}},
	title = {Analytic derivation of optimal imaging conditions for incoherent imaging in aberration-corrected electron microscopes},
	volume = {108},
	issn = {0304-3991},
	url = {http://www.sciencedirect.com/science/article/pii/S0304399108001812},
	doi = {10.1016/j.ultramic.2008.05.013},
	abstract = {The optimal lens parameters for incoherent imaging using third and fifth-order aberration-corrected electron microscopes are derived analytically. We propose simple models for the point spread function (PSF) and transfer function that give analytic formulae for the lateral resolution and depth resolution. We also derive an analytic formula for the contrast transfer function (CTF) in three dimensions and show that depth sectioning has an information limit equivalent to tomography with a missing cone of 90 o minus the aperture angle.},
	number = {11},
	urldate = {2016-10-24},
	journal = {Ultramicroscopy},
	author = {Intaraprasonk, Varat and Xin, Huolin L. and Muller, David A.},
	month = oct,
	year = {2008},
	pages = {1454--1466},
}

@article{hofmann_convergence_2007,
	title = {A convergence rates result for {\textbackslash}{uppercaseTikhonov} regularization in {\textbackslash}{uppercaseBanach} spaces with non-smooth operators},
	volume = {23},
	journal = {Inverse Problems},
	author = {Hofmann, B. and Kaltenbacher, B. and Poeschl, C. and Scherzer, O.},
	year = {2007},
	pages = {987--1010}
}

@book{martinez_introduction_2002,
	address = {New York, NY},
	series = {Universitext},
	title = {An {Introduction} to {Semiclassical} and {Microlocal} {Analysis}},
	isbn = {978-1-4419-2961-7 978-1-4757-4495-8},
	url = {http://link.springer.com/10.1007/978-1-4757-4495-8},
	urldate = {2016-09-12},
	publisher = {Springer New York},
	author = {Martinez, Andr{\'e}},
	editor = {Axler, S. and Gehring, F. W. and Ribet, K. A.},
	year = {2002},
}

@article{padula_software_2009,
	title = {A {Software} {Framework} for {Abstract} {Expression} of {Coordinate}-free {Linear} {Algebra} and {Optimization} {Algorithms}},
	volume = {36},
	issn = {0098-3500},
	url = {http://doi.acm.org/10.1145/1499096.1499097},
	doi = {10.1145/1499096.1499097},
	abstract = {The Rice Vector Library is a collection of C++ classes expressing core concepts (vector, function,{\textellipsis}) of calculus in Hilbert space with minimal implementation dependence, and providing standardized interfaces behind which to hide application-dependent implementation details (data containers, function objects). A variety of coordinate-free algorithms from linear algebra and optimization, including Krylov subspace methods and various relatives of Newton's method for nonlinear equations and constrained and unconstrained optimization, may be expressed purely in terms of this system of classes. The resulting code may be used without alteration in a wide range of control, design, and parameter estimation applications, in serial and parallel computing environments.},
	number = {2},
	urldate = {2016-10-31},
	journal = {ACM Trans. Math. Softw.},
	author = {Padula, Anthony D. and Scott, Shannon D. and Symes, William W.},
	month = apr,
	year = {2009},
	pages = {8:1--8:36},
}

@article{bredies_preconditioned_2015,
	title = {Preconditioned {Douglas}--{Rachford} {Splitting} {Methods} for {Convex}-concave {Saddle}-point {Problems}},
	volume = {53},
	issn = {0036-1429},
	url = {http://epubs.siam.org/doi/abs/10.1137/140965028},
	doi = {10.1137/140965028},
	abstract = {We propose a preconditioned version of the Douglas--Rachford splitting method for solving convex-concave saddle-point problems associated with Fenchel--Rockafellar duality. Our approach makes it possible to use approximate solvers for the linear subproblem arising in this context. We prove weak convergence in Hilbert space under minimal assumptions. In particular, various efficient preconditioners are introduced in this framework for which only a few inner iterations are needed instead of computing an exact solution or controlling the error. The method is applied to a discrete total-variation denoising problem. Numerical experiments show that the proposed algorithms with appropriate preconditioners are very competitive with existing fast algorithms including the first-order primal-dual algorithm for saddle-point problems of Chambolle and Pock.},
	number = {1},
	urldate = {2016-11-06},
	journal = {SIAM Journal on Numerical Analysis},
	author = {Bredies, K. and Sun, H.},
	month = jan,
	year = {2015},
	pages = {421--444},
}

@article{bredies_preconditioned_2015-1,
	title = {Preconditioned {Douglas}{\textendash}{Rachford} {Algorithms} for {TV}- and {TGV}-{Regularized} {Variational} {Imaging} {Problems}},
	volume = {52},
	issn = {0924-9907, 1573-7683},
	url = {http://link.springer.com/article/10.1007/s10851-015-0564-1},
	doi = {10.1007/s10851-015-0564-1},
	abstract = {The recently introduced preconditioned Douglas{\textendash}Rachford iteration (PDR) for convex{\textendash}concave saddle-point problems is studied with respect to convergence rates and applied to variational imaging problems with total variation (TV) and total generalized variation (TGV) penalty. A rate of O(1/k)O(1/k)\{{\textbackslash}mathcal \{O\}\}(1/k) for restricted primal{\textendash}dual gaps evaluated for ergodic sequences generated by the PDR iteration is established. Based on PDR, new fast iterative algorithms for TV-denoising, TV-deblurring, and TGV-denoising of second order with L2L2L{\textasciicircum}2 and L1L1L{\textasciicircum}1 discrepancy are proposed. While for denoising, symmetric (block) Red{\textendash}Black Gauss{\textendash}Seidel preconditioners are effective, fast Fourier transform-based preconditioners are employed for the deblurring problems. Finally, for the L2L2L{\textasciicircum}2-TGV-denoising problem, an effective modified primal{\textendash}dual gap is developed which may serve as a stopping criterion. All algorithms are tested and compared in numerical experiments. In particular, for problems where strong convexity does not hold, it turns out that the proposed preconditioning techniques are beneficial and lead to competitive results.},
	language = {en},
	number = {3},
	urldate = {2016-11-06},
	journal = {Journal of Mathematical Imaging and Vision},
	author = {Bredies, Kristian and Sun, Hong Peng},
	month = feb,
	year = {2015},
	pages = {317--344},
}

@article{bredies_total_2010,
	title = {Total {Generalized} {Variation}},
	volume = {3},
	url = {http://epubs.siam.org/doi/abs/10.1137/090769521},
	doi = {10.1137/090769521},
	abstract = {The novel concept of total generalized variation of a function u is introduced, and some of its essential properties are proved. Differently from the bounded variation seminorm, the new concept involves higher-order derivatives of u. Numerical examples illustrate the high quality of this functional as a regularization term for mathematical imaging problems. In particular this functional selectively regularizes on different regularity levels and, as a side effect, does not lead to a staircasing effect.},
	number = {3},
	urldate = {2016-11-06},
	journal = {SIAM Journal on Imaging Sciences},
	author = {Bredies, K. and Kunisch, K. and Pock, T.},
	month = jan,
	year = {2010},
	pages = {492--526},
}

@book{giusti_minimal_1984,
	address = {Boston, MA},
	title = {Minimal {Surfaces} and {Functions} of {Bounded} {Variation}},
	isbn = {978-0-8176-3153-6 978-1-4684-9486-0},
	url = {http://link.springer.com/10.1007/978-1-4684-9486-0},
	language = {en},
	urldate = {2016-11-06},
	publisher = {Birkh{\"a}user Boston},
	author = {Giusti, Enrico},
	year = {1984},
}

@article{harjulehto_critical_2013,
	title = {Critical variable exponent functionals in image restoration},
	volume = {26},
	issn = {0893-9659},
	url = {http://www.sciencedirect.com/science/article/pii/S0893965912001851},
	doi = {10.1016/j.aml.2012.03.032},
	abstract = {We study a variable exponent model for image restoration in the case that the exponent attains the critical value one. We prove existence and $\Gamma$ -convergence. The results answer an open question by Li, Li and Pi [F. Li, Z. Li, L. Pi, Ling, Variable exponent functionals in image restoration, Appl. Math. Comput. 216 (3) (2010) 870{\textendash}882]},
	number = {1},
	urldate = {2016-11-07},
	journal = {Applied Mathematics Letters},
	author = {Harjulehto, P. and H{\"a}st{\"o}, P. and Latvala, V. and Toivanen, O.},
	month = jan,
	year = {2013},
	pages = {56--60},
}

@article{harjulehto_overview_2010,
	title = {Overview of differential equations with non-standard growth},
	volume = {72},
	issn = {0362-546X},
	url = {http://www.sciencedirect.com/science/article/pii/S0362546X10001100},
	doi = {10.1016/j.na.2010.02.033},
	abstract = {Differential equations with non-standard growth have been a very active field of investigation in recent years. In this survey we present an overview of the field, as well as several of the most important results. We consider both existence and regularity questions. Finally, we provide a comprehensive list of papers published to date.},
	number = {12},
	urldate = {2016-11-07},
	journal = {Nonlinear Analysis: Theory, Methods \& Applications},
	author = {Harjulehto, Petteri and H{\"a}st{\"o}, Peter and L{\^e}, {\'U}t V. and Nuortio, Matti},
	month = jun,
	year = {2010},
	pages = {4551--4574},
}

@article{li_variable_2010,
	title = {Variable exponent functionals in image restoration},
	volume = {216},
	issn = {0096-3003},
	url = {http://www.sciencedirect.com/science/article/pii/S0096300310001189},
	doi = {10.1016/j.amc.2010.01.094},
	abstract = {We study a functional with variable exponent, 1 \&lt; p ( x ) ? 2 , which provides a model for image denoising and restoration. Here p ( x ) is defined by the gradient information in the observed image. The diffusion derived from the proposed model is between total variation based regularization and Gaussian smoothing. The diffusion speed of the corresponding heat equation is tuned by the variable exponent p ( x ) . The minimization problem and its associated flow in a weakened formulation are discussed. The existence, uniqueness, stability and long-time behavior of the proposed model are established in the variable exponent functional space W 1 , p ( x ) . Experimental results illustrate the effectiveness of the model in image restoration.},
	number = {3},
	urldate = {2016-11-07},
	journal = {Applied Mathematics and Computation},
	author = {Li, Fang and Li, Zhibin and Pi, Ling},
	month = apr,
	year = {2010},
	pages = {870--882},
}

@article{harjulehto_minimizers_2008,
	title = {Minimizers of the variable exponent, non-uniformly convex {Dirichlet} energy},
	volume = {89},
	issn = {0021-7824},
	url = {http://www.sciencedirect.com/science/article/pii/S0021782407001249},
	doi = {10.1016/j.matpur.2007.10.006},
	abstract = {We study energy minimizing properties of the function u=lim$\lambda$j{\textrightarrow}1+u$\lambda$j, where u$\lambda$j is the solution to the p$\lambda$j(.)-Laplacian Dirichlet problem with prescribed boundary values. Here p:$\Omega${\textrightarrow}[1,$\infty$) is a variable exponent and p$\lambda$j(x)=max\{p(x),$\lambda$j\} for $\lambda$j{\textgreater}1. This problem leads in a natural way to a mixture of Sobolev and total variation norms. The main results are obtained under the assumption that p is strongly log-H{\"o}lder continuous and bounded. To motivate our approach we also consider the one-dimensional case and give examples which justify our assumptions. The results can be applied in the analysis of a model for image restoration combining total variation and isotropic smoothing. Nous {\'e}tudions des propri{\'e}t{\'e}s de la fonction u=lim$\lambda$j{\textrightarrow}1+u$\lambda$j, o{\`u} u$\lambda$j est la solution du p$\lambda$j(.)-laplacien probl{\`e}me aux limites de Dirichlet. Ici, p:$\Omega${\textrightarrow}[1,$\infty$) est un exposant variable et p$\lambda$j(x)=max\{p(x),$\lambda$j\}, quand $\lambda$j{\textgreater}1. Ces conditions conduisent naturellement {\`a} une norme combin{\'e}e de la variation totale et de la norme de Sobolev. Nos principaux r{\'e}sultats sont obtenus sous l'hypoth{\`e}se que l'exposant est fortement h{\"o}lderien et born{\'e}. Afin de justifier les hypoth{\`e}ses nous examinons aussi le cas unidimensionnel. Les r{\'e}sultats peuvent {\^e}tre appliqu{\'e}s {\`a} l'analyse d'une m{\'e}thode de restauration d'image, qui combine un lissage bas{\'e} sur la variation totale et un lissage isotropique.},
	number = {2},
	urldate = {2016-11-07},
	journal = {Journal de Math{\'e}matiques Pures et Appliqu{\'e}es},
	author = {Harjulehto, Petteri and H{\"a}st{\"o}, Peter and Latvala, Visa},
	month = feb,
	year = {2008},
	pages = {174--197},
}

@article{hinsen_high-level_2003,
	title = {High-{Level} {Parallel} {Software} {Development} with {Python} and {BSP}},
	volume = {13},
	abstract = {One of the main obstacles to a more widespread use of parallel computing in science is the difficulty of implementing, testing, and maintaining parallel programs. The combination of a simple parallel computation model, BSP, and a high-level programming language, Python, simplifies these tasks significantly. It allows the rapid development facilities of Python to be applied to parallel programs, providing interactive development as well as interactive debugging of parallel code. 1},
	journal = {Parallel Processing Letters},
	author = {Hinsen, Konrad},
	year = {2003},
	pages = {2003},
}

@article{hinsen_using_2006,
	title = {Using {B} {SP} and {Python} to simplify parallel programming},
	volume = {22},
	issn = {0167-739X},
	url = {http://www.sciencedirect.com/science/article/pii/S0167739X03002061},
	doi = {10.1016/j.future.2003.09.003},
	abstract = {Scientific computing is usually associated with compiled languages for maximum efficiency. However, in a typical application program, only a small part of the code is time-critical and requires the efficiency of a compiled language. It is often advantageous to use interpreted high-level languages for the remaining tasks, adopting a mixed-language approach. This will be demonstrated for Python, an interpreted object-oriented high-level language that is well suited for scientific computing. Particular attention is paid to high-level parallel programming using Python and the BSP model. We explain the basics of BSP and how it differs from other parallel programming tools like MPI. Thereafter we present an application of Python and BSP for solving a partial differential equation from computational science, utilizing high-level design of libraries and mixed-language (Python{\textendash}C or Python{\textendash}Fortran) programming.},
	number = {1{\textendash}2},
	urldate = {2016-11-07},
	journal = {Future Generation Computer Systems},
	author = {Hinsen, Konrad and Petter Langtangen, Hans and Skavhaug, Ola and {\O}deg{\r a}rd, {\r A}smund},
	month = jan,
	year = {2006},
	pages = {123--157},
}

@article{hinsen_parallel_2007,
	title = {Parallel {Scripting} with {Python}},
	volume = {9},
	issn = {1521-9615},
	url = {http://ieeexplore.ieee.org/document/4362735/},
	doi = {10.1109/MCSE.2007.117},
	number = {6},
	urldate = {2016-11-07},
	journal = {Computing in Science \& Engineering},
	author = {Hinsen, Konrad},
	month = nov,
	year = {2007},
	pages = {82--89},
}

@article{beck_fast_2009,
	title = {A {Fast} {Iterative} {Shrinkage}-{Thresholding} {Algorithm} for {Linear} {Inverse} {Problems}},
	volume = {2},
	url = {http://epubs.siam.org/doi/abs/10.1137/080716542},
	doi = {10.1137/080716542},
	abstract = {We consider the class of iterative shrinkage-thresholding algorithms (ISTA) for solving linear inverse problems arising in signal/image processing. This class of methods, which can be viewed as an extension of the classical gradient algorithm, is attractive due to its simplicity and thus is adequate for solving large-scale problems even with dense matrix data. However, such methods are also known to converge quite slowly. In this paper we present a new fast iterative shrinkage-thresholding algorithm (FISTA) which preserves the computational simplicity of ISTA but with a global rate of convergence which is proven to be significantly better, both theoretically and practically. Initial promising numerical results for wavelet-based image deblurring demonstrate the capabilities of FISTA which is shown to be faster than ISTA by several orders of magnitude.},
	number = {1},
	urldate = {2016-11-22},
	journal = {SIAM Journal on Imaging Sciences},
	author = {Beck, A. and Teboulle, M.},
	month = jan,
	year = {2009},
	pages = {183--202},
}

@article{bailey_fractional_1991,
	title = {The {Fractional} {Fourier} {Transform} and {Applications}},
	volume = {33},
	issn = {0036-1445},
	url = {http://epubs.siam.org/doi/abs/10.1137/1033097},
	doi = {10.1137/1033097},
	abstract = {This paper describes the {\textquotedblleft}fractional Fourier transform,{\textquotedblright} which admits computation by an algorithm that has complexity proportional to the fast Fourier transform algorithm. Whereas the discrete Fourier transform (DFT) is based on integral roots of unity \$e{\textasciicircum}\{\{\{ - 2{\textbackslash}pi i\} / n\}\} \$, the fractional Fourier transform is based on fractional roots of unity \$e{\textasciicircum}\{ - 2{\textbackslash}pi i{\textbackslash}alpha \} \$ where \${\textbackslash}alpha \$ is arbitrary. The fractional Fourier transform and the corresponding fast algorithm are useful for such applications as computing DFTs of sequences with prime lengths, computing DFTs of sparse sequences, analyzing sequences with noninteger periodicities, performing high-resolution trigonometric interpolation, detecting lines in noisy images, and detecting signals with linearly drifting frequencies. In many cases, the resulting algorithms are faster by arbitrarily large factors than conventional techniques.},
	number = {3},
	urldate = {2016-11-24},
	journal = {SIAM Review},
	author = {Bailey, D. and Swarztrauber, P.},
	month = sep,
	year = {1991},
	pages = {389--404},
}

@article{chen_novel_2005,
	title = {A novel extension of the parallel-beam projection-slice theorem to divergent fan-beam and cone-beam projections},
	volume = {32},
	issn = {2473-4209},
	url = {http://onlinelibrary.wiley.com/doi/10.1118/1.1861792/abstract},
	doi = {10.1118/1.1861792},
	abstract = {The general goal of this paper is to extend the parallel-beam projection-slice theorem to divergent fan-beam and cone-beam projections without rebinning the divergent fan-beam and cone-beam projections into parallel-beam projections directly. The basic idea is to establish a novel link between the local Fourier transform of the projection data and the Fourier transform of the image object. Analogous to the two- and three-dimensional parallel-beam cases, the measured projection data are backprojected along the projection direction and then a local Fourier transform is taken for the backprojected data array. However, due to the loss of the shift invariance of the image object in a single view of the divergent-beam projections, the measured projection data is weighted by a distance dependent weight w(r) before the local Fourier transform is performed. The variable r in the weighting function w(r) is the distance from the backprojected point to the x-ray source position. It is shown that a special choice of the weighting function, w(r)=1/r, will facilitate the calculations and a simple relation can be established between the Fourier transform of the image function and the local Fourier transform of the 1/r-weighted backprojection data array. Unlike the parallel-beam cases, a one-to-one correspondence does not exist for a local Fourier transform of the backprojected data array and a single line in the two-dimensional (2D) case or a single slice in the 3D case of the Fourier transform of the image function. However, the Fourier space of the image object can be built up after the local Fourier transforms of the 1/r-weighted backprojection data arrays are shifted and then summed in a laboratory frame. Thus the established relations Eq. (27) and Eq. (29) between the Fourier space of the image object and the Fourier transforms of the backprojected data arrays can be viewed as a generalized projection-slice theorem for divergent fan-beam and cone-beam projections. Once the Fourier space of the image function is built up, an inverse Fourier transform could be performed to reconstruct tomographic images from the divergent beam projections. Due to the linearity of the Fourier transform, an image reconstruction step can be performed either when the complete Fourier space is available or in parallel with the building of the Fourier space. Numerical simulations are performed to verify the generalized projection-slice theorem by using a disc phantom in the fan-beam case.},
	language = {en},
	number = {3},
	urldate = {2016-12-01},
	journal = {Medical Physics},
	author = {Chen, Guang-Hong and Leng, Shuai and Mistretta, Charles A.},
	month = mar,
	year = {2005},
	pages = {654--665},
}

@book{hackbusch_tensor_2012,
	address = {Berlin, Heidelberg},
	series = {Springer {Series} in {Computational} {Mathematics}},
	title = {Tensor {Spaces} and {Numerical} {Tensor} {Calculus}},
	volume = {42},
	isbn = {978-3-642-28026-9 978-3-642-28027-6},
	url = {http://link.springer.com/10.1007/978-3-642-28027-6},
	urldate = {2016-12-07},
	publisher = {Springer Berlin Heidelberg},
	author = {Hackbusch, Wolfgang},
	year = {2012},
}

@book{wei_theory_2016,
	edition = {1 edition},
	title = {Theory and {Computation} of {Tensors}: {Multi}-{Dimensional} {Arrays}},
	shorttitle = {Theory and {Computation} of {Tensors}},
	abstract = {Theory and Computation of Tensors: Multi-Dimensional Arrays investigates theories and computations of tensors to broaden perspectives on matrices. Data in the Big Data Era is not only growing larger but also becoming much more complicated. Tensors (multi-dimensional arrays) arise naturally from many engineering or scientific disciplines because they can represent multi-relational data or nonlinear relationships.Provides an introduction of recent results about tensorsInvestigates theories and computations of tensors to broaden perspectives on matricesDiscusses how to extend numerical linear algebra to numerical multi-linear algebraOffers examples of how researchers and students can engage in research and the applications of tensors and multi-dimensional arrays},
	language = {English},
	publisher = {Academic Press},
	author = {Wei, Yimin and Ding, Weiyang},
	month = aug,
	year = {2016},
}

@article{bauschke_projection_1996,
	title = {On {Projection} {Algorithms} for {Solving} {Convex} {Feasibility} {Problems}},
	volume = {38},
	issn = {0036-1445},
	url = {http://epubs.siam.org/doi/abs/10.1137/S0036144593251710},
	doi = {10.1137/S0036144593251710},
	abstract = {Due to their extraordinary utility and broad applicability in many areas of classical mathematics and modern physical sciences (most notably, computerized tomography), algorithms for solving convex feasibility problems continue to receive great attention. To unify, generalize, and review some of these algorithms, a very broad and flexible framework is investigated. Several crucial new concepts which allow a systematic discussion of questions on behaviour in general Hilbert spaces and on the quality of convergence are brought out. Numerous examples are given.},
	number = {3},
	urldate = {2016-12-15},
	journal = {SIAM Review},
	author = {Bauschke, H. and Borwein, J.},
	month = sep,
	year = {1996},
	pages = {367--426},
}

@incollection{burger_bregman_2016,
	series = {Springer {Optimization} and {Its} {Applications}},
	title = {Bregman {Distances} in {Inverse} {Problems} and {Partial} {Differential} {Equations}},
	copyright = {{\textcopyright}2016 Springer International Publishing Switzerland},
	isbn = {978-3-319-30784-8 978-3-319-30785-5},
	url = {http://link.springer.com/chapter/10.1007/978-3-319-30785-5_2},
	abstract = {The aim of this paper is to provide an overview of recent development related to Bregman distances outside its native areas of optimization and statistics. We discuss approaches in inverse problems and image processing based on Bregman distances, which have evolved to a standard tool in these fields in the last decade. Moreover, we discuss related issues in the analysis and numerical analysis of nonlinear partial differential equations with a variational structure. For such problems Bregman distances appear to be of similar importance, but are currently used only in a quite hidden fashion. We try to work out explicitly the aspects related to Bregman distances, which also lead to novel mathematical questions and may also stimulate further research in these areas.},
	language = {en},
	number = {109},
	urldate = {2016-12-19},
	booktitle = {Advances in {Mathematical} {Modeling}, {Optimization} and {Optimal} {Control}},
	publisher = {Springer International Publishing},
	author = {Burger, Martin},
	editor = {Hiriart-Urruty, Jean-Baptiste and Korytowski, Adam and Maurer, Helmut and Szymkat, Maciej},
	year = {2016},
	note = {DOI: 10.1007/978-3-319-30785-5\_2},
	pages = {3--33},
}

@article{wang_towards_2016,
	title = {Towards {Bayesian} {Deep} {Learning}: {A} {Framework} and {Some} {Existing} {Methods}},
	volume = {28},
	issn = {1041-4347},
	shorttitle = {Towards {Bayesian} {Deep} {Learning}},
	doi = {10.1109/TKDE.2016.2606428},
	abstract = {While perception tasks such as visual object recognition and text understanding play an important role in human intelligence, subsequent tasks that involve inference, reasoning, and planning require an even higher level of intelligence. The past few years have seen major advances in many perception tasks using deep learning models. For higher-level inference, however, probabilistic graphical models with their Bayesian nature are still more powerful and flexible. To achieve integrated intelligence that involves both perception and inference, it is naturally desirable to tightly integrate deep learning and Bayesian models within a principled probabilistic framework, which we call Bayesian deep learning. In this unified framework, the perception of text or images using deep learning can boost the performance of higher-level inference and in return, the feedback from the inference process is able to enhance the perception of text or images. This paper proposes a general framework for Bayesian deep learning and reviews its recent applications on recommender systems, topic models, and control. In this paper, we also discuss the relationship and differences between Bayesian deep learning and other related topics such as the Bayesian treatment of neural networks.},
	number = {12},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Wang, H. and Yeung, D. Y.},
	month = dec,
	year = {2016},
	pages = {3395--3408},
}

@article{hahn_efficient_2014,
	title = {Efficient algorithms for linear dynamic inverse problems with known motion},
	volume = {30},
	issn = {0266-5611},
	url = {http://stacks.iop.org/0266-5611/30/i=3/a=035008},
	doi = {10.1088/0266-5611/30/3/035008},
	abstract = {An inverse problem is called dynamic if the object changes during the data acquisition process. This occurs e.g. in medical applications when fast moving organs like the lungs or the heart are imaged. Most regularization methods are based on the assumption that the object is static during the measuring procedure. Hence, their application in the dynamic case often leads to serious motion artefacts in the reconstruction. Therefore, an algorithm has to take into account the temporal changes of the investigated object. In this paper, a reconstruction method that compensates for the motion of the object is derived for dynamic linear inverse problems. The algorithm is validated at numerical examples from computerized tomography.},
	language = {en},
	number = {3},
	urldate = {2017-01-13},
	journal = {Inverse Problems},
	author = {Hahn, B. N.},
	year = {2014},
	pages = {035008}
}

@book{cierniak_x-ray_2011,
	address = {London},
	title = {X-{Ray} {Computed} {Tomography} in {Biomedical} {Engineering}},
	isbn = {978-0-85729-026-7 978-0-85729-027-4},
	url = {http://link.springer.com/10.1007/978-0-85729-027-4},
	language = {en},
	urldate = {2017-01-20},
	publisher = {Springer London},
	author = {Cierniak, Robert},
	year = {2011},
}

@incollection{chan_numerical_2015,
	title = {Numerical {Methods} and {Applications} in {Total} {Variation} {Image} {Restoration}},
	copyright = {{\textcopyright}2015 Springer Science+Business Media New York},
	isbn = {978-1-4939-0789-2 978-1-4939-0790-8},
	url = {http://link.springer.com/referenceworkentry/10.1007/978-1-4939-0790-8_24},
	abstract = {Since their introduction in a classic paper by Rudin, Osher, and Fatemi (Physica D 60:259{\textendash}268, 1992), total variation minimizing models have become one of the most popular and successful methodologies for image restoration. New developments continue to expand the capability of the basic method in various aspects. Many faster numerical algorithms and more sophisticated applications have been proposed. This chapter reviews some of these recent developments. , Abstract Since their introduction in a classic paper by Rudin, Osher, and Fatemi (Physica D 60:259{\textendash}268, 1992), total variation minimizing models have become one of the most popular and successful methodologies for image restoration. New developments continue to expand the capability of the basic method in various aspects. Many faster numerical algorithms and more sophisticated applications have been proposed. This chapter reviews some of these recent developments.},
	language = {en},
	urldate = {2017-01-20},
	booktitle = {Handbook of {Mathematical} {Methods} in {Imaging}},
	publisher = {Springer New York},
	author = {Chan, Raymond and Chan, Tony F. and Yip, Andy},
	editor = {Scherzer, Otmar},
	year = {2015},
	note = {DOI: 10.1007/978-1-4939-0790-8\_24},
	pages = {1501--1537},
}

@book{palamodov_reconstructive_2004,
	series = {Monographs in {Mathematics}},
	title = {Reconstructive {Integral} {Geometry}},
	isbn = {978-3-7643-7129-6},
	url = {http://www.springer.com/birkhauser/mathematics/book/978-3-7643-7129-6},
	abstract = {\{This book covers facts and methods for the reconstruction of a function in a real affine or projective space from data of integrals, particularly over~ lines, planes, and spheres. Recent results are collected stressing explicit analytic methods. Another focus consists of the relations between algebraic integral geometry and partial differential equations. A concise basic course in harmonic analysis and distribution theory is given in the first chapter. The first half of the book includes the ray, the spherical mean transforms in the plane or in 3-space, and inversion from incomplete data. It will be of particular interest to application oriented readers. Further chapters are devoted to the Funk-Radon transform on algebraic varieties of arbitrary dimension.The material appeals to graduates and researchers in pure and applied mathematics who are interested in image reconstruction, inverse problems or functional analysis. \}},
	urldate = {2017-01-20},
	publisher = {\{Birkh{\"a}user Basel\}},
	author = {Palamodov, Victor},
	month = aug,
	year = {2004},
}

@article{censor_projection_2015,
	title = {Projection methods: an annotated bibliography of books and reviews},
	volume = {64},
	issn = {0233-1934},
	shorttitle = {Projection methods},
	url = {http://dx.doi.org/10.1080/02331934.2014.957701},
	doi = {10.1080/02331934.2014.957701},
	abstract = {Projections onto sets are used in a wide variety of methods in optimization theory but not every method that uses projections really belongs to the class of projection methods as we mean it here. Here, projection methods are iterative algorithms that use projections onto sets while relying on the general principle that when a family of (usually closed and convex) sets is present, then projections (or approximate projections) onto the given individual sets are easier to perform than projections onto other sets (intersections, image sets under some transformation, etc.) that are derived from the given family of individual sets. Projection methods employ projections (or approximate projections) onto convex sets in various ways. They may use different kinds of projections and, sometimes, even use different projections within the same algorithm. They serve to solve a variety of problems which are either of the feasibility or the optimization types. They have different algorithmic structures, of which some are particularly suitable for parallel computing, and they demonstrate nice convergence properties and/or good initial behavioural patterns. This class of algorithms has witnessed great progress in recent years and its member algorithms have been applied with success to many scientific, technological and mathematical problems. This annotated bibliography includes books and review papers on, or related to, projection methods that we know about, use and like. If you know of books or review papers that should be added to this list please contact us.},
	number = {11},
	urldate = {2017-01-20},
	journal = {Optimization},
	author = {Censor, Yair and Cegielski, Andrzej},
	month = nov,
	year = {2015},
	pages = {2343--2358},
}

@book{scherl_evaluation_2011,
	address = {Wiesbaden},
	title = {Evaluation of {State}-of-the-{Art} {Hardware} {Architectures} for {Fast} {Cone}-{Beam} {CT} {Reconstruction}},
	isbn = {978-3-8348-1743-3 978-3-8348-8259-2},
	url = {http://link.springer.com/10.1007/978-3-8348-8259-2},
	language = {en},
	urldate = {2017-01-20},
	publisher = {Vieweg+Teubner},
	author = {Scherl, Holger},
	year = {2011},
}

@book{zeng_medical_2010,
	address = {Berlin, Heidelberg},
	title = {Medical {Image} {Reconstruction}},
	isbn = {978-3-642-05367-2 978-3-642-05368-9},
	url = {http://link.springer.com/10.1007/978-3-642-05368-9},
	language = {en},
	urldate = {2017-01-20},
	publisher = {Springer Berlin Heidelberg},
	author = {Zeng, Gengsheng Lawrence},
	year = {2010},
}

@article{chun_simple_2009,
	title = {A {Simple} {Regularizer} for {B}-spline {Nonrigid} {Image} {Registration} {That} {Encourages} {Local} {Invertibility}},
	volume = {3},
	issn = {1932-4553},
	url = {http://ieeexplore.ieee.org/document/4786548/},
	doi = {10.1109/JSTSP.2008.2011116},
	number = {1},
	urldate = {2017-01-20},
	journal = {IEEE Journal of Selected Topics in Signal Processing},
	author = {Chun, Se Young and Fessler, Jeffrey A.},
	month = feb,
	year = {2009},
	pages = {159--169},
}

@inproceedings{biswal_implementation_2010,
	title = {Implementation of {Katsevich} algorithm for helical cone-beam computed tomography using {CORDIC}},
	isbn = {978-1-61284-039-0},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5735394},
	doi = {10.1109/ICSMB.2010.5735394},
	urldate = {2017-01-20},
	publisher = {IEEE},
	author = {Biswal, Pradyut and Banerjee, Swapna},
	month = dec,
	year = {2010},
	pages = {313--317},
}

@article{katsevich_general_2003,
	title = {A general scheme for constructing inversion algorithms for cone beam {CT}},
	volume = {2003},
	issn = {0161-1712, 1687-0425},
	url = {http://www.hindawi.com/journals/ijmms/2003/562374/abs/},
	doi = {10.1155/S0161171203209315},
	language = {en},
	number = {21},
	urldate = {2017-01-20},
	journal = {International Journal of Mathematics and Mathematical Sciences},
	author = {Katsevich, Alexander},
	year = {2003},
	pages = {1305--1321},
}

@article{kim_forward-projection_2012,
	title = {Forward-{Projection} {Architecture} for {Fast} {Iterative} {Image} {Reconstruction} in {X}-{Ray} {CT}},
	volume = {60},
	issn = {1053-587X, 1941-0476},
	url = {http://ieeexplore.ieee.org/document/6239609/},
	doi = {10.1109/TSP.2012.2208636},
	number = {10},
	urldate = {2017-01-20},
	journal = {IEEE Transactions on Signal Processing},
	author = {Kim, Jung Kuk and Fessler, Jeffrey A. and Zhang, Zhengya},
	month = oct,
	year = {2012},
	pages = {5508--5518},
}

@article{noo_new_2007,
	title = {A new scheme for view-dependent data differentiation in fan-beam and cone-beam computed tomography},
	volume = {52},
	issn = {0031-9155, 1361-6560},
	url = {http://stacks.iop.org/0031-9155/52/i=17/a=020?key=crossref.bfd19e4f70c2ff69b1764bb8574a430d},
	doi = {10.1088/0031-9155/52/17/020},
	number = {17},
	urldate = {2017-01-20},
	journal = {Physics in Medicine and Biology},
	author = {Noo, Fr{\'e}d{\'e}ric and Hoppe, Stefan and Dennerlein, Frank and Lauritsch, G{\"u}nter and Hornegger, Joachim},
	month = sep,
	year = {2007},
	pages = {5393--5414},
}

@article{schulz_characterization_2016,
	title = {Characterization of the {SG}-{Wave} {Front} {Set} in {Terms} of the {FBI}-{Transform}},
	volume = {22},
	issn = {1069-5869, 1531-5851},
	url = {http://link.springer.com/10.1007/s00041-015-9451-9},
	doi = {10.1007/s00041-015-9451-9},
	language = {en},
	number = {5},
	urldate = {2017-01-20},
	journal = {Journal of Fourier Analysis and Applications},
	author = {Schulz, Ren{\'e} M.},
	month = oct,
	year = {2016},
	pages = {1141--1156},
}

@article{gourion_inverse_2002,
	title = {The inverse problem of emission tomography},
	volume = {18},
	issn = {0266-5611},
	url = {http://stacks.iop.org/0266-5611/18/i=5/a=315?key=crossref.14e72c694543fa8b0a66154030f31380},
	doi = {10.1088/0266-5611/18/5/315},
	number = {5},
	urldate = {2017-01-20},
	journal = {Inverse Problems},
	author = {Gourion, Daniel and Noll, Dominikus},
	month = oct,
	year = {2002},
	pages = {1435--1460},
}

@article{fell_resolution_2016,
	title = {Resolution of the {Wavefront} {Set} {Using} {General} {Continuous} {Wavelet} {Transforms}},
	volume = {22},
	issn = {1069-5869, 1531-5851},
	url = {http://link.springer.com/10.1007/s00041-015-9445-7},
	doi = {10.1007/s00041-015-9445-7},
	language = {en},
	number = {5},
	urldate = {2017-01-20},
	journal = {Journal of Fourier Analysis and Applications},
	author = {Fell, Jonathan and F{\"u}hr, Hartmut and Voigtlaender, Felix},
	month = oct,
	year = {2016},
	pages = {997--1058},
}

@article{chen_variable_2006,
	title = {Variable {Exponent}, {Linear} {Growth} {Functionals} in {Image} {Restoration}},
	volume = {66},
	issn = {0036-1399, 1095-712X},
	url = {http://epubs.siam.org/doi/abs/10.1137/050624522},
	doi = {10.1137/050624522},
	language = {en},
	number = {4},
	urldate = {2017-01-20},
	journal = {SIAM Journal on Applied Mathematics},
	author = {Chen, Yunmei and Levine, Stacey and Rao, Murali},
	month = jan,
	year = {2006},
	pages = {1383--1406},
}

@article{esser_general_2010,
	title = {A {General} {Framework} for a {Class} of {First} {Order} {Primal}-{Dual} {Algorithms} for {Convex} {Optimization} in {Imaging} {Science}},
	volume = {3},
	issn = {1936-4954},
	url = {http://epubs.siam.org/doi/abs/10.1137/09076934X},
	doi = {10.1137/09076934X},
	language = {en},
	number = {4},
	urldate = {2017-01-20},
	journal = {SIAM Journal on Imaging Sciences},
	author = {Esser, Ernie and Zhang, Xiaoqun and Chan, Tony F.},
	month = jan,
	year = {2010},
	pages = {1015--1046},
}

@article{yang_parallel_2006,
	title = {Parallel {Implementation} of {Katsevich}'s {FBP} {Algorithm}},
	volume = {2006},
	issn = {1687-4188, 1687-4196},
	url = {http://www.hindawi.com/journals/ijbi/2006/017463/abs/},
	doi = {10.1155/IJBI/2006/17463},
	language = {en},
	urldate = {2017-01-20},
	journal = {International Journal of Biomedical Imaging},
	author = {Yang, Jiansheng and Guo, Xiaohu and Kong, Qiang and Zhou, Tie and Jiang, Ming},
	year = {2006},
	pages = {1--8},
}

@inproceedings{zhu_numerical_2004,
	title = {Numerical studies on {Feldkamp}-type and {Katsevich}-type algorithms for cone-beam scanning along nonstandard spirals},
	url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.559876},
	doi = {10.1117/12.559876},
	urldate = {2017-01-20},
	author = {Zhu, Jiehua and Zhao, Shiying and Yu, Hengyong and Ye, Yangbo and Lee, Seung Wook and Wang, Ge},
	editor = {Bonse, Ulrich},
	month = oct,
	year = {2004},
	pages = {558},
}

@article{smith_mathematical_1985,
	title = {Mathematical foundations of computed tomography},
	volume = {24},
	copyright = {{\textcopyright} 1985 Optical Society of America},
	issn = {1539-4522},
	url = {http://www.osapublishing.org/abstract.cfm?uri=ao-24-23-3950},
	doi = {10.1364/AO.24.003950},
	abstract = {Along with a review of some of the mathematical foundations of computed tomography, the article contains new results on derivation of reconstruction formulas in a general setting encompassing all standard formulas; discussion and examples of the role of the point spread function with recipes for producing suitable ones; formulas for, and examples of, the reconstruction of certain functions of the attenuation coefficient, e.g., sharpened versions of it, some of them with the property that reconstruction at a point requires only the attenuation along rays meeting a small neighborhood of the point.},
	language = {EN},
	number = {23},
	urldate = {2017-01-25},
	journal = {Applied Optics},
	author = {Smith, Kennan T. and Keinert, F.},
	month = dec,
	year = {1985},
	pages = {3950--3957}
}

@article{marr_theory_1980,
	title = {Theory of edge detection},
	volume = {207},
	issn = {0950-1193},
	abstract = {A theory of edge detection is presented. The analysis proceeds in two parts. (1) Intensity changes, which occur in a natural image over a wide range of scales, are detected separately at different scales. An appropriate filter for this purpose at a given scale is found to be the second derivative of a Gaussian, and it is shown that, provided some simple conditions are satisfied, these primary filters need not be orientation-dependent. Thus, intensity changes at a given scale are best detected by finding the zero values of delta 2G(x,y)*I(x,y) for image I, where G(x,y) is a two-dimensional Gaussian distribution and delta 2 is the Laplacian. The intensity changes thus discovered in each of the channels are then represented by oriented primitives called zero-crossing segments, and evidence is given that this representation is complete. (2) Intensity changes in images arise from surface discontinuities or from reflectance or illumination boundaries, and these all have the property that they are spatially. Because of this, the zero-crossing segments from the different channels are not independent, and rules are deduced for combining them into a description of the image. This description is called the raw primal sketch. The theory explains several basic psychophysical findings, and the operation of forming oriented zero-crossing segments from the output of centre-surround delta 2G filters acting on the image forms the basis for a physiological model of simple cells (see Marr \& Ullman 1979).},
	language = {eng},
	number = {1167},
	journal = {Proceedings of the Royal Society of London. Series B, Biological Sciences},
	author = {Marr, D. and Hildreth, E.},
	month = feb,
	year = {1980},
	pmid = {6102765},
	pages = {187--217},
}

@article{park_priori_2015,
	title = {Priori mask guided image reconstruction (p-{MGIR}) for ultra-low dose cone-beam computed tomography},
	volume = {60},
	issn = {0031-9155},
	url = {http://stacks.iop.org/0031-9155/60/i=21/a=8505},
	doi = {10.1088/0031-9155/60/21/8505},
	abstract = {Recently, the compressed sensing (CS) based iterative reconstruction method has received attention because of its ability to reconstruct cone beam computed tomography (CBCT) images with good quality using sparsely sampled or noisy projections, thus enabling dose reduction. However, some challenges remain. In particular, there is always a tradeoff between image resolution and noise/streak artifact reduction based on the amount of regularization weighting that is applied uniformly across the CBCT volume. The purpose of this study is to develop a novel low-dose CBCT reconstruction algorithm framework called priori mask guided image reconstruction ( p -MGIR) that allows reconstruction of high-quality low-dose CBCT images while preserving the image resolution. In p- MGIR, the unknown CBCT volume was mathematically modeled as a combination of two regions: (1) where anatomical structures are complex, and (2) where intensities are relatively uniform. The priori mask, which is the key concept of the p- MGIR algorithm, was defined as the matrix that distinguishes between the two separate CBCT regions where the resolution needs to be preserved and where streak or noise needs to be suppressed. We then alternately updated each part of image by solving two sub-minimization problems iteratively, where one minimization was focused on preserving the edge information of the first part while the other concentrated on the removal of noise/artifacts from the latter part. To evaluate the performance of the p- MGIR algorithm, a numerical head-and-neck phantom, a Catphan 600 physical phantom, and a clinical head-and-neck cancer case were used for analysis. The results were compared with the standard Feldkamp-Davis-Kress as well as conventional CS-based algorithms. Examination of the p- MGIR algorithm showed that high-quality low-dose CBCT images can be reconstructed without compromising the image resolution. For both phantom and the patient cases, the p- MGIR is able to achieve a clinically-reasonable image with 60 projections. Therefore, a clinically-viable, high-resolution head-and-neck CBCT image can be obtained while cutting the dose by 83\%. Moreover, the image quality obtained using p- MGIR is better than the quality obtained using other algorithms. In this work, we propose a novel low-dose CBCT reconstruction algorithm called p- MGIR. It can be potentially used as a CBCT reconstruction algorithm with low dose scan requests},
	language = {en},
	number = {21},
	urldate = {2017-02-17},
	journal = {Physics in Medicine and Biology},
	author = {Park, Justin C. and Zhang, Hao and Chen, Yunmei and Fan, Qiyong and Kahler, Darren L. and Liu, Chihray and Lu, Bo},
	year = {2015},
	pages = {8505},
}

@article{lorenz_flexible_2017,
	title = {Flexible sparse regularization},
	volume = {33},
	issn = {0266-5611},
	url = {http://stacks.iop.org/0266-5611/33/i=1/a=014002},
	doi = {10.1088/0266-5611/33/1/014002},
	abstract = {The seminal paper of Daubechies, Defrise, DeMol made clear that \#\#IMG\#\# [http://ej.iop.org/images/0266-5611/33/1/014002/ipaa4552ieqn1.gif] \${\textbackslash}ell {\textasciicircum}p\$ spaces with \#\#IMG\#\# [http://ej.iop.org/images/0266-5611/33/1/014002/ipaa4552ieqn2.gif] \$p{\i}n [1,2)\$ and p -powers of the corresponding norms are appropriate settings for dealing with reconstruction of sparse solutions of ill-posed problems by regularization. It seems that the case p = 1 provides the best results in most of the situations compared to the cases \#\#IMG\#\# [http://ej.iop.org/images/0266-5611/33/1/014002/ipaa4552ieqn3.gif] \$p{\i}n (1,2)\$ . An extensive literature gives great credit also to using \#\#IMG\#\# [http://ej.iop.org/images/0266-5611/33/1/014002/ipaa4552ieqn4.gif] \${\textbackslash}ell {\textasciicircum}p\$ spaces with \#\#IMG\#\# [http://ej.iop.org/images/0266-5611/33/1/014002/ipaa4552ieqn5.gif] \$p{\i}n (0,1)\$ together with the corresponding quasi-norms, although one has to tackle challenging numerical problems raised by the non-convexity of the quasi-norms. In any of these settings, either superlinear, linear or sublinear, the question of how to choose the exponent p has been not only a numerical issue, but also a philosophical one. In this work we introduce a more flexible way of sparse regularization by varying exponents. We introduce the corresponding functional analytic framework, that leaves the setting of normed spaces but works with so-called F-norms. One curious result is that there are F-norms which generate the l 1 space, but they are strictly convex, while the l 1 -norm is just convex.},
	language = {en},
	number = {1},
	urldate = {2017-02-17},
	journal = {Inverse Problems},
	author = {Lorenz, Dirk A. and Resmerita, Elena},
	year = {2017},
	pages = {014002},
}

@article{samashvili_wavelet_2015,
	title = {The {Wavelet} {Characterization} of the {Variable} {Exponent} {Lebesgue} {Space}},
	volume = {19},
	abstract = {The paper deals with unconditional wavelet bases in variable exponent Lebesgue spacesInhomogeneous wavelets of Daubechies type are considered. Some conditions for exponents
are found for which the Daubechies wavelet system is an unconditional basis in Lp({\textperiodcentered}) (Rn) space.},
	number = {2},
	journal = {Bulletin of TICMI},
	author = {Samashvili, Nino},
	year = {2015},
	pages = {3--9},
}

@book{zuo_advanced_2017,
	address = {New York, NY},
	title = {Advanced {Transmission} {Electron} {Microscopy}},
	isbn = {978-1-4939-6605-9 978-1-4939-6607-3},
	url = {http://link.springer.com/10.1007/978-1-4939-6607-3},
	language = {en},
	urldate = {2017-02-17},
	publisher = {Springer New York},
	author = {Zuo, Jian Min and Spence, John C.H.},
	year = {2017},
	note = {DOI: 10.1007/978-1-4939-6607-3},
}

@article{chambolle_introduction_2016,
	title = {An introduction to continuous optimization for imaging},
	volume = {25},
	issn = {0962-4929, 1474-0508},
	url = {http://www.journals.cambridge.org/abstract_S096249291600009X},
	doi = {10.1017/S096249291600009X},
	language = {en},
	urldate = {2017-02-18},
	journal = {Acta Numerica},
	author = {Chambolle, Antonin and Pock, Thomas},
	month = may,
	year = {2016},
	pages = {161--319},
}

@article{quinto_singularities_1993,
	title = {Singularities of the \{{X}\}-{Ray} {Transform} and {Limited} {Data} {Tomography} in \${\textbackslash}mathbb\{{R}\}{\textasciicircum}2 \$ and \${\textbackslash}mathbb\{{R}\}{\textasciicircum}3 \$},
	volume = {24},
	issn = {0036-1410},
	url = {http://epubs.siam.org/doi/abs/10.1137/0524069},
	doi = {10.1137/0524069},
	abstract = {Given a function f, the author specifies the singularities of f that are visible in a stable way from limited X-ray tomographic data. This determines which singularities of f can be stably recovered from limited data and which cannot, no matter how good the inversion algorithm. Microlocal analysis is used to determine the relationship between the singularities of a function f and those of its X-ray transform. The results are applied to determine the singularities that are visible for limited angle tomography and the interior and exterior problems. The author also suggests a practical method to use this relationship to reconstruct singularities of f from limited data \$Rf\$. The X-ray transform with sources on a curve in \${\textbackslash}mathbb\{R\}{\textasciicircum}3 \$ is also analyzed.},
	number = {5},
	urldate = {2017-02-23},
	journal = {SIAM Journal on Mathematical Analysis},
	author = {Quinto, E.},
	month = sep,
	year = {1993},
	pages = {1215--1225},
}

@article{faridani_local_1992,
	title = {Local {Tomography}},
	volume = {52},
	issn = {0036-1399},
	url = {http://epubs.siam.org/doi/10.1137/0152026},
	doi = {10.1137/0152026},
	abstract = {Tomography produces the reconstruction of a function f from a large number of line integrals of f. Conventional tomography is a global procedure in that the standard convolution formulas for reconstruction at a single point require the integrals over all lines within some plane containing the point. Local tomography, as introduced initially, produced the reconstruction of the related function \${\textbackslash}Lambda f\$, where \${\textbackslash}Lambda \$ is the square root of \$ - {\textbackslash}Delta \$, the positive Laplace operator. The reconstruction of \${\textbackslash}Lambda f\$ is local in that reconstruction at a point requires integrals only over lines passing infinitesimally close to the point, and \${\textbackslash}Lambda f\$ has the same smooth regions and boundaries as f. However, \${\textbackslash}Lambda f\$ is cupped in regions where f is constant. \${\textbackslash}Lambda {\textasciicircum}\{ - 1\} f\$, also amenable to local reconstruction, is smooth everywhere and contains a counter-cup. This article provides a detailed study of the actions of \${\textbackslash}Lambda \$ and \${\textbackslash}Lambda {\textasciicircum}\{ - 1\} \$, and shows several examples of what can be achieved with a linear combination. It includes the results of x-ray experiments in which the line integrals are obtained from attenuation measurements on two-dimensional image intensifiers and fluorescent screens, instead of the usual linear detector arrays.},
	number = {2},
	urldate = {2017-02-23},
	journal = {SIAM Journal on Applied Mathematics},
	author = {Faridani, A. and Ritman, E. and Smith, K.},
	month = apr,
	year = {1992},
	pages = {459--484},
}

@article{ehrhardt_joint_2015,
	title = {Joint reconstruction of {PET}-{MRI} by exploiting structural similarity},
	volume = {31},
	issn = {0266-5611},
	url = {http://stacks.iop.org/0266-5611/31/i=1/a=015001},
	doi = {10.1088/0266-5611/31/1/015001},
	abstract = {Recent advances in technology have enabled the combination of positron emission tomography (PET) with magnetic resonance imaging (MRI). These PET-MRI scanners simultaneously acquire functional PET and anatomical or functional MRI data. As function and anatomy are not independent of one another the images to be reconstructed are likely to have shared structures. We aim to exploit this inherent structural similarity by reconstructing from both modalities in a joint reconstruction framework. The structural similarity between two modalities can be modelled in two different ways: edges are more likely to be at similar positions and/or to have similar orientations. We analyse the diffusion process generated by minimizing priors that encapsulate these different models. It turns out that the class of parallel level set priors always corresponds to anisotropic diffusion which is sometimes forward and sometimes backward diffusion. We perform numerical experiments where we jointly reconstruct from blurred Radon data with Poisson noise (PET) and under-sampled Fourier data with Gaussian noise (MRI). Our results show that both modalities benefit from each other in areas of shared edge information. The joint reconstructions have less artefacts and sharper edges compared to separate reconstructions and the l 2 -error can be reduced in all of the considered cases of under-sampling.},
	language = {en},
	number = {1},
	urldate = {2017-02-23},
	journal = {Inverse Problems},
	author = {Ehrhardt, Matthias J. and Thielemans, Kris and Pizarro, Luis and Atkinson, David and Ourselin, S{\'e}bastien and Hutton, Brian F. and Arridge, Simon R.},
	year = {2015},
	pages = {015001},
}

@article{kinahan_dual_2006,
	title = {Dual {Energy} {CT} {Attenuation} {Correction} {Methods} for {Quantitative} {Assessment} of {Response} to {Cancer} {Therapy} with {PET}/{CT} {Imaging}},
	volume = {5},
	issn = {1533-0346},
	url = {http://dx.doi.org/10.1177/153303460600500403},
	doi = {10.1177/153303460600500403},
	abstract = {We hypothesize that improved quantification for PET imaging of high atomic number materials can be achieved by combining low-dose x-ray imaging with dual energy CT for PET attenuation correction. Improved quantification of tracer uptake will lead to improved patient outcomes by providing more accurate information for therapeutic choices. Accurate PET/CT measurements of early response will be critical in determining the best cancer therapy option for each patient in a timely manner and in sparing patients the morbidity and cost of ineffective treatments. We first evaluate the potential errors in PET images arising from CT-based attenuation correction when iodine-based contrast is incorrectly classified as bone when forming the linear attenuation coefficient image. We then investigate two methods of reducing errors in the linear attenuation image: an approximate, but fast, hybrid classification/scaling algorithm and a model-based dual-energy CT method that incorporates the polyenergetic spectrum and a noise model in an iterative reconstruction method. Both methods are shown to reduce errors in the estimated linear attenuation coefficient image, but require further study to determine the effects of noise propagation if low-dose CT scans are used for the estimation of the linear attenuation image.},
	language = {en},
	number = {4},
	urldate = {2017-02-23},
	journal = {Technology in Cancer Research \& Treatment},
	author = {Kinahan, Paul E. and Alessio, Adam M. and Fessler, Jeffrey A.},
	month = aug,
	year = {2006},
	pages = {319--327},
}

@incollection{bal_combined_2011,
	address = {Providence, Rhode Island},
	title = {Combined source and attenuation reconstructions in {SPECT}},
	volume = {559},
	isbn = {978-0-8218-5301-6 978-0-8218-8238-2},
	url = {http://www.ams.org/conm/559/},
	language = {en},
	urldate = {2017-02-23},
	booktitle = {Contemporary {Mathematics}},
	publisher = {American Mathematical Society},
	author = {Bal, Guillaume and Jollivet, Alexandre},
	editor = {Bal, Guillaume and Finch, David and Kuchment, Peter and Schotland, John and Stefanov, Plamen and Uhlmann, Gunther and Uhlmann, Gunther},
	year = {2011},
	note = {DOI: 10.1090/conm/559/11068},
	pages = {13--27},
}

@article{adler_operator_2017,
	title = {Operator {Discretization} {Library} ({ODL})},
	url = {https://doi.org/10.5281/zenodo.249479},
	doi = {10.5281/zenodo.249479},
	urldate = {2017-02-24},
	author = {Adler, Jonas and Kohr, Holger and {\"O}ktem, Ozan},
	year = {2017}
}

@article{bot_douglas--rachford_2013,
	title = {A {Douglas}--{Rachford} {Type} {Primal}-{Dual} {Method} for {Solving} {Inclusions} with {Mixtures} of {Composite} and {Parallel}-{Sum} {Type} {Monotone} {Operators}},
	volume = {23},
	issn = {1052-6234, 1095-7189},
	url = {http://epubs.siam.org/doi/10.1137/120901106},
	doi = {10.1137/120901106},
	language = {en},
	number = {4},
	urldate = {2017-02-24},
	journal = {SIAM Journal on Optimization},
	author = {Bo{\c t}, Radu Ioan and Hendrich, Christopher},
	month = jan,
	year = {2013},
	pages = {2541--2565},
}

@article{bot_convergence_2015,
	title = {On the convergence rate of a forward-backward type primal-dual splitting algorithm for convex optimization problems},
	volume = {64},
	issn = {0233-1934, 1029-4945},
	url = {http://www.tandfonline.com/doi/abs/10.1080/02331934.2014.966306},
	doi = {10.1080/02331934.2014.966306},
	language = {en},
	number = {1},
	urldate = {2017-02-24},
	journal = {Optimization},
	author = {Bo{\c t}, Radu Ioan and Csetnek, Ern{\"o} Robert},
	month = jan,
	year = {2015},
	pages = {5--23},
}

@article{van_der_walt_numpy_2011,
	title = {The {NumPy} {Array}: {A} {Structure} for {Efficient} {Numerical} {Computation}},
	volume = {13},
	issn = {1521-9615},
	shorttitle = {The {NumPy} {Array}},
	url = {http://ieeexplore.ieee.org/document/5725236/},
	doi = {10.1109/MCSE.2011.37},
	number = {2},
	urldate = {2017-02-24},
	journal = {Computing in Science \& Engineering},
	author = {van der Walt, St{\'e}fan and Colbert, S Chris and Varoquaux, Ga{\"e}l},
	month = mar,
	year = {2011},
	pages = {22--30},
}

@article{behnel_cython:_2011,
	title = {Cython: {The} {Best} of {Both} {Worlds}},
	volume = {13},
	issn = {1521-9615},
	shorttitle = {Cython},
	url = {http://ieeexplore.ieee.org/document/5582062/},
	doi = {10.1109/MCSE.2010.118},
	number = {2},
	urldate = {2017-02-24},
	journal = {Computing in Science \& Engineering},
	author = {Behnel, Stefan and Bradshaw, Robert and Citro, Craig and Dalcin, Lisandro and Seljebotn, Dag Sverre and Smith, Kurt},
	month = mar,
	year = {2011},
	pages = {31--39},
}

@misc{noauthor_numba_nodate,
	title = {Numba {\textemdash} {Numba}},
	url = {http://numba.pydata.org/},
	urldate = {2017-02-24}
}

@article{al-rfou_theano:_2016,
	title = {Theano: {A} {Python} framework for fast computation of mathematical expressions},
	shorttitle = {Theano},
	url = {http://arxiv.org/abs/1605.02688},
	abstract = {Theano is a Python library that allows to define, optimize, and evaluate mathematical expressions involving multi-dimensional arrays efficiently. Since its introduction, it has been one of the most used CPU and GPU mathematical compilers - especially in the machine learning community - and has shown steady performance improvements. Theano is being actively and continuously developed since 2008, multiple frameworks have been built on top of it and it has been used to produce many state-of-the-art machine learning models. The present article is structured as follows. Section I provides an overview of the Theano software and its community. Section II presents the principal features of Theano and how to use them, and compares them with other similar projects. Section III focuses on recently-introduced functionalities and improvements. Section IV compares the performance of Theano against Torch7 and TensorFlow on several machine learning models. Section V discusses current limitations of Theano and potential ways of improving it.},
	urldate = {2017-02-24},
	journal = {arXiv:1605.02688 [cs]},
	author = {Al-Rfou, Rami and Alain, Guillaume and Almahairi, Amjad and Angermueller, Christof and Bahdanau, Dzmitry and Ballas, Nicolas and Bastien, Fr{\'e}d{\'e}ric and Bayer, Justin and Belikov, Anatoly and Belopolsky, Alexander and Bengio, Yoshua and Bergeron, Arnaud and Bergstra, James and Bisson, Valentin and Snyder, Josh Bleecher and Bouchard, Nicolas and Boulanger-Lewandowski, Nicolas and Bouthillier, Xavier and de Br{\'e}bisson, Alexandre and Breuleux, Olivier and Carrier, Pierre-Luc and Cho, Kyunghyun and Chorowski, Jan and Christiano, Paul and Cooijmans, Tim and C{\^o}t{\'e}, Marc-Alexandre and C{\^o}t{\'e}, Myriam and Courville, Aaron and Dauphin, Yann N. and Delalleau, Olivier and Demouth, Julien and Desjardins, Guillaume and Dieleman, Sander and Dinh, Laurent and Ducoffe, M{\'e}lanie and Dumoulin, Vincent and Kahou, Samira Ebrahimi and Erhan, Dumitru and Fan, Ziye and Firat, Orhan and Germain, Mathieu and Glorot, Xavier and Goodfellow, Ian and Graham, Matt and Gulcehre, Caglar and Hamel, Philippe and Harlouchet, Iban and Heng, Jean-Philippe and Hidasi, Bal{\'a}zs and Honari, Sina and Jain, Arjun and Jean, S{\'e}bastien and Jia, Kai and Korobov, Mikhail and Kulkarni, Vivek and Lamb, Alex and Lamblin, Pascal and Larsen, Eric and Laurent, C{\'e}sar and Lee, Sean and Lefrancois, Simon and Lemieux, Simon and L{\'e}onard, Nicholas and Lin, Zhouhan and Livezey, Jesse A. and Lorenz, Cory and Lowin, Jeremiah and Ma, Qianli and Manzagol, Pierre-Antoine and Mastropietro, Olivier and McGibbon, Robert T. and Memisevic, Roland and van Merri{\"e}nboer, Bart and Michalski, Vincent and Mirza, Mehdi and Orlandi, Alberto and Pal, Christopher and Pascanu, Razvan and Pezeshki, Mohammad and Raffel, Colin and Renshaw, Daniel and Rocklin, Matthew and Romero, Adriana and Roth, Markus and Sadowski, Peter and Salvatier, John and Savard, Fran{\c c}ois and Schl{\"u}ter, Jan and Schulman, John and Schwartz, Gabriel and Serban, Iulian Vlad and Serdyuk, Dmitriy and Shabanian, Samira and Simon, {\'E}tienne and Spieckermann, Sigurd and Subramanyam, S. Ramana and Sygnowski, Jakub and Tanguay, J{\'e}r{\'e}mie and van Tulder, Gijs and Turian, Joseph and Urban, Sebastian and Vincent, Pascal and Visin, Francesco and de Vries, Harm and Warde-Farley, David and Webb, Dustin J. and Willson, Matthew and Xu, Kelvin and Xue, Lijun and Yao, Li and Zhang, Saizheng and Zhang, Ying},
	month = may,
	year = {2016},
	note = {arXiv: 1605.02688},
}

@article{chambolle_image_1997-1,
	title = {Image recovery via total variation minimization and related problems},
	volume = {76},
	issn = {0029-599X, 0945-3245},
	url = {http://link.springer.com/10.1007/s002110050258},
	doi = {10.1007/s002110050258},
	number = {2},
	urldate = {2017-02-26},
	journal = {Numerische Mathematik},
	author = {Chambolle, Antonin and Lions, Pierre-Louis},
	month = apr,
	year = {1997},
	pages = {167--188},
}

@article{ring_structural_2000,
	title = {Structural {Properties} of {Solutions} to {Total} {Variation} {Regularization} {Problems}},
	volume = {34},
	issn = {0764-583X, 1290-3841},
	url = {http://www.esaim-m2an.org/10.1051/m2an:2000104},
	doi = {10.1051/m2an:2000104},
	number = {4},
	urldate = {2017-02-26},
	journal = {ESAIM: Mathematical Modelling and Numerical Analysis},
	author = {Ring, Wolfgang},
	month = jul,
	year = {2000},
	pages = {799--810},
}

@inproceedings{blomgren_total_1997,
	title = {Total variation image restoration: numerical methods and extensions},
	volume = {3},
	isbn = {978-0-8186-8183-7},
	shorttitle = {Total variation image restoration},
	url = {http://ieeexplore.ieee.org/document/632128/},
	doi = {10.1109/ICIP.1997.632128},
	urldate = {2017-02-26},
	booktitle = {Proceedings of the {International} {Conference} on {Image} {Processing}},
	publisher = {IEEE Comput. Soc},
	author = {Blomgren, P. and Chan, T.F. and Mulet, P. and Wong, C.K.},
	year = {1997},
	pages = {384--387},
}

@inproceedings{chan_fourth_2010,
	title = {A fourth order dual method for staircase reduction in texture extraction and image restoration problems},
	isbn = {978-1-4244-7992-4},
	url = {http://ieeexplore.ieee.org/document/5653199/},
	doi = {10.1109/ICIP.2010.5653199},
	urldate = {2017-02-26},
	publisher = {IEEE},
	author = {Chan, Tony F. and Esedoglu, Selim and Park, Frederick},
	month = sep,
	year = {2010},
	pages = {4137--4140},
}

@article{yang_convolutional_2017,
	title = {A convolutional neural network approach to calibrating the rotation axis for {X}-ray computed tomography},
	volume = {24},
	issn = {1600-5775},
	url = {http://scripts.iucr.org/cgi-bin/paper?S1600577516020117},
	doi = {10.1107/S1600577516020117},
	number = {2},
	urldate = {2017-02-28},
	journal = {Journal of Synchrotron Radiation},
	author = {Yang, Xiaogang and De Carlo, Francesco and Phatak, Charudatta and G{\"u}rsoy, Dog?a},
	month = mar,
	year = {2017},
	pages = {469--475},
}

@article{jin_deep_2016,
	title = {Deep {Convolutional} {Neural} {Network} for {Inverse} {Problems} in {Imaging}},
	url = {http://arxiv.org/abs/1611.03679},
	abstract = {In this paper, we propose a novel deep convolutional neural network (CNN)-based algorithm for solving ill-posed inverse problems. Regularized iterative algorithms have emerged as the standard approach to ill-posed inverse problems in the past few decades. These methods produce excellent results, but can be challenging to deploy in practice due to factors including the high computational cost of the forward and adjoint operators and the difficulty of hyper parameter selection. The starting point of our work is the observation that unrolled iterative methods have the form of a CNN (filtering followed by point-wise non-linearity) when the normal operator (H*H, the adjoint of H times H) of the forward model is a convolution. Based on this observation, we propose using direct inversion followed by a CNN to solve normal-convolutional inverse problems. The direct inversion encapsulates the physical model of the system, but leads to artifacts when the problem is ill-posed; the CNN combines multiresolution decomposition and residual learning in order to learn to remove these artifacts while preserving image structure. We demonstrate the performance of the proposed network in sparse-view reconstruction (down to 50 views) on parallel beam X-ray computed tomography in synthetic phantoms as well as in real experimental sinograms. The proposed network outperforms total variation-regularized iterative reconstruction for the more realistic phantoms and requires less than a second to reconstruct a 512 x 512 image on GPU.},
	urldate = {2017-02-28},
	journal = {arXiv:1611.03679 [cs]},
	author = {Jin, Kyong Hwan and McCann, Michael T. and Froustey, Emmanuel and Unser, Michael},
	month = nov,
	year = {2016},
	note = {arXiv: 1611.03679},
}

@article{chen_image_2017,
	title = {Image correction for cone-beam computed tomography simulator using neural network corrector},
	volume = {9},
	issn = {1687-8140},
	url = {http://dx.doi.org/10.1177/1687814017690476},
	doi = {10.1177/1687814017690476},
	abstract = {In this article, a neural network corrector is proposed to correct the image shift, yielding the degradation of three-dimensional image reconstruction, for each slice captured by cone-beam computed tomography simulator. There are 3 degrees of freedom in tube module of simulator; the central point of tube module should be aligned with the central point of detector module to guarantee the accurate image projection. However, the mechanism manufacturing and assembling tolerance will let the above aim cannot be met. Here, a standard kit is made to measure the image shift by 1{\textdegree} step from -10{\textdegree} to 10{\textdegree}. The measure data will be the input training data of proposed neural network corrector, and the corrected translation position will be the output of neural network corrector. The Levenberg{\textendash}Marquardt learning algorithm adjusts the connected weights and biases of the neural network using a supervised gradient descent method, such that the defined error function can be minimized. To avoid the problem of overfitting and improve the generalized ability of the neural network, Bayesian regularization is added to the Levenberg{\textendash}Marquardt learning algorithm. After the training of neural network corrector, the different target position commands are fed into the neural network corrector. Then, the corrected data from neural network corrector are fed to be the new position command to verify the image correction performance. Moreover, a phantom kit is made to check the corrected performance of the neural network corrector. Finally, the experimental results verify that the image shift can be reduced by the neural network corrector.},
	language = {en},
	number = {2},
	urldate = {2017-02-28},
	journal = {Advances in Mechanical Engineering},
	author = {Chen, Chin-Sheng and Hsu, Cheng-Yi and Chen, Shih-Kang and Lin, Chih-Jer and Hsieh, Ching-Hao and Liu, Yi-Hung},
	month = feb,
	year = {2017},
	pages = {1687814017690476},
}

@inproceedings{batenburg_neural_2006,
	title = {A {Neural} {Network} {Approach} to {Real}-{Time} {Discrete} {Tomography}},
	url = {https://link.springer.com/chapter/10.1007/11774938_31},
	abstract = {Tomography deals with the reconstruction of the density distribution inside an unknown object from its projections in several directions. In Discrete tomography one focuses on the reconstruction of objects having a small, discrete set of density values. Using this prior knowledge in the reconstruction algorithm may vastly reduce the number of projections that is required to obtain high quality reconstructions.Recently the first generation of real-time tomographic scanners has appeared, capable of acquiring several images per second. Discrete tomography is well suited for real-time operation, as only few projections are required, reducing scanning time. However, for efficient real-time operation an extremely fast reconstruction algorithm is also required.In this paper we present a new reconstruction method, which is based on a feed-forward neural network. The network can compute reconstructions extremely fast, making it suitable for real-time tomography. Our experimental results demonstrate that the approach achieves good reconstruction quality.},
	language = {en},
	urldate = {2017-02-28},
	booktitle = {Combinatorial {Image} {Analysis}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Batenburg, K. J. and Kosters, W. A.},
	month = jun,
	year = {2006},
	note = {DOI: 10.1007/11774938\_31},
	pages = {389--403},
}

@article{bleichrodt_easy_2016,
	title = {Easy implementation of advanced tomography algorithms using the {ASTRA} toolbox with {Spot} operators},
	volume = {71},
	issn = {1017-1398, 1572-9265},
	url = {https://link.springer.com/article/10.1007/s11075-015-0016-4},
	doi = {10.1007/s11075-015-0016-4},
	abstract = {Mathematical scripting languages are commonly used to develop new tomographic reconstruction algorithms. For large experimental datasets, high performance parallel (GPU) implementations are essential, requiring a re-implementation of the algorithm using a language that is closer to the computing hardware. In this paper, we introduce a new MATLAB interface to the ASTRA toolbox, a high performance toolbox for building tomographic reconstruction algorithms. By exposing the ASTRA linear tomography operators through a standard MATLAB matrix syntax, existing and new reconstruction algorithms implemented in MATLAB can now be applied directly to large experimental datasets. This is achieved by using the Spot toolbox, which wraps external code for linear operations into MATLAB objects that can be used as matrices. We provide a series of examples that demonstrate how this Spot operator can be used in combination with existing algorithms implemented in MATLAB and how it can be used for rapid development of new algorithms, resulting in direct applicability to large-scale experimental datasets.},
	language = {en},
	number = {3},
	urldate = {2017-02-28},
	journal = {Numerical Algorithms},
	author = {Bleichrodt, Folkert and Leeuwen, Tristan van and Palenstijn, Willem Jan and Aarle, Wim van and Sijbers, Jan and Batenburg, K. Joost},
	month = mar,
	year = {2016},
	pages = {673--697},
}

@inproceedings{putzke_recurrent_nodate,
	title = {Recurrent {Inference} {Machines} for solving {Inverse} {Problems}},
	abstract = {Inverse problems are typically solved by first defining a model and then choosing
an inference procedure. With this separation of modeling from inference, inverse
problems can be framed in a modular way. For example, variational inference
can be applied to a broad class of models. The modularity, however, typically
goes away after model parameters have been trained under a chosen inference
procedure. During training, model and inference often interact in a way that the
model parameters will ultimately be adapted to the chosen inference procedure,
posing the two components inseparable after training. But if model and inference
become inseperable after training, why separate them in the first place?
We propose a novel learning framework which abandons the dichotomy between
model and inference. Instead, we introduce Recurrent Inference Machines (RIM),
a class of recurrent neural networks (RNN), that directly learn to solve inverse
problems.
We demonstrate the effectiveness of RIMs in experiments on various image recon-
struction tasks. We show empirically that RIMs exhibit the desirable convergence
behavior of classical inference procedures, and that they can outperform state-of-
the-art methods when trained on specialized inference tasks.
Our approach bridges the gap between inverse problems and deep learning, pro-
viding a framework for fast progression in the field of inverse problems.},
	author = {Putzke, Patrick and Welling, Max},
}

@incollection{chan_total_2006,
	title = {Total {Variation} {Image} {Restoration}: {Overview} and {Recent} {Developments}},
	copyright = {{\textcopyright}2006 Springer Science+Business Media, Inc.},
	isbn = {978-0-387-26371-7 978-0-387-28831-4},
	shorttitle = {Total {Variation} {Image} {Restoration}},
	url = {http://link.springer.com/chapter/10.1007/0-387-28831-7_2},
	abstract = {Since their introduction in a classic paper by Rudin, Osher and Fatemi [695], total variation minimizing models have become one of the most popular and successful methodology for image restoration. More recently, there has been a resurgence of interest and exciting new developments, some extending the applicabilities to impainting, blind deconvolution and vector-valued images, while others offer improvements in better preservation of contrast, geometry and textures, in ameliorating the staircasing effect, and in exploiting the multiscale nature of the models. In addition, new computational methods have been proposed with improved computational speed and robustness. We shall review some of these recent developments.},
	language = {en},
	urldate = {2017-03-04},
	booktitle = {Handbook of {Mathematical} {Models} in {Computer} {Vision}},
	publisher = {Springer US},
	author = {Chan, T. and Esedoglu, S. and Park, F. and Yip, A.},
	editor = {Paragios, Nikos and Chen, Yunmei and Faugeras, Olivier},
	year = {2006},
	note = {DOI: 10.1007/0-387-28831-7\_2},
	pages = {17--31},
}

@article{kirisits_convergence_2016,
	title = {Convergence rates for regularization functionals with polyconvex integrands},
	url = {http://arxiv.org/abs/1612.06724},
	abstract = {Convergence rates results for variational regularization methods typically assume the regularization functional to be convex. While this assumption is natural for scalar-valued functions, it can be unnecessarily strong for vector-valued ones. In this paper we focus on regularization functionals with polyconvex integrands. Even though such functionals are nonconvex in general, it is possible to derive linear convergence rates with respect to a generalized Bregman distance, an idea introduced by Grasmair in 2010. As a case example we consider the image registration problem.},
	urldate = {2017-03-04},
	journal = {arXiv:1612.06724 [math]},
	author = {Kirisits, Clemens and Scherzer, Otmar},
	month = dec,
	year = {2016},
	note = {arXiv: 1612.06724},
}

@article{rudin_nonlinear_1992,
	title = {Nonlinear total variation based noise removal algorithms},
	volume = {60},
	issn = {01672789},
	url = {http://linkinghub.elsevier.com/retrieve/pii/016727899290242F},
	doi = {10.1016/0167-2789(92)90242-F},
	language = {en},
	number = {1-4},
	urldate = {2017-03-04},
	journal = {Physica D: Nonlinear Phenomena},
	author = {Rudin, Leonid I. and Osher, Stanley and Fatemi, Emad},
	month = nov,
	year = {1992},
	pages = {259--268},
}

@article{oktem_shape-based_2017,
	title = {Shape-based image reconstruction using linearized deformations},
	volume = {33},
	issn = {0266-5611, 1361-6420},
	url = {http://stacks.iop.org/0266-5611/33/i=3/a=035004?key=crossref.ea306837ee620c9d460690d0d54c7a8b},
	doi = {10.1088/1361-6420/aa55af},
	number = {3},
	urldate = {2017-03-07},
	journal = {Inverse Problems},
	author = {{\"O}ktem, Ozan and Chen, Chong and Onur Domani{\c c}, Nevzat and Ravikumar, Pradeep and Bajaj, Chandrajit},
	month = mar,
	year = {2017},
	pages = {035004},
}

@article{hoshino_development_2011,
	title = {Development of an {X}-ray real-time stereo imaging technique using synchrotron radiation},
	volume = {18},
	issn = {0909-0495},
	url = {http://scripts.iucr.org/cgi-bin/paper?S0909049511017547},
	doi = {10.1107/S0909049511017547},
	number = {4},
	urldate = {2017-03-08},
	journal = {Journal of Synchrotron Radiation},
	author = {Hoshino, Masato and Uesugi, Kentaro and Pearson, James and Sonobe, Takashi and Shirai, Mikiyasu and Yagi, Naoto},
	month = jul,
	year = {2011},
	pages = {569--574},
}

@inproceedings{dimaio_improved_2007,
	title = {Improved {Methods} for {Template}-{Matching} in {Electron}-{Density} {Maps} {Using} {Spherical} {Harmonics}},
	isbn = {978-0-7695-3031-4},
	url = {http://ieeexplore.ieee.org/document/4413064/},
	doi = {10.1109/BIBM.2007.58},
	urldate = {2017-03-12},
	publisher = {IEEE},
	author = {DiMaio, Frank and Soni, Ameet and Phillips, George N. and Shavlik, Jude W.},
	month = nov,
	year = {2007},
	pages = {258--265},
}

@article{kohr_total_2017,
	title = {Total variation regularization with variable {Lebesgue} prior},
	url = {http://arxiv.org/abs/1702.08807},
	abstract = {This work proposes the variable exponent Lebesgue modular as a replacement for the 1-norm in total variation (TV) regularization. It allows the exponent to vary with spatial location and thus enables users to locally select whether to preserve edges or smooth intensity variations. In contrast to earlier work using TV-like methods with variable exponents, the exponent function is here computed offline as a fixed parameter of the final optimization problem, resulting in a convex goal functional. The obtained formulas for the convex conjugate and the proximal operators are simple in structure and can be evaluated very efficiently, an important property for practical usability. Numerical results with variable \$L{\textasciicircum}p\$ TV prior in denoising and tomography problems on synthetic data compare favorably to total generalized variation (TGV) and TV.},
	urldate = {2017-03-13},
	journal = {arXiv:1702.08807 [math]},
	author = {Kohr, Holger},
	month = feb,
	year = {2017},
	note = {arXiv: 1702.08807},
}
